{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b24ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5456 entries, 0 to 5455\n",
      "Data columns (total 25 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Sensor1   5456 non-null   float64\n",
      " 1   Sensor2   5456 non-null   float64\n",
      " 2   Sensor3   5456 non-null   float64\n",
      " 3   Sensor4   5456 non-null   float64\n",
      " 4   Sensor5   5456 non-null   float64\n",
      " 5   Sensor6   5456 non-null   float64\n",
      " 6   Sensor7   5456 non-null   float64\n",
      " 7   Sensor8   5456 non-null   float64\n",
      " 8   Sensor9   5456 non-null   float64\n",
      " 9   Sensor10  5456 non-null   float64\n",
      " 10  Sensor11  5456 non-null   float64\n",
      " 11  Sensor12  5456 non-null   float64\n",
      " 12  Sensor13  5456 non-null   float64\n",
      " 13  Sensor14  5456 non-null   float64\n",
      " 14  Sensor15  5456 non-null   float64\n",
      " 15  Sensor16  5456 non-null   float64\n",
      " 16  Sensor17  5456 non-null   float64\n",
      " 17  Sensor18  5456 non-null   float64\n",
      " 18  Sensor19  5456 non-null   float64\n",
      " 19  Sensor20  5456 non-null   float64\n",
      " 20  Sensor21  5456 non-null   float64\n",
      " 21  Sensor22  5456 non-null   float64\n",
      " 22  Sensor23  5456 non-null   float64\n",
      " 23  Sensor24  5456 non-null   float64\n",
      " 24  Command   5456 non-null   object \n",
      "dtypes: float64(24), object(1)\n",
      "memory usage: 1.0+ MB\n",
      "None\n",
      "Index(['Sensor1', 'Sensor2', 'Sensor3', 'Sensor4', 'Sensor5', 'Sensor6',\n",
      "       'Sensor7', 'Sensor8', 'Sensor9', 'Sensor10', 'Sensor11', 'Sensor12',\n",
      "       'Sensor13', 'Sensor14', 'Sensor15', 'Sensor16', 'Sensor17', 'Sensor18',\n",
      "       'Sensor19', 'Sensor20', 'Sensor21', 'Sensor22', 'Sensor23', 'Sensor24',\n",
      "       'Command'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the sensor readings dataset from a CSV file into a Pandas DataFrame \n",
    "df = pd.read_csv(\"sensor_readings_24.csv\")\n",
    "\n",
    "# Get basic information about data\n",
    "print(df.info())\n",
    "print(df.columns)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.iloc[:, :-1].to_numpy()\n",
    "\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(df.iloc[:, -1])\n",
    "\n",
    "# Split data into train (70%) and test (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# # Extract numeric values from mileage, engine, and max_power columns and convert them to floats\n",
    "# for col in [\"mileage\", \"engine\", \"max_power\"]:\n",
    "#     X[col] = pd.to_numeric(\n",
    "#         X[col].astype(str).str.extract(r\"(\\d+\\.?\\d*)\")[0],\n",
    "#         errors=\"coerce\"\n",
    "#     )\n",
    "\n",
    "# # Separate numeric and categorical columns for preprocessing\n",
    "# numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "# categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# # Impute missing numeric values using the median of each column\n",
    "# for col in numeric_cols:\n",
    "#     X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# # Impute missing categorical values using the most frequent category (mode)\n",
    "# for col in categorical_cols:\n",
    "#     X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "# # Split data into train (70%) and test (30%) sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Define preprocessing pipeline: standardize numeric columns and one-hot encode categorical columns\n",
    "# preprocess = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         (\"num\", StandardScaler(), numeric_cols),\n",
    "#         (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "#     ],\n",
    "#     remainder=\"drop\"\n",
    "# )\n",
    "\n",
    "# # Fit preprocessing on training data and apply the same transformation to both train and test sets\n",
    "# X_train_scaled = preprocess.fit_transform(X_train)\n",
    "# X_test_scaled = preprocess.transform(X_test)\n",
    "\n",
    "# # Scaling the target variable to improve neural network training stability\n",
    "# scaler_y = StandardScaler()\n",
    "# y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "# # Build a neural network model to predict car selling price\n",
    "# nn_model = tf.keras.Sequential([\n",
    "#     tf.keras.Input(shape=(X_train_scaled.shape[1],)),\n",
    "#     tf.keras.layers.Dense(80, activation='relu',),\n",
    "#     tf.keras.layers.Dense(80, activation='relu',),\n",
    "#     tf.keras.layers.Dense(80, activation='relu',),\n",
    "#     tf.keras.layers.Dense(y_train_scaled.shape[1])\n",
    "# ])\n",
    "\n",
    "# # Compile the neural network using Adam optimizer and Huber loss for regression\n",
    "# nn_model.compile(\n",
    "#     tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "#     # loss=tf.keras.losses.Huber(delta=100000.0),  # delta in INR\n",
    "#     loss='mse',\n",
    "#     # metrics=['mae']\n",
    "# )\n",
    "\n",
    "# # Reduce learning rate when validation loss stops improving\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor=\"val_loss\", factor=0.5, patience=10, min_lr=1e-6\n",
    "# )\n",
    "\n",
    "# # Stop training early and restore the best model weights\n",
    "# early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor=\"val_loss\", patience=30, restore_best_weights=True\n",
    "# )\n",
    "\n",
    "# # Train the neural network using validation split and adaptive callbacks\n",
    "# nn_model.fit(\n",
    "#     X_train_scaled, y_train_scaled,\n",
    "#     validation_split=0.2,\n",
    "#     shuffle=True,\n",
    "#     epochs=3000,\n",
    "#     batch_size=32,\n",
    "#     callbacks=[early_stop, reduce_lr],\n",
    "#     #verbose=0\n",
    "# )\n",
    "\n",
    "# # Generate predictions for the train and test dataset\n",
    "# nn_model_prediction_train = nn_model.predict(X_train_scaled)\n",
    "# nn_model_prediction_test = nn_model.predict(X_test_scaled)\n",
    "\n",
    "# # Apply inverse transformation to obtain predicted prices in the original currency scale\n",
    "# nn_model_prediction_train = scaler_y.inverse_transform(nn_model_prediction_train)\n",
    "# nn_model_prediction_test = scaler_y.inverse_transform(nn_model_prediction_test)\n",
    "\n",
    "\n",
    "# # Evaluate and display model accuracy with Mean Absolute Error for train and test datasets\n",
    "# print(f\"Mean absolute error in train dataset using Neural Network Model: {mean_absolute_error(y_train, nn_model_prediction_train):.2f}\")\n",
    "# print(f\"Mean absolute error in test dataset using Neural Network Model: {mean_absolute_error(y_test, nn_model_prediction_test):.2f}\")\n",
    "\n",
    "# # Plot Predicted Vs Actual Selling Prices of the cars in the test dataset\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.scatter(y_test, nn_model_prediction_test, alpha=0.5)\n",
    "# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"red\", linewidth=2)\n",
    "# plt.xlabel(\"Actual Selling Price\")\n",
    "# plt.ylabel(\"Predicted Selling Price\")\n",
    "# plt.title(\"Actual vs Predicted Selling Price (Test Data)\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
