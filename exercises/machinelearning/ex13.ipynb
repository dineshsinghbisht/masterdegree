{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b24ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trtbps    303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalachh  303 non-null    int64  \n",
      " 8   exng      303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slp       303 non-null    int64  \n",
      " 11  caa       303 non-null    int64  \n",
      " 12  thall     303 non-null    int64  \n",
      " 13  output    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n",
      "None\n",
      "Index(['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n",
      "       'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output'],\n",
      "      dtype='object')\n",
      "Index([0, 1], dtype='int64')\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dineshbisht/masterdegree/myproject_env/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.4890 - loss: 0.7179 - val_accuracy: 0.7237 - val_loss: 0.6505\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5110 - loss: 0.7162 - val_accuracy: 0.8158 - val_loss: 0.6204\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5727 - loss: 0.6819 - val_accuracy: 0.8289 - val_loss: 0.5920\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6652 - loss: 0.6385 - val_accuracy: 0.8684 - val_loss: 0.5685\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7357 - loss: 0.6149 - val_accuracy: 0.8684 - val_loss: 0.5434\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7137 - loss: 0.6036 - val_accuracy: 0.8816 - val_loss: 0.5162\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7577 - loss: 0.5810 - val_accuracy: 0.8947 - val_loss: 0.4864\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 0.5387 - val_accuracy: 0.9211 - val_loss: 0.4549\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7489 - loss: 0.5368 - val_accuracy: 0.9474 - val_loss: 0.4250\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7841 - loss: 0.5085 - val_accuracy: 0.9474 - val_loss: 0.3976\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7885 - loss: 0.5075 - val_accuracy: 0.9474 - val_loss: 0.3721\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8062 - loss: 0.4491 - val_accuracy: 0.9474 - val_loss: 0.3472\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7885 - loss: 0.4675 - val_accuracy: 0.9474 - val_loss: 0.3253\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8018 - loss: 0.4454 - val_accuracy: 0.9474 - val_loss: 0.3068\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8018 - loss: 0.4430 - val_accuracy: 0.9474 - val_loss: 0.2900\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.4152 - val_accuracy: 0.9474 - val_loss: 0.2754\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7885 - loss: 0.4441 - val_accuracy: 0.9605 - val_loss: 0.2639\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8150 - loss: 0.3906 - val_accuracy: 0.9605 - val_loss: 0.2542\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8062 - loss: 0.4512 - val_accuracy: 0.9474 - val_loss: 0.2477\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8106 - loss: 0.4057 - val_accuracy: 0.9474 - val_loss: 0.2426\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7885 - loss: 0.4442 - val_accuracy: 0.9342 - val_loss: 0.2395\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8194 - loss: 0.4093 - val_accuracy: 0.9211 - val_loss: 0.2363\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8150 - loss: 0.4185 - val_accuracy: 0.9211 - val_loss: 0.2337\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8370 - loss: 0.3826 - val_accuracy: 0.9211 - val_loss: 0.2326\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8370 - loss: 0.3769 - val_accuracy: 0.9342 - val_loss: 0.2323\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8062 - loss: 0.4017 - val_accuracy: 0.9342 - val_loss: 0.2328\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8194 - loss: 0.3864 - val_accuracy: 0.9342 - val_loss: 0.2345\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8106 - loss: 0.3855 - val_accuracy: 0.9211 - val_loss: 0.2359\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8282 - loss: 0.3741 - val_accuracy: 0.9211 - val_loss: 0.2349\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.4040 - val_accuracy: 0.9211 - val_loss: 0.2329\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8634 - loss: 0.3437 - val_accuracy: 0.9211 - val_loss: 0.2299\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8326 - loss: 0.3514 - val_accuracy: 0.9211 - val_loss: 0.2260\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8370 - loss: 0.3595 - val_accuracy: 0.9211 - val_loss: 0.2225\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8458 - loss: 0.3509 - val_accuracy: 0.9342 - val_loss: 0.2190\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8546 - loss: 0.3549 - val_accuracy: 0.9342 - val_loss: 0.2180\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8458 - loss: 0.3560 - val_accuracy: 0.9211 - val_loss: 0.2188\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8370 - loss: 0.3819 - val_accuracy: 0.9211 - val_loss: 0.2226\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8546 - loss: 0.3361 - val_accuracy: 0.9079 - val_loss: 0.2292\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8458 - loss: 0.3573 - val_accuracy: 0.8947 - val_loss: 0.2334\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.3631 - val_accuracy: 0.8947 - val_loss: 0.2369\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 0.3695 - val_accuracy: 0.9079 - val_loss: 0.2387\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8458 - loss: 0.3472 - val_accuracy: 0.9079 - val_loss: 0.2390\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8678 - loss: 0.3175 - val_accuracy: 0.9079 - val_loss: 0.2371\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8855 - loss: 0.3082 - val_accuracy: 0.8947 - val_loss: 0.2346\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8502 - loss: 0.3395 - val_accuracy: 0.9079 - val_loss: 0.2319\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8458 - loss: 0.3111 - val_accuracy: 0.8947 - val_loss: 0.2289\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8634 - loss: 0.3298 - val_accuracy: 0.8947 - val_loss: 0.2275\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8590 - loss: 0.3011 - val_accuracy: 0.8947 - val_loss: 0.2271\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8590 - loss: 0.2939 - val_accuracy: 0.8947 - val_loss: 0.2262\n",
      "Epoch 50/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8370 - loss: 0.3199 - val_accuracy: 0.8816 - val_loss: 0.2252\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.8546 - loss: 0.3306\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Accuracy Score in train dataset using Neural Network Model: 0.91\n",
      "Accuracy Score in test dataset using Neural Network Model: 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the dataset from a CSV file into a Pandas DataFrame \n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "# Get basic information about data\n",
    "print(df.info())\n",
    "print(df.columns)\n",
    "\n",
    "# Extract all columns except the last as features (X) \n",
    "X = df.iloc[:, :-1].to_numpy()\n",
    "\n",
    "# Scale feature values so all inputs are on the same numerical range\n",
    "scaler_x = StandardScaler()\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "\n",
    "# Encode the last column as numeric target labels (y)\n",
    "y = pd.get_dummies(df.iloc[:, -1])\n",
    "print(y.columns)\n",
    "\n",
    "# Split data into train (70%) and test (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, stratify=y)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(50, activation='relu',),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(30, activation='relu',),\n",
    "    tf.keras.layers.Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=100)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# Generate predictions for the train and test dataset\n",
    "nn_model_prediction_train = np.argmax(model.predict(X_train), axis=1)\n",
    "nn_model_prediction_test = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Evaluate and display model accuracy with Accuracy for train and test datasets\n",
    "print(f\"\\nAccuracy Score in train dataset using Neural Network Model: {accuracy_score(np.argmax(y_train, axis=1), nn_model_prediction_train):.2f}\")\n",
    "print(f\"Accuracy Score in test dataset using Neural Network Model: {accuracy_score(np.argmax(y_test, axis=1), nn_model_prediction_test):.2f}\\n\")\n",
    "\n",
    "# # Create a dictionary that maps numeric class labels to their original column names\n",
    "# mapping = {0:y.columns[0], 1:y.columns[1], 2:y.columns[2], 3:y.columns[3]}\n",
    "\n",
    "# # Create an empty list to store converted neural network predictions\n",
    "# nn_model_prediction_test_strings = []\n",
    "\n",
    "# # Loop through numeric predictions and convert them to original class labels using the mapping\n",
    "# for number in nn_model_prediction_test:\n",
    "#     nn_model_prediction_test_strings.append(mapping[number])\n",
    "\n",
    "# # Create an empty list to store actual class labels\n",
    "# real_commands = []\n",
    "\n",
    "# # Convert one-hot encoded true labels to numeric class indices and map them back to original class names\n",
    "# for number in np.argmax(y_test, axis=1):\n",
    "#     real_commands.append(mapping[number]) \n",
    "\n",
    "# # Create an empty DataFrame to store validation results\n",
    "# df_validation = pd.DataFrame()\n",
    "\n",
    "# # Add predicted class labels to the DataFrame\n",
    "# df_validation[\"Prediction\"] = nn_model_prediction_test_strings\n",
    "\n",
    "# # Add actual class labels (true values) to the DataFrame'\n",
    "# df_validation[\"Read Command\"] = real_commands\n",
    "\n",
    "# # Randomly select 20 rows for print\n",
    "# df_validation = df_validation.sample(20)\n",
    "# print(\"Predicted and the actual Control Command for 20 random rows from the test data\")\n",
    "# print(df_validation.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
