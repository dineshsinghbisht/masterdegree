{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Move-Forward', 'Sharp-Right-Turn', 'Slight-Left-Turn',\n",
      "       'Slight-Right-Turn'],\n",
      "      dtype='object')\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dineshbisht/masterdegree/myproject_env/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3746 - loss: 1.2740 - val_accuracy: 0.5762 - val_loss: 1.0692\n",
      "Epoch 2/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.5574 - loss: 1.0185 - val_accuracy: 0.6752 - val_loss: 0.8578\n",
      "Epoch 3/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.6420 - loss: 0.8540 - val_accuracy: 0.7170 - val_loss: 0.7202\n",
      "Epoch 4/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.6887 - loss: 0.7521 - val_accuracy: 0.7463 - val_loss: 0.6459\n",
      "Epoch 5/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.7199 - loss: 0.6902 - val_accuracy: 0.7581 - val_loss: 0.5961\n",
      "Epoch 6/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7363 - loss: 0.6415 - val_accuracy: 0.7845 - val_loss: 0.5524\n",
      "Epoch 7/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.7564 - loss: 0.6066 - val_accuracy: 0.8013 - val_loss: 0.5230\n",
      "Epoch 8/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.7717 - loss: 0.5766 - val_accuracy: 0.8028 - val_loss: 0.4999\n",
      "Epoch 9/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.7830 - loss: 0.5480 - val_accuracy: 0.8152 - val_loss: 0.4819\n",
      "Epoch 10/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.7969 - loss: 0.5247 - val_accuracy: 0.8299 - val_loss: 0.4534\n",
      "Epoch 11/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.7967 - loss: 0.5190 - val_accuracy: 0.8270 - val_loss: 0.4468\n",
      "Epoch 12/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7928 - loss: 0.4990 - val_accuracy: 0.8321 - val_loss: 0.4299\n",
      "Epoch 13/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8130 - loss: 0.4837 - val_accuracy: 0.8394 - val_loss: 0.4188\n",
      "Epoch 14/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.8160 - loss: 0.4663 - val_accuracy: 0.8490 - val_loss: 0.4108\n",
      "Epoch 15/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.8155 - loss: 0.4628 - val_accuracy: 0.8438 - val_loss: 0.4036\n",
      "Epoch 16/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.8258 - loss: 0.4486 - val_accuracy: 0.8490 - val_loss: 0.4004\n",
      "Epoch 17/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.8292 - loss: 0.4297 - val_accuracy: 0.8578 - val_loss: 0.3836\n",
      "Epoch 18/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.8368 - loss: 0.4204 - val_accuracy: 0.8578 - val_loss: 0.3775\n",
      "Epoch 19/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8368 - loss: 0.4114 - val_accuracy: 0.8570 - val_loss: 0.3715\n",
      "Epoch 20/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.8546 - loss: 0.3850 - val_accuracy: 0.8534 - val_loss: 0.3673\n",
      "Epoch 21/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.8456 - loss: 0.3934 - val_accuracy: 0.8614 - val_loss: 0.3606\n",
      "Epoch 22/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8500 - loss: 0.3978 - val_accuracy: 0.8688 - val_loss: 0.3537\n",
      "Epoch 23/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.8578 - loss: 0.3775 - val_accuracy: 0.8651 - val_loss: 0.3505\n",
      "Epoch 24/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8597 - loss: 0.3676 - val_accuracy: 0.8702 - val_loss: 0.3405\n",
      "Epoch 25/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.8575 - loss: 0.3713 - val_accuracy: 0.8651 - val_loss: 0.3414\n",
      "Epoch 26/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.8675 - loss: 0.3507 - val_accuracy: 0.8717 - val_loss: 0.3292\n",
      "Epoch 27/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.8561 - loss: 0.3541 - val_accuracy: 0.8732 - val_loss: 0.3377\n",
      "Epoch 28/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.8697 - loss: 0.3563 - val_accuracy: 0.8761 - val_loss: 0.3387\n",
      "Epoch 29/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.8763 - loss: 0.3358 - val_accuracy: 0.8798 - val_loss: 0.3192\n",
      "Epoch 30/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.8793 - loss: 0.3170 - val_accuracy: 0.8768 - val_loss: 0.3125\n",
      "Epoch 31/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.8732 - loss: 0.3352 - val_accuracy: 0.8856 - val_loss: 0.3060\n",
      "Epoch 32/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8810 - loss: 0.3127 - val_accuracy: 0.8842 - val_loss: 0.3036\n",
      "Epoch 33/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.8827 - loss: 0.3102 - val_accuracy: 0.8937 - val_loss: 0.2993\n",
      "Epoch 34/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8761 - loss: 0.3152 - val_accuracy: 0.8827 - val_loss: 0.2973\n",
      "Epoch 35/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8849 - loss: 0.3057 - val_accuracy: 0.8849 - val_loss: 0.2923\n",
      "Epoch 36/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.8815 - loss: 0.3122 - val_accuracy: 0.8849 - val_loss: 0.2965\n",
      "Epoch 37/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8939 - loss: 0.2933 - val_accuracy: 0.8915 - val_loss: 0.2901\n",
      "Epoch 38/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.8915 - loss: 0.2854 - val_accuracy: 0.8944 - val_loss: 0.2854\n",
      "Epoch 39/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.8873 - loss: 0.2834 - val_accuracy: 0.8952 - val_loss: 0.2808\n",
      "Epoch 40/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.8988 - loss: 0.2743 - val_accuracy: 0.8930 - val_loss: 0.2829\n",
      "Epoch 41/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.9010 - loss: 0.2665 - val_accuracy: 0.8996 - val_loss: 0.2725\n",
      "Epoch 42/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9000 - loss: 0.2734 - val_accuracy: 0.9018 - val_loss: 0.2710\n",
      "Epoch 43/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.8974 - loss: 0.2714 - val_accuracy: 0.8959 - val_loss: 0.2690\n",
      "Epoch 44/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9000 - loss: 0.2669 - val_accuracy: 0.8988 - val_loss: 0.2659\n",
      "Epoch 45/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.8932 - loss: 0.2630 - val_accuracy: 0.8988 - val_loss: 0.2632\n",
      "Epoch 46/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.8996 - loss: 0.2554 - val_accuracy: 0.9032 - val_loss: 0.2609\n",
      "Epoch 47/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9020 - loss: 0.2573 - val_accuracy: 0.8996 - val_loss: 0.2577\n",
      "Epoch 48/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.9000 - loss: 0.2590 - val_accuracy: 0.9076 - val_loss: 0.2633\n",
      "Epoch 49/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.9108 - loss: 0.2433 - val_accuracy: 0.9069 - val_loss: 0.2543\n",
      "Epoch 50/50\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9093 - loss: 0.2437 - val_accuracy: 0.9032 - val_loss: 0.2568\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.9030 - loss: 0.2515\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step\n",
      "\n",
      "Accuracy Score in train dataset using Neural Network Model: 0.95\n",
      "Accuracy Score in test dataset using Neural Network Model: 0.91\n",
      "\n",
      "Predicted and the actual Control Command for 20 random rows from the test data\n",
      "       Prediction      Read Command\n",
      " Sharp-Right-Turn  Sharp-Right-Turn\n",
      "Slight-Right-Turn Slight-Right-Turn\n",
      "Slight-Right-Turn Slight-Right-Turn\n",
      " Slight-Left-Turn  Slight-Left-Turn\n",
      " Slight-Left-Turn  Slight-Left-Turn\n",
      "     Move-Forward      Move-Forward\n",
      " Sharp-Right-Turn      Move-Forward\n",
      " Sharp-Right-Turn  Sharp-Right-Turn\n",
      "Slight-Right-Turn Slight-Right-Turn\n",
      " Sharp-Right-Turn  Sharp-Right-Turn\n",
      "     Move-Forward      Move-Forward\n",
      "     Move-Forward      Move-Forward\n",
      "Slight-Right-Turn Slight-Right-Turn\n",
      " Sharp-Right-Turn  Sharp-Right-Turn\n",
      " Sharp-Right-Turn  Sharp-Right-Turn\n",
      "     Move-Forward      Move-Forward\n",
      "Slight-Right-Turn Slight-Right-Turn\n",
      " Sharp-Right-Turn  Sharp-Right-Turn\n",
      "     Move-Forward      Move-Forward\n",
      " Sharp-Right-Turn  Sharp-Right-Turn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the sensor readings dataset from a CSV file into a Pandas DataFrame \n",
    "df = pd.read_csv(\"sensor_readings_24.csv\")\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())\n",
    "# print(df.columns)\n",
    "\n",
    "# Extract all columns except the last as features (X) \n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "# Scale feature values so all inputs are on the same numerical range\n",
    "scaler_x = StandardScaler()\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "\n",
    "# Encode the last column as numeric target labels (y)\n",
    "y = pd.get_dummies(df.iloc[:, -1])\n",
    "print(y.columns)\n",
    "\n",
    "# Split data into train (75%) and test (25%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, stratify=y)\n",
    "\n",
    "# Train the model on the training dataset\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(50, activation='relu',),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(30, activation='relu',),\n",
    "    tf.keras.layers.Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=100)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for the train and test dataset\n",
    "nn_model_prediction_train = np.argmax(model.predict(X_train), axis=1)\n",
    "nn_model_prediction_test = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Evaluate and display model accuracy with Accuracy for train and test datasets\n",
    "print(f\"\\nAccuracy Score in train dataset using Neural Network Model: {accuracy_score(np.argmax(y_train, axis=1), nn_model_prediction_train):.2f}\")\n",
    "print(f\"Accuracy Score in test dataset using Neural Network Model: {accuracy_score(np.argmax(y_test, axis=1), nn_model_prediction_test):.2f}\\n\")\n",
    "\n",
    "# Create a dictionary that maps numeric class labels to their original column names\n",
    "mapping = {0:y.columns[0], 1:y.columns[1], 2:y.columns[2], 3:y.columns[3]}\n",
    "\n",
    "# Create an empty list to store converted neural network predictions\n",
    "nn_model_prediction_test_strings = []\n",
    "\n",
    "# Loop through numeric predictions and convert them to original class labels using the mapping\n",
    "for number in nn_model_prediction_test:\n",
    "    nn_model_prediction_test_strings.append(mapping[number])\n",
    "\n",
    "# Create an empty list to store actual class labels\n",
    "real_commands = []\n",
    "\n",
    "# Convert one-hot encoded true labels to numeric class indices and map them back to original class names\n",
    "for number in np.argmax(y_test, axis=1):\n",
    "    real_commands.append(mapping[number]) \n",
    "\n",
    "# Create an empty DataFrame to store validation results\n",
    "df_validation = pd.DataFrame()\n",
    "\n",
    "# Add predicted class labels to the DataFrame\n",
    "df_validation[\"Prediction\"] = nn_model_prediction_test_strings\n",
    "\n",
    "# Add actual class labels (true values) to the DataFrame'\n",
    "df_validation[\"Read Command\"] = real_commands\n",
    "\n",
    "# Randomly select 20 rows for print\n",
    "df_validation = df_validation.sample(20)\n",
    "print(\"Predicted and the actual Control Command for 20 random rows from the test data\")\n",
    "print(df_validation.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
