{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b24ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59314651136.0000 - mae: 642881.5000 - val_loss: 54502342656.0000 - val_mae: 594623.1250 - learning_rate: 0.0010\n",
      "Epoch 2/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 55296761856.0000 - mae: 601892.3125 - val_loss: 43350429696.0000 - val_mae: 479988.9062 - learning_rate: 0.0010\n",
      "Epoch 3/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 35002261504.0000 - mae: 394355.6250 - val_loss: 22268905472.0000 - val_mae: 265560.8438 - learning_rate: 0.0010\n",
      "Epoch 4/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 22609188864.0000 - mae: 267907.8750 - val_loss: 17512503296.0000 - val_mae: 215421.9531 - learning_rate: 0.0010\n",
      "Epoch 5/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 19675609088.0000 - mae: 237024.0781 - val_loss: 15875578880.0000 - val_mae: 197732.4375 - learning_rate: 0.0010\n",
      "Epoch 6/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 18341083136.0000 - mae: 223034.8594 - val_loss: 15030703104.0000 - val_mae: 189303.5000 - learning_rate: 0.0010\n",
      "Epoch 7/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 17525063680.0000 - mae: 214653.0000 - val_loss: 14474642432.0000 - val_mae: 183570.9531 - learning_rate: 0.0010\n",
      "Epoch 8/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 16931001344.0000 - mae: 208497.7188 - val_loss: 14127494144.0000 - val_mae: 179597.6875 - learning_rate: 0.0010\n",
      "Epoch 9/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 16515505152.0000 - mae: 203911.9688 - val_loss: 13880238080.0000 - val_mae: 176723.4219 - learning_rate: 0.0010\n",
      "Epoch 10/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 16217450496.0000 - mae: 200860.1250 - val_loss: 13679930368.0000 - val_mae: 174565.0156 - learning_rate: 0.0010\n",
      "Epoch 11/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 15963469824.0000 - mae: 198170.2031 - val_loss: 13512263680.0000 - val_mae: 172869.9375 - learning_rate: 0.0010\n",
      "Epoch 12/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 15733498880.0000 - mae: 195756.4688 - val_loss: 13349432320.0000 - val_mae: 171155.2500 - learning_rate: 0.0010\n",
      "Epoch 13/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 15516724224.0000 - mae: 193544.6094 - val_loss: 13233179648.0000 - val_mae: 170053.9688 - learning_rate: 0.0010\n",
      "Epoch 14/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 15319845888.0000 - mae: 191434.5469 - val_loss: 13134045184.0000 - val_mae: 169286.9844 - learning_rate: 0.0010\n",
      "Epoch 15/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 15099760640.0000 - mae: 189162.9688 - val_loss: 12884353024.0000 - val_mae: 166344.9219 - learning_rate: 0.0010\n",
      "Epoch 16/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 14906715136.0000 - mae: 187205.4219 - val_loss: 12725344256.0000 - val_mae: 164904.4375 - learning_rate: 0.0010\n",
      "Epoch 17/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 14677483520.0000 - mae: 184914.2812 - val_loss: 12510925824.0000 - val_mae: 162672.4219 - learning_rate: 0.0010\n",
      "Epoch 18/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 14463903744.0000 - mae: 182632.1406 - val_loss: 12367033344.0000 - val_mae: 161260.1562 - learning_rate: 0.0010\n",
      "Epoch 19/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 14208706560.0000 - mae: 179969.3750 - val_loss: 12303769600.0000 - val_mae: 160952.1562 - learning_rate: 0.0010\n",
      "Epoch 20/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 13980599296.0000 - mae: 177662.4375 - val_loss: 11972371456.0000 - val_mae: 157365.4688 - learning_rate: 0.0010\n",
      "Epoch 21/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 13692968960.0000 - mae: 174742.4219 - val_loss: 11704333312.0000 - val_mae: 154422.0156 - learning_rate: 0.0010\n",
      "Epoch 22/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 13440462848.0000 - mae: 172219.0156 - val_loss: 11513202688.0000 - val_mae: 152678.1250 - learning_rate: 0.0010\n",
      "Epoch 23/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 13169961984.0000 - mae: 169499.3594 - val_loss: 11278592000.0000 - val_mae: 149899.7188 - learning_rate: 0.0010\n",
      "Epoch 24/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 12927481856.0000 - mae: 167108.8594 - val_loss: 11052042240.0000 - val_mae: 147517.0781 - learning_rate: 0.0010\n",
      "Epoch 25/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 12661409792.0000 - mae: 164394.1562 - val_loss: 10821377024.0000 - val_mae: 145389.2969 - learning_rate: 0.0010\n",
      "Epoch 26/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 12433028096.0000 - mae: 162203.8438 - val_loss: 10639429632.0000 - val_mae: 143888.1250 - learning_rate: 0.0010\n",
      "Epoch 27/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 12172563456.0000 - mae: 159553.4844 - val_loss: 10438970368.0000 - val_mae: 141427.3906 - learning_rate: 0.0010\n",
      "Epoch 28/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 11936458752.0000 - mae: 157224.1562 - val_loss: 10275269632.0000 - val_mae: 139768.9062 - learning_rate: 0.0010\n",
      "Epoch 29/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 11688562688.0000 - mae: 154598.1719 - val_loss: 10103826432.0000 - val_mae: 137833.0000 - learning_rate: 0.0010\n",
      "Epoch 30/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 11439660032.0000 - mae: 151944.5312 - val_loss: 9883664384.0000 - val_mae: 135659.6094 - learning_rate: 0.0010\n",
      "Epoch 31/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 11225372672.0000 - mae: 149814.1250 - val_loss: 9756284928.0000 - val_mae: 134557.1875 - learning_rate: 0.0010\n",
      "Epoch 32/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 11037642752.0000 - mae: 147811.0156 - val_loss: 9597574144.0000 - val_mae: 132724.0938 - learning_rate: 0.0010\n",
      "Epoch 33/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 10855504896.0000 - mae: 145878.8438 - val_loss: 9481957376.0000 - val_mae: 131716.5625 - learning_rate: 0.0010\n",
      "Epoch 34/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 10710149120.0000 - mae: 144625.0938 - val_loss: 9333941248.0000 - val_mae: 129821.3672 - learning_rate: 0.0010\n",
      "Epoch 35/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 10550788096.0000 - mae: 142894.6250 - val_loss: 9253107712.0000 - val_mae: 128976.2656 - learning_rate: 0.0010\n",
      "Epoch 36/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 10415727616.0000 - mae: 141740.5156 - val_loss: 9197708288.0000 - val_mae: 128982.9062 - learning_rate: 0.0010\n",
      "Epoch 37/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 10283269120.0000 - mae: 140259.5156 - val_loss: 9103783936.0000 - val_mae: 127652.2344 - learning_rate: 0.0010\n",
      "Epoch 38/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 10146992128.0000 - mae: 138966.6875 - val_loss: 9013017600.0000 - val_mae: 126796.8750 - learning_rate: 0.0010\n",
      "Epoch 39/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 10017308672.0000 - mae: 137588.2656 - val_loss: 8963138560.0000 - val_mae: 126079.9141 - learning_rate: 0.0010\n",
      "Epoch 40/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 9881997312.0000 - mae: 136304.0156 - val_loss: 8899488768.0000 - val_mae: 125571.3906 - learning_rate: 0.0010\n",
      "Epoch 41/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 9768409088.0000 - mae: 135201.0469 - val_loss: 8839499776.0000 - val_mae: 125039.0547 - learning_rate: 0.0010\n",
      "Epoch 42/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 9651747840.0000 - mae: 133979.8906 - val_loss: 8790130688.0000 - val_mae: 124188.3438 - learning_rate: 0.0010\n",
      "Epoch 43/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 9539120128.0000 - mae: 132783.7500 - val_loss: 8757178368.0000 - val_mae: 124161.5078 - learning_rate: 0.0010\n",
      "Epoch 44/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 9456202752.0000 - mae: 131887.2031 - val_loss: 8684888064.0000 - val_mae: 123177.8828 - learning_rate: 0.0010\n",
      "Epoch 45/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 9388394496.0000 - mae: 131192.8125 - val_loss: 8647482368.0000 - val_mae: 122914.1797 - learning_rate: 0.0010\n",
      "Epoch 46/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 9310663680.0000 - mae: 130295.9297 - val_loss: 8578636288.0000 - val_mae: 122234.7578 - learning_rate: 0.0010\n",
      "Epoch 47/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 9254897664.0000 - mae: 129722.2344 - val_loss: 8551412736.0000 - val_mae: 122039.2266 - learning_rate: 0.0010\n",
      "Epoch 48/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 9213911040.0000 - mae: 129319.0781 - val_loss: 8511692288.0000 - val_mae: 121606.6328 - learning_rate: 0.0010\n",
      "Epoch 49/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 9164437504.0000 - mae: 128807.1250 - val_loss: 8476897792.0000 - val_mae: 120955.9062 - learning_rate: 0.0010\n",
      "Epoch 50/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 9127463936.0000 - mae: 128349.2891 - val_loss: 8457691648.0000 - val_mae: 120918.1328 - learning_rate: 0.0010\n",
      "Epoch 51/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 9091760128.0000 - mae: 127995.6562 - val_loss: 8435392000.0000 - val_mae: 120698.1250 - learning_rate: 0.0010\n",
      "Epoch 52/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 9064295424.0000 - mae: 127535.0938 - val_loss: 8410472448.0000 - val_mae: 120314.1250 - learning_rate: 0.0010\n",
      "Epoch 53/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 9041068032.0000 - mae: 127454.0078 - val_loss: 8391483904.0000 - val_mae: 119848.4219 - learning_rate: 0.0010\n",
      "Epoch 54/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 9005930496.0000 - mae: 127058.4531 - val_loss: 8409574912.0000 - val_mae: 120002.5625 - learning_rate: 0.0010\n",
      "Epoch 55/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 9000344576.0000 - mae: 126843.4141 - val_loss: 8362912256.0000 - val_mae: 119766.8438 - learning_rate: 0.0010\n",
      "Epoch 56/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 8998821888.0000 - mae: 126829.1016 - val_loss: 8349136896.0000 - val_mae: 119619.4766 - learning_rate: 0.0010\n",
      "Epoch 57/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 8956347392.0000 - mae: 126440.3594 - val_loss: 8357474304.0000 - val_mae: 119691.3750 - learning_rate: 0.0010\n",
      "Epoch 58/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 8948931584.0000 - mae: 126345.4766 - val_loss: 8334950912.0000 - val_mae: 119298.6875 - learning_rate: 0.0010\n",
      "Epoch 59/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 8924321792.0000 - mae: 126055.6172 - val_loss: 8355843072.0000 - val_mae: 120060.2734 - learning_rate: 0.0010\n",
      "Epoch 60/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 8914968576.0000 - mae: 126022.9609 - val_loss: 8313055232.0000 - val_mae: 119131.6406 - learning_rate: 0.0010\n",
      "Epoch 61/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 8890483712.0000 - mae: 125689.3359 - val_loss: 8307040256.0000 - val_mae: 119003.4766 - learning_rate: 0.0010\n",
      "Epoch 62/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 8873357312.0000 - mae: 125489.3047 - val_loss: 8304908288.0000 - val_mae: 118968.8594 - learning_rate: 0.0010\n",
      "Epoch 63/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8861418496.0000 - mae: 125356.6953 - val_loss: 8297618944.0000 - val_mae: 119133.4375 - learning_rate: 0.0010\n",
      "Epoch 64/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 8845838336.0000 - mae: 125201.9141 - val_loss: 8296611328.0000 - val_mae: 118897.1797 - learning_rate: 0.0010\n",
      "Epoch 65/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 8833155072.0000 - mae: 125106.8906 - val_loss: 8268345856.0000 - val_mae: 118772.1484 - learning_rate: 0.0010\n",
      "Epoch 66/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 8813555712.0000 - mae: 124897.6406 - val_loss: 8312230400.0000 - val_mae: 119110.1562 - learning_rate: 0.0010\n",
      "Epoch 67/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 8818269184.0000 - mae: 124890.9297 - val_loss: 8247689728.0000 - val_mae: 118570.8984 - learning_rate: 0.0010\n",
      "Epoch 68/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 8795893760.0000 - mae: 124682.5859 - val_loss: 8237238784.0000 - val_mae: 118318.4922 - learning_rate: 0.0010\n",
      "Epoch 69/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 8785035264.0000 - mae: 124590.9297 - val_loss: 8244582912.0000 - val_mae: 118698.5859 - learning_rate: 0.0010\n",
      "Epoch 70/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 8779835392.0000 - mae: 124519.8828 - val_loss: 8254688768.0000 - val_mae: 118890.6406 - learning_rate: 0.0010\n",
      "Epoch 71/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 8775249920.0000 - mae: 124471.6016 - val_loss: 8235052544.0000 - val_mae: 118579.7109 - learning_rate: 0.0010\n",
      "Epoch 72/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 8758080512.0000 - mae: 124322.8203 - val_loss: 8219484160.0000 - val_mae: 118190.0000 - learning_rate: 0.0010\n",
      "Epoch 73/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 8735363072.0000 - mae: 124043.5625 - val_loss: 8225326592.0000 - val_mae: 118167.8984 - learning_rate: 0.0010\n",
      "Epoch 74/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 8725510144.0000 - mae: 123953.6250 - val_loss: 8213799936.0000 - val_mae: 118048.1094 - learning_rate: 0.0010\n",
      "Epoch 75/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 8733129728.0000 - mae: 123927.2344 - val_loss: 8186267648.0000 - val_mae: 117843.1250 - learning_rate: 0.0010\n",
      "Epoch 76/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 8700931072.0000 - mae: 123657.4609 - val_loss: 8191122944.0000 - val_mae: 117901.6953 - learning_rate: 0.0010\n",
      "Epoch 77/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 8695289856.0000 - mae: 123602.8125 - val_loss: 8178350080.0000 - val_mae: 117813.4375 - learning_rate: 0.0010\n",
      "Epoch 78/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 8686109696.0000 - mae: 123458.7266 - val_loss: 8179234816.0000 - val_mae: 117764.0312 - learning_rate: 0.0010\n",
      "Epoch 79/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 8673471488.0000 - mae: 123332.4297 - val_loss: 8175063552.0000 - val_mae: 117811.8750 - learning_rate: 0.0010\n",
      "Epoch 80/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 8669564928.0000 - mae: 123395.9766 - val_loss: 8183451136.0000 - val_mae: 117689.5703 - learning_rate: 0.0010\n",
      "Epoch 81/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 8664506368.0000 - mae: 123196.1172 - val_loss: 8160140288.0000 - val_mae: 117587.7266 - learning_rate: 0.0010\n",
      "Epoch 82/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 8643245056.0000 - mae: 123010.1797 - val_loss: 8162749440.0000 - val_mae: 117642.0000 - learning_rate: 0.0010\n",
      "Epoch 83/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8648778752.0000 - mae: 122988.8750 - val_loss: 8148888576.0000 - val_mae: 117336.3359 - learning_rate: 0.0010\n",
      "Epoch 84/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8631837696.0000 - mae: 122863.3203 - val_loss: 8144419840.0000 - val_mae: 117309.5781 - learning_rate: 0.0010\n",
      "Epoch 85/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 8620800000.0000 - mae: 122728.7812 - val_loss: 8142400000.0000 - val_mae: 117388.4844 - learning_rate: 0.0010\n",
      "Epoch 86/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 8602822656.0000 - mae: 122476.9844 - val_loss: 8132958208.0000 - val_mae: 117180.0000 - learning_rate: 0.0010\n",
      "Epoch 87/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 8600121344.0000 - mae: 122469.1250 - val_loss: 8155118080.0000 - val_mae: 117321.8359 - learning_rate: 0.0010\n",
      "Epoch 88/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 8606464000.0000 - mae: 122557.6094 - val_loss: 8137896960.0000 - val_mae: 117099.3125 - learning_rate: 0.0010\n",
      "Epoch 89/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 8601013248.0000 - mae: 122498.2344 - val_loss: 8132739072.0000 - val_mae: 116998.6875 - learning_rate: 0.0010\n",
      "Epoch 90/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 8574769152.0000 - mae: 122156.2734 - val_loss: 8126851072.0000 - val_mae: 117087.1406 - learning_rate: 0.0010\n",
      "Epoch 91/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 8565789184.0000 - mae: 122082.9297 - val_loss: 8120626688.0000 - val_mae: 116956.0469 - learning_rate: 0.0010\n",
      "Epoch 92/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 8569260032.0000 - mae: 122100.3281 - val_loss: 8106162176.0000 - val_mae: 117058.8516 - learning_rate: 0.0010\n",
      "Epoch 93/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 8553287168.0000 - mae: 122009.8359 - val_loss: 8102313472.0000 - val_mae: 116682.4453 - learning_rate: 0.0010\n",
      "Epoch 94/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 8540996608.0000 - mae: 121858.8438 - val_loss: 8097541632.0000 - val_mae: 116657.6484 - learning_rate: 0.0010\n",
      "Epoch 95/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 8534853632.0000 - mae: 121769.6406 - val_loss: 8087633408.0000 - val_mae: 116632.3594 - learning_rate: 0.0010\n",
      "Epoch 96/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 8532807680.0000 - mae: 121748.7266 - val_loss: 8070513664.0000 - val_mae: 116544.8984 - learning_rate: 0.0010\n",
      "Epoch 97/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8522723328.0000 - mae: 121565.4297 - val_loss: 8092538368.0000 - val_mae: 116563.8984 - learning_rate: 0.0010\n",
      "Epoch 98/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8513462272.0000 - mae: 121480.4766 - val_loss: 8058923008.0000 - val_mae: 116301.0625 - learning_rate: 0.0010\n",
      "Epoch 99/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 8504022016.0000 - mae: 121407.5938 - val_loss: 8062244864.0000 - val_mae: 116273.8828 - learning_rate: 0.0010\n",
      "Epoch 100/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 8498402816.0000 - mae: 121243.7188 - val_loss: 8060547584.0000 - val_mae: 116438.6484 - learning_rate: 0.0010\n",
      "Epoch 101/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 8491322880.0000 - mae: 121214.8750 - val_loss: 8052621312.0000 - val_mae: 116361.7500 - learning_rate: 0.0010\n",
      "Epoch 102/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 8480060416.0000 - mae: 121036.7109 - val_loss: 8040239104.0000 - val_mae: 116083.5938 - learning_rate: 0.0010\n",
      "Epoch 103/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 8473402880.0000 - mae: 120979.8125 - val_loss: 8032235008.0000 - val_mae: 116151.6953 - learning_rate: 0.0010\n",
      "Epoch 104/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 8466639872.0000 - mae: 120967.4531 - val_loss: 8029402624.0000 - val_mae: 115874.6484 - learning_rate: 0.0010\n",
      "Epoch 105/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 8457054208.0000 - mae: 120830.0000 - val_loss: 8039132672.0000 - val_mae: 115929.2266 - learning_rate: 0.0010\n",
      "Epoch 106/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 8441528320.0000 - mae: 120667.3203 - val_loss: 8028576256.0000 - val_mae: 115975.8984 - learning_rate: 0.0010\n",
      "Epoch 107/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 8437880832.0000 - mae: 120645.4141 - val_loss: 8007462400.0000 - val_mae: 115723.7578 - learning_rate: 0.0010\n",
      "Epoch 108/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 8436202496.0000 - mae: 120590.2422 - val_loss: 8006494208.0000 - val_mae: 115792.2891 - learning_rate: 0.0010\n",
      "Epoch 109/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 8423116288.0000 - mae: 120479.6406 - val_loss: 8024404992.0000 - val_mae: 115793.8828 - learning_rate: 0.0010\n",
      "Epoch 110/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 8410351104.0000 - mae: 120248.4922 - val_loss: 8043247104.0000 - val_mae: 115922.7344 - learning_rate: 0.0010\n",
      "Epoch 111/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 8403625984.0000 - mae: 120263.5078 - val_loss: 8002429952.0000 - val_mae: 115912.5469 - learning_rate: 0.0010\n",
      "Epoch 112/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 8399646208.0000 - mae: 120232.6562 - val_loss: 7985139200.0000 - val_mae: 115409.1797 - learning_rate: 0.0010\n",
      "Epoch 113/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 8393106432.0000 - mae: 120170.9453 - val_loss: 8026189312.0000 - val_mae: 115771.5156 - learning_rate: 0.0010\n",
      "Epoch 114/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 8374324736.0000 - mae: 119820.4766 - val_loss: 7983174656.0000 - val_mae: 115622.1797 - learning_rate: 0.0010\n",
      "Epoch 115/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 8373056512.0000 - mae: 119902.2500 - val_loss: 7967310848.0000 - val_mae: 115437.9844 - learning_rate: 0.0010\n",
      "Epoch 116/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 8374797312.0000 - mae: 119926.0703 - val_loss: 7958974464.0000 - val_mae: 115329.2422 - learning_rate: 0.0010\n",
      "Epoch 117/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 8349686272.0000 - mae: 119599.5312 - val_loss: 7960013824.0000 - val_mae: 115370.6797 - learning_rate: 0.0010\n",
      "Epoch 118/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 8344845824.0000 - mae: 119498.8281 - val_loss: 7948281856.0000 - val_mae: 114944.9219 - learning_rate: 0.0010\n",
      "Epoch 119/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8329620480.0000 - mae: 119422.2266 - val_loss: 7940882432.0000 - val_mae: 114815.1016 - learning_rate: 0.0010\n",
      "Epoch 120/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 8321679872.0000 - mae: 119330.4297 - val_loss: 7938795520.0000 - val_mae: 115102.1094 - learning_rate: 0.0010\n",
      "Epoch 121/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 8322265088.0000 - mae: 119352.9297 - val_loss: 7924247552.0000 - val_mae: 114715.1719 - learning_rate: 0.0010\n",
      "Epoch 122/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 8304314368.0000 - mae: 119127.5703 - val_loss: 7920155136.0000 - val_mae: 114685.5938 - learning_rate: 0.0010\n",
      "Epoch 123/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 8294291968.0000 - mae: 119032.4766 - val_loss: 7927780864.0000 - val_mae: 114647.0469 - learning_rate: 0.0010\n",
      "Epoch 124/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 8285555712.0000 - mae: 118925.4453 - val_loss: 7910344192.0000 - val_mae: 114608.7500 - learning_rate: 0.0010\n",
      "Epoch 125/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 8262791680.0000 - mae: 118684.6562 - val_loss: 7888878592.0000 - val_mae: 114353.2266 - learning_rate: 0.0010\n",
      "Epoch 126/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 8265483776.0000 - mae: 118714.0234 - val_loss: 7897021440.0000 - val_mae: 114345.0625 - learning_rate: 0.0010\n",
      "Epoch 127/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8255355904.0000 - mae: 118605.2891 - val_loss: 7888690688.0000 - val_mae: 114284.5781 - learning_rate: 0.0010\n",
      "Epoch 128/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 8246505984.0000 - mae: 118571.7109 - val_loss: 7873244672.0000 - val_mae: 114147.9141 - learning_rate: 0.0010\n",
      "Epoch 129/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 8222682624.0000 - mae: 118244.8281 - val_loss: 7919446016.0000 - val_mae: 114672.9688 - learning_rate: 0.0010\n",
      "Epoch 130/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 8232480768.0000 - mae: 118449.2891 - val_loss: 7866939392.0000 - val_mae: 114105.9766 - learning_rate: 0.0010\n",
      "Epoch 131/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 8215187456.0000 - mae: 118168.7188 - val_loss: 7861455360.0000 - val_mae: 114133.6484 - learning_rate: 0.0010\n",
      "Epoch 132/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8205450240.0000 - mae: 118131.7500 - val_loss: 7889331712.0000 - val_mae: 114404.5938 - learning_rate: 0.0010\n",
      "Epoch 133/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 8198002688.0000 - mae: 117967.3672 - val_loss: 7853901312.0000 - val_mae: 113871.2031 - learning_rate: 0.0010\n",
      "Epoch 134/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 8186400256.0000 - mae: 117802.8984 - val_loss: 7850263040.0000 - val_mae: 113842.0000 - learning_rate: 0.0010\n",
      "Epoch 135/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 8172504064.0000 - mae: 117662.3281 - val_loss: 7840070144.0000 - val_mae: 113908.2812 - learning_rate: 0.0010\n",
      "Epoch 136/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 8167786496.0000 - mae: 117730.3828 - val_loss: 7825067520.0000 - val_mae: 113534.0312 - learning_rate: 0.0010\n",
      "Epoch 137/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 8156483584.0000 - mae: 117475.4375 - val_loss: 7846775296.0000 - val_mae: 114142.1875 - learning_rate: 0.0010\n",
      "Epoch 138/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 8132407296.0000 - mae: 117308.9375 - val_loss: 7824961536.0000 - val_mae: 113633.2812 - learning_rate: 0.0010\n",
      "Epoch 139/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 8151942656.0000 - mae: 117571.5781 - val_loss: 7821084160.0000 - val_mae: 113544.3984 - learning_rate: 0.0010\n",
      "Epoch 140/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8118584832.0000 - mae: 117053.5078 - val_loss: 7815566848.0000 - val_mae: 113474.6094 - learning_rate: 0.0010\n",
      "Epoch 141/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 8111297536.0000 - mae: 117014.9219 - val_loss: 7787728896.0000 - val_mae: 113147.4062 - learning_rate: 0.0010\n",
      "Epoch 142/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 8097674752.0000 - mae: 116882.2422 - val_loss: 7799786496.0000 - val_mae: 113327.9688 - learning_rate: 0.0010\n",
      "Epoch 143/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 8094534656.0000 - mae: 116899.1562 - val_loss: 7786685952.0000 - val_mae: 113154.0078 - learning_rate: 0.0010\n",
      "Epoch 144/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8083299328.0000 - mae: 116641.5781 - val_loss: 7785980928.0000 - val_mae: 113097.7188 - learning_rate: 0.0010\n",
      "Epoch 145/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 8063148032.0000 - mae: 116489.5312 - val_loss: 7790617600.0000 - val_mae: 113371.3125 - learning_rate: 0.0010\n",
      "Epoch 146/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 8069938688.0000 - mae: 116595.8516 - val_loss: 7765646848.0000 - val_mae: 112970.9297 - learning_rate: 0.0010\n",
      "Epoch 147/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 8049550336.0000 - mae: 116340.5234 - val_loss: 7764709888.0000 - val_mae: 112966.4453 - learning_rate: 0.0010\n",
      "Epoch 148/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 8036992512.0000 - mae: 116180.0391 - val_loss: 7752706560.0000 - val_mae: 112749.4375 - learning_rate: 0.0010\n",
      "Epoch 149/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 8029669888.0000 - mae: 116072.0078 - val_loss: 7755224064.0000 - val_mae: 112960.9844 - learning_rate: 0.0010\n",
      "Epoch 150/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 8021705728.0000 - mae: 115980.3281 - val_loss: 7760556032.0000 - val_mae: 113062.2188 - learning_rate: 0.0010\n",
      "Epoch 151/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 8011226624.0000 - mae: 115907.4844 - val_loss: 7734249472.0000 - val_mae: 112579.2656 - learning_rate: 0.0010\n",
      "Epoch 152/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7997037568.0000 - mae: 115695.3828 - val_loss: 7731459584.0000 - val_mae: 112573.7422 - learning_rate: 0.0010\n",
      "Epoch 153/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 7993247744.0000 - mae: 115657.5859 - val_loss: 7730013696.0000 - val_mae: 112532.2734 - learning_rate: 0.0010\n",
      "Epoch 154/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7978395648.0000 - mae: 115466.9766 - val_loss: 7717229056.0000 - val_mae: 112443.1250 - learning_rate: 0.0010\n",
      "Epoch 155/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7970280960.0000 - mae: 115369.3906 - val_loss: 7718823936.0000 - val_mae: 112514.3828 - learning_rate: 0.0010\n",
      "Epoch 156/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7953324544.0000 - mae: 115267.0469 - val_loss: 7717721600.0000 - val_mae: 112491.7422 - learning_rate: 0.0010\n",
      "Epoch 157/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7959204864.0000 - mae: 115268.3984 - val_loss: 7688156160.0000 - val_mae: 112060.6484 - learning_rate: 0.0010\n",
      "Epoch 158/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 7950505472.0000 - mae: 115100.6016 - val_loss: 7704879104.0000 - val_mae: 112405.8359 - learning_rate: 0.0010\n",
      "Epoch 159/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 7936196608.0000 - mae: 115053.4688 - val_loss: 7678569472.0000 - val_mae: 111913.4141 - learning_rate: 0.0010\n",
      "Epoch 160/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7928530432.0000 - mae: 114824.3203 - val_loss: 7678406656.0000 - val_mae: 112019.0078 - learning_rate: 0.0010\n",
      "Epoch 161/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 7912866304.0000 - mae: 114761.8125 - val_loss: 7671241216.0000 - val_mae: 111971.3359 - learning_rate: 0.0010\n",
      "Epoch 162/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 7896454144.0000 - mae: 114456.5469 - val_loss: 7666437632.0000 - val_mae: 111856.3594 - learning_rate: 0.0010\n",
      "Epoch 163/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 7903077888.0000 - mae: 114576.0000 - val_loss: 7669611008.0000 - val_mae: 111942.7578 - learning_rate: 0.0010\n",
      "Epoch 164/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 7887003648.0000 - mae: 114363.9375 - val_loss: 7657022976.0000 - val_mae: 111700.6953 - learning_rate: 0.0010\n",
      "Epoch 165/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 7892585984.0000 - mae: 114499.7578 - val_loss: 7648665088.0000 - val_mae: 111690.2812 - learning_rate: 0.0010\n",
      "Epoch 166/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 7869649920.0000 - mae: 114120.8359 - val_loss: 7645379584.0000 - val_mae: 111658.2422 - learning_rate: 0.0010\n",
      "Epoch 167/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 7861561344.0000 - mae: 114112.5703 - val_loss: 7647979008.0000 - val_mae: 111871.4766 - learning_rate: 0.0010\n",
      "Epoch 168/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 7845949440.0000 - mae: 113847.3594 - val_loss: 7631520768.0000 - val_mae: 111632.9297 - learning_rate: 0.0010\n",
      "Epoch 169/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 7844036096.0000 - mae: 113857.9375 - val_loss: 7623997952.0000 - val_mae: 111363.2109 - learning_rate: 0.0010\n",
      "Epoch 170/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 7823264256.0000 - mae: 113575.8203 - val_loss: 7627893248.0000 - val_mae: 111540.8359 - learning_rate: 0.0010\n",
      "Epoch 171/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7808318464.0000 - mae: 113493.2734 - val_loss: 7612710912.0000 - val_mae: 111387.4844 - learning_rate: 0.0010\n",
      "Epoch 172/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7828194304.0000 - mae: 113738.2188 - val_loss: 7591817728.0000 - val_mae: 111026.5547 - learning_rate: 0.0010\n",
      "Epoch 173/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 7798113280.0000 - mae: 113305.7734 - val_loss: 7588390400.0000 - val_mae: 110999.6484 - learning_rate: 0.0010\n",
      "Epoch 174/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7797849088.0000 - mae: 113326.2578 - val_loss: 7585702912.0000 - val_mae: 111028.1875 - learning_rate: 0.0010\n",
      "Epoch 175/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7788919296.0000 - mae: 113261.6797 - val_loss: 7586689536.0000 - val_mae: 111095.5312 - learning_rate: 0.0010\n",
      "Epoch 176/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 7777071104.0000 - mae: 113109.6719 - val_loss: 7573190144.0000 - val_mae: 110905.5156 - learning_rate: 0.0010\n",
      "Epoch 177/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 7777601024.0000 - mae: 113104.9844 - val_loss: 7564063744.0000 - val_mae: 110864.4141 - learning_rate: 0.0010\n",
      "Epoch 178/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7759623680.0000 - mae: 112775.3438 - val_loss: 7570833920.0000 - val_mae: 110909.4766 - learning_rate: 0.0010\n",
      "Epoch 179/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 7752328192.0000 - mae: 112868.1250 - val_loss: 7548545536.0000 - val_mae: 110673.2891 - learning_rate: 0.0010\n",
      "Epoch 180/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 7745177088.0000 - mae: 112784.8438 - val_loss: 7555110400.0000 - val_mae: 110828.8359 - learning_rate: 0.0010\n",
      "Epoch 181/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7738424320.0000 - mae: 112666.6406 - val_loss: 7538642432.0000 - val_mae: 110446.8438 - learning_rate: 0.0010\n",
      "Epoch 182/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 7738749952.0000 - mae: 112638.3516 - val_loss: 7532662784.0000 - val_mae: 110347.2031 - learning_rate: 0.0010\n",
      "Epoch 183/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 7720111104.0000 - mae: 112380.1016 - val_loss: 7536468480.0000 - val_mae: 110513.6094 - learning_rate: 0.0010\n",
      "Epoch 184/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7719265280.0000 - mae: 112339.7656 - val_loss: 7538791936.0000 - val_mae: 110577.6641 - learning_rate: 0.0010\n",
      "Epoch 185/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7708422656.0000 - mae: 112289.3281 - val_loss: 7518433792.0000 - val_mae: 110306.4219 - learning_rate: 0.0010\n",
      "Epoch 186/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 7699182080.0000 - mae: 112197.1328 - val_loss: 7517190144.0000 - val_mae: 110276.7734 - learning_rate: 0.0010\n",
      "Epoch 187/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 7689691648.0000 - mae: 112039.8672 - val_loss: 7526808576.0000 - val_mae: 110609.4375 - learning_rate: 0.0010\n",
      "Epoch 188/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7674321920.0000 - mae: 111907.1406 - val_loss: 7502851584.0000 - val_mae: 110219.0703 - learning_rate: 0.0010\n",
      "Epoch 189/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7662890496.0000 - mae: 111745.4844 - val_loss: 7519305728.0000 - val_mae: 110397.1562 - learning_rate: 0.0010\n",
      "Epoch 190/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 7657298432.0000 - mae: 111624.2188 - val_loss: 7521030656.0000 - val_mae: 110626.9922 - learning_rate: 0.0010\n",
      "Epoch 191/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7647183360.0000 - mae: 111681.3516 - val_loss: 7510901760.0000 - val_mae: 110591.1016 - learning_rate: 0.0010\n",
      "Epoch 192/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7669605888.0000 - mae: 111977.8359 - val_loss: 7504663040.0000 - val_mae: 110124.3672 - learning_rate: 0.0010\n",
      "Epoch 193/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7647420416.0000 - mae: 111638.7422 - val_loss: 7491038720.0000 - val_mae: 110060.6562 - learning_rate: 0.0010\n",
      "Epoch 194/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7628729856.0000 - mae: 111394.3047 - val_loss: 7516325888.0000 - val_mae: 110491.2422 - learning_rate: 0.0010\n",
      "Epoch 195/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7621457408.0000 - mae: 111343.5312 - val_loss: 7498607616.0000 - val_mae: 110360.9531 - learning_rate: 0.0010\n",
      "Epoch 196/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 7627925504.0000 - mae: 111376.0312 - val_loss: 7471749632.0000 - val_mae: 109808.7188 - learning_rate: 0.0010\n",
      "Epoch 197/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 7607990272.0000 - mae: 111177.5156 - val_loss: 7476499968.0000 - val_mae: 110048.0938 - learning_rate: 0.0010\n",
      "Epoch 198/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7603875840.0000 - mae: 111049.1797 - val_loss: 7470085120.0000 - val_mae: 110032.3125 - learning_rate: 0.0010\n",
      "Epoch 199/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7600321536.0000 - mae: 111158.7344 - val_loss: 7458390016.0000 - val_mae: 109817.8203 - learning_rate: 0.0010\n",
      "Epoch 200/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7602669056.0000 - mae: 111245.9141 - val_loss: 7481106944.0000 - val_mae: 110095.2969 - learning_rate: 0.0010\n",
      "Epoch 201/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7578261504.0000 - mae: 110814.7656 - val_loss: 7454349312.0000 - val_mae: 109641.7891 - learning_rate: 0.0010\n",
      "Epoch 202/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 7573370368.0000 - mae: 110769.6250 - val_loss: 7450473984.0000 - val_mae: 109643.1406 - learning_rate: 0.0010\n",
      "Epoch 203/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7567525376.0000 - mae: 110692.0938 - val_loss: 7443859456.0000 - val_mae: 109670.4688 - learning_rate: 0.0010\n",
      "Epoch 204/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7565345280.0000 - mae: 110707.1875 - val_loss: 7453710336.0000 - val_mae: 109820.1719 - learning_rate: 0.0010\n",
      "Epoch 205/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 7564700672.0000 - mae: 110780.4453 - val_loss: 7448193024.0000 - val_mae: 109844.5312 - learning_rate: 0.0010\n",
      "Epoch 206/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 7546716672.0000 - mae: 110488.3516 - val_loss: 7423506944.0000 - val_mae: 109297.7891 - learning_rate: 0.0010\n",
      "Epoch 207/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7542716416.0000 - mae: 110516.0781 - val_loss: 7426780160.0000 - val_mae: 109339.4688 - learning_rate: 0.0010\n",
      "Epoch 208/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7532418560.0000 - mae: 110271.5078 - val_loss: 7419681792.0000 - val_mae: 109591.3672 - learning_rate: 0.0010\n",
      "Epoch 209/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 7527137792.0000 - mae: 110200.1562 - val_loss: 7410839040.0000 - val_mae: 109306.2344 - learning_rate: 0.0010\n",
      "Epoch 210/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7524091392.0000 - mae: 110214.1094 - val_loss: 7408030720.0000 - val_mae: 109178.1875 - learning_rate: 0.0010\n",
      "Epoch 211/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7515013632.0000 - mae: 110199.0234 - val_loss: 7405307392.0000 - val_mae: 109141.1250 - learning_rate: 0.0010\n",
      "Epoch 212/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 7502147072.0000 - mae: 109949.7891 - val_loss: 7449631744.0000 - val_mae: 109958.6406 - learning_rate: 0.0010\n",
      "Epoch 213/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 7499232256.0000 - mae: 110040.6875 - val_loss: 7393679360.0000 - val_mae: 108999.7188 - learning_rate: 0.0010\n",
      "Epoch 214/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7494638080.0000 - mae: 109979.5312 - val_loss: 7418145280.0000 - val_mae: 109519.1484 - learning_rate: 0.0010\n",
      "Epoch 215/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 7494958592.0000 - mae: 109931.4297 - val_loss: 7401759744.0000 - val_mae: 109219.1250 - learning_rate: 0.0010\n",
      "Epoch 216/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7478598144.0000 - mae: 109753.1250 - val_loss: 7383561728.0000 - val_mae: 108925.9453 - learning_rate: 0.0010\n",
      "Epoch 217/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7466108416.0000 - mae: 109622.8672 - val_loss: 7385832448.0000 - val_mae: 109297.4531 - learning_rate: 0.0010\n",
      "Epoch 218/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7461558272.0000 - mae: 109559.7031 - val_loss: 7377433600.0000 - val_mae: 108870.0000 - learning_rate: 0.0010\n",
      "Epoch 219/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 7456275968.0000 - mae: 109460.6562 - val_loss: 7372637696.0000 - val_mae: 108767.3672 - learning_rate: 0.0010\n",
      "Epoch 220/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7453372928.0000 - mae: 109606.9688 - val_loss: 7392367104.0000 - val_mae: 109434.3594 - learning_rate: 0.0010\n",
      "Epoch 221/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7440616448.0000 - mae: 109274.4844 - val_loss: 7360359936.0000 - val_mae: 108623.8672 - learning_rate: 0.0010\n",
      "Epoch 222/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7446039552.0000 - mae: 109317.5156 - val_loss: 7388719616.0000 - val_mae: 109232.8750 - learning_rate: 0.0010\n",
      "Epoch 223/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 7415236608.0000 - mae: 109097.0469 - val_loss: 7379815424.0000 - val_mae: 109177.2969 - learning_rate: 0.0010\n",
      "Epoch 224/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 7422699520.0000 - mae: 109128.9844 - val_loss: 7351969280.0000 - val_mae: 108663.1641 - learning_rate: 0.0010\n",
      "Epoch 225/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 7393779200.0000 - mae: 108881.3359 - val_loss: 7340144640.0000 - val_mae: 108478.8438 - learning_rate: 0.0010\n",
      "Epoch 226/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 7389868032.0000 - mae: 108979.3359 - val_loss: 7381508608.0000 - val_mae: 109180.6797 - learning_rate: 0.0010\n",
      "Epoch 227/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 7385790976.0000 - mae: 108779.6328 - val_loss: 7343778816.0000 - val_mae: 108763.8828 - learning_rate: 0.0010\n",
      "Epoch 228/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 7380856832.0000 - mae: 108600.9688 - val_loss: 7341607424.0000 - val_mae: 108679.9062 - learning_rate: 0.0010\n",
      "Epoch 229/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 7393587712.0000 - mae: 108869.1719 - val_loss: 7336683008.0000 - val_mae: 108330.9375 - learning_rate: 0.0010\n",
      "Epoch 230/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 7368819712.0000 - mae: 108558.3047 - val_loss: 7377652224.0000 - val_mae: 109101.3203 - learning_rate: 0.0010\n",
      "Epoch 231/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 7364983808.0000 - mae: 108698.9688 - val_loss: 7369071616.0000 - val_mae: 109000.8906 - learning_rate: 0.0010\n",
      "Epoch 232/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 7357053440.0000 - mae: 108438.6172 - val_loss: 7341522944.0000 - val_mae: 108589.8281 - learning_rate: 0.0010\n",
      "Epoch 233/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7350468608.0000 - mae: 108317.9766 - val_loss: 7322522624.0000 - val_mae: 108161.2812 - learning_rate: 0.0010\n",
      "Epoch 234/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7362027520.0000 - mae: 108675.5703 - val_loss: 7319981056.0000 - val_mae: 108294.4375 - learning_rate: 0.0010\n",
      "Epoch 235/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7332224000.0000 - mae: 108189.3594 - val_loss: 7326601728.0000 - val_mae: 108654.2031 - learning_rate: 0.0010\n",
      "Epoch 236/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7333261312.0000 - mae: 108214.5156 - val_loss: 7326045184.0000 - val_mae: 108584.4141 - learning_rate: 0.0010\n",
      "Epoch 237/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 7322456064.0000 - mae: 108025.0938 - val_loss: 7314341888.0000 - val_mae: 108166.4844 - learning_rate: 0.0010\n",
      "Epoch 238/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 7316147200.0000 - mae: 107926.9609 - val_loss: 7324020736.0000 - val_mae: 108401.2188 - learning_rate: 0.0010\n",
      "Epoch 239/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7313186304.0000 - mae: 108004.1875 - val_loss: 7344822272.0000 - val_mae: 108820.0312 - learning_rate: 0.0010\n",
      "Epoch 240/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7304390144.0000 - mae: 107899.5781 - val_loss: 7303606272.0000 - val_mae: 108075.0547 - learning_rate: 0.0010\n",
      "Epoch 241/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7302765056.0000 - mae: 107984.9766 - val_loss: 7312545792.0000 - val_mae: 108300.9453 - learning_rate: 0.0010\n",
      "Epoch 242/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7287634944.0000 - mae: 107692.9531 - val_loss: 7338717696.0000 - val_mae: 109023.9609 - learning_rate: 0.0010\n",
      "Epoch 243/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7288368640.0000 - mae: 107782.6719 - val_loss: 7291238912.0000 - val_mae: 107958.4453 - learning_rate: 0.0010\n",
      "Epoch 244/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 7271718400.0000 - mae: 107574.7344 - val_loss: 7299858432.0000 - val_mae: 107935.4922 - learning_rate: 0.0010\n",
      "Epoch 245/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7259724288.0000 - mae: 107470.9375 - val_loss: 7287320064.0000 - val_mae: 108061.5938 - learning_rate: 0.0010\n",
      "Epoch 246/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 7262974464.0000 - mae: 107357.3906 - val_loss: 7281339392.0000 - val_mae: 107878.1719 - learning_rate: 0.0010\n",
      "Epoch 247/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 7248864768.0000 - mae: 107382.8672 - val_loss: 7290421760.0000 - val_mae: 108046.9609 - learning_rate: 0.0010\n",
      "Epoch 248/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 7261838848.0000 - mae: 107562.3984 - val_loss: 7304518144.0000 - val_mae: 108156.6094 - learning_rate: 0.0010\n",
      "Epoch 249/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 7254313472.0000 - mae: 107365.6797 - val_loss: 7289251328.0000 - val_mae: 107757.2969 - learning_rate: 0.0010\n",
      "Epoch 250/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 7237893120.0000 - mae: 107138.2266 - val_loss: 7275873792.0000 - val_mae: 107809.0781 - learning_rate: 0.0010\n",
      "Epoch 251/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7221325312.0000 - mae: 106938.6172 - val_loss: 7284431360.0000 - val_mae: 108148.3047 - learning_rate: 0.0010\n",
      "Epoch 252/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7229796864.0000 - mae: 107039.8516 - val_loss: 7266396672.0000 - val_mae: 107681.2344 - learning_rate: 0.0010\n",
      "Epoch 253/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 7207900160.0000 - mae: 106794.0156 - val_loss: 7269147136.0000 - val_mae: 107645.8828 - learning_rate: 0.0010\n",
      "Epoch 254/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 7206202368.0000 - mae: 107007.1875 - val_loss: 7280104960.0000 - val_mae: 108070.1094 - learning_rate: 0.0010\n",
      "Epoch 255/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 7206061056.0000 - mae: 106782.2734 - val_loss: 7314531840.0000 - val_mae: 108388.4609 - learning_rate: 0.0010\n",
      "Epoch 256/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 7185226240.0000 - mae: 106673.7969 - val_loss: 7316533760.0000 - val_mae: 108744.0312 - learning_rate: 0.0010\n",
      "Epoch 257/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 7212905472.0000 - mae: 106985.3047 - val_loss: 7269328896.0000 - val_mae: 107577.9844 - learning_rate: 0.0010\n",
      "Epoch 258/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 7181544960.0000 - mae: 106471.5469 - val_loss: 7263966720.0000 - val_mae: 107499.7500 - learning_rate: 0.0010\n",
      "Epoch 259/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7174384128.0000 - mae: 106486.4141 - val_loss: 7249846784.0000 - val_mae: 107447.8516 - learning_rate: 0.0010\n",
      "Epoch 260/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 7188332032.0000 - mae: 106596.7578 - val_loss: 7264341504.0000 - val_mae: 107815.1250 - learning_rate: 0.0010\n",
      "Epoch 261/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7178156032.0000 - mae: 106683.6094 - val_loss: 7254792192.0000 - val_mae: 107631.1406 - learning_rate: 0.0010\n",
      "Epoch 262/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 7164158464.0000 - mae: 106445.6094 - val_loss: 7237777408.0000 - val_mae: 107391.1250 - learning_rate: 0.0010\n",
      "Epoch 263/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 7156824064.0000 - mae: 106244.4375 - val_loss: 7240875520.0000 - val_mae: 107482.0391 - learning_rate: 0.0010\n",
      "Epoch 264/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 7153759744.0000 - mae: 106280.1875 - val_loss: 7240210944.0000 - val_mae: 107642.0000 - learning_rate: 0.0010\n",
      "Epoch 265/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7135693824.0000 - mae: 106038.6953 - val_loss: 7290238976.0000 - val_mae: 108544.3828 - learning_rate: 0.0010\n",
      "Epoch 266/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7149847040.0000 - mae: 106296.4844 - val_loss: 7243307520.0000 - val_mae: 107347.1172 - learning_rate: 0.0010\n",
      "Epoch 267/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 7139142656.0000 - mae: 106074.8359 - val_loss: 7228793344.0000 - val_mae: 107393.3672 - learning_rate: 0.0010\n",
      "Epoch 268/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 7126105088.0000 - mae: 105987.3438 - val_loss: 7223366656.0000 - val_mae: 107203.2969 - learning_rate: 0.0010\n",
      "Epoch 269/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 7110871040.0000 - mae: 105777.8984 - val_loss: 7228643840.0000 - val_mae: 107331.2656 - learning_rate: 0.0010\n",
      "Epoch 270/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 7124523008.0000 - mae: 106048.0547 - val_loss: 7232147456.0000 - val_mae: 107474.1484 - learning_rate: 0.0010\n",
      "Epoch 271/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 7118774272.0000 - mae: 105956.6953 - val_loss: 7252439040.0000 - val_mae: 107689.3281 - learning_rate: 0.0010\n",
      "Epoch 272/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 7116668416.0000 - mae: 105871.5078 - val_loss: 7246266368.0000 - val_mae: 107590.9141 - learning_rate: 0.0010\n",
      "Epoch 273/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 7092593664.0000 - mae: 105631.0234 - val_loss: 7224297984.0000 - val_mae: 107315.1875 - learning_rate: 0.0010\n",
      "Epoch 274/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 7097755648.0000 - mae: 105653.5703 - val_loss: 7223280640.0000 - val_mae: 107138.1719 - learning_rate: 0.0010\n",
      "Epoch 275/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 7087270912.0000 - mae: 105488.9062 - val_loss: 7234059264.0000 - val_mae: 107531.3359 - learning_rate: 0.0010\n",
      "Epoch 276/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 7090107392.0000 - mae: 105519.9922 - val_loss: 7212612608.0000 - val_mae: 107120.8984 - learning_rate: 0.0010\n",
      "Epoch 277/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 7075864064.0000 - mae: 105383.8438 - val_loss: 7241384960.0000 - val_mae: 107474.7266 - learning_rate: 0.0010\n",
      "Epoch 278/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 7069148672.0000 - mae: 105278.2812 - val_loss: 7213854208.0000 - val_mae: 107164.6484 - learning_rate: 0.0010\n",
      "Epoch 279/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 7063367168.0000 - mae: 105274.8203 - val_loss: 7217531392.0000 - val_mae: 107179.0391 - learning_rate: 0.0010\n",
      "Epoch 280/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 7054673408.0000 - mae: 105260.3047 - val_loss: 7218896384.0000 - val_mae: 107225.0391 - learning_rate: 0.0010\n",
      "Epoch 281/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 7061910528.0000 - mae: 105324.5703 - val_loss: 7233187328.0000 - val_mae: 107516.2031 - learning_rate: 0.0010\n",
      "Epoch 282/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 7051311104.0000 - mae: 105163.0781 - val_loss: 7217658880.0000 - val_mae: 107219.1562 - learning_rate: 0.0010\n",
      "Epoch 283/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7049653760.0000 - mae: 105102.3516 - val_loss: 7220570112.0000 - val_mae: 107253.8672 - learning_rate: 0.0010\n",
      "Epoch 284/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 7053881856.0000 - mae: 105243.9141 - val_loss: 7208331264.0000 - val_mae: 107087.1406 - learning_rate: 0.0010\n",
      "Epoch 285/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 7038233088.0000 - mae: 105028.1328 - val_loss: 7202999808.0000 - val_mae: 106986.4375 - learning_rate: 0.0010\n",
      "Epoch 286/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 7036883456.0000 - mae: 104965.1562 - val_loss: 7192809472.0000 - val_mae: 106920.3594 - learning_rate: 0.0010\n",
      "Epoch 287/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 7026441216.0000 - mae: 104902.2812 - val_loss: 7188903936.0000 - val_mae: 106844.3672 - learning_rate: 0.0010\n",
      "Epoch 288/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 7034444800.0000 - mae: 104938.5234 - val_loss: 7200466944.0000 - val_mae: 107154.3438 - learning_rate: 0.0010\n",
      "Epoch 289/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 7011236864.0000 - mae: 104648.5703 - val_loss: 7206313472.0000 - val_mae: 107254.6094 - learning_rate: 0.0010\n",
      "Epoch 290/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 7028941312.0000 - mae: 104843.3203 - val_loss: 7184280064.0000 - val_mae: 106685.0312 - learning_rate: 0.0010\n",
      "Epoch 291/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 7015033344.0000 - mae: 104781.2109 - val_loss: 7207088640.0000 - val_mae: 107138.0391 - learning_rate: 0.0010\n",
      "Epoch 292/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 6994844672.0000 - mae: 104567.9766 - val_loss: 7195501056.0000 - val_mae: 106915.6875 - learning_rate: 0.0010\n",
      "Epoch 293/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6992220672.0000 - mae: 104445.6016 - val_loss: 7184919040.0000 - val_mae: 106838.7578 - learning_rate: 0.0010\n",
      "Epoch 294/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6995949056.0000 - mae: 104487.4688 - val_loss: 7168695808.0000 - val_mae: 106647.9609 - learning_rate: 0.0010\n",
      "Epoch 295/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 6985921024.0000 - mae: 104442.3125 - val_loss: 7167228416.0000 - val_mae: 106553.6953 - learning_rate: 0.0010\n",
      "Epoch 296/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6981337600.0000 - mae: 104327.4609 - val_loss: 7186000896.0000 - val_mae: 106865.0625 - learning_rate: 0.0010\n",
      "Epoch 297/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 6976954880.0000 - mae: 104365.2969 - val_loss: 7193455616.0000 - val_mae: 106896.6406 - learning_rate: 0.0010\n",
      "Epoch 298/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6975141888.0000 - mae: 104375.5234 - val_loss: 7158150656.0000 - val_mae: 106426.6875 - learning_rate: 0.0010\n",
      "Epoch 299/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6972530176.0000 - mae: 104289.1797 - val_loss: 7167008256.0000 - val_mae: 106616.8438 - learning_rate: 0.0010\n",
      "Epoch 300/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 6962552832.0000 - mae: 104135.5234 - val_loss: 7152101376.0000 - val_mae: 106550.9531 - learning_rate: 0.0010\n",
      "Epoch 301/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 6956803584.0000 - mae: 104109.5391 - val_loss: 7214692864.0000 - val_mae: 107207.4062 - learning_rate: 0.0010\n",
      "Epoch 302/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 6962322432.0000 - mae: 104239.6797 - val_loss: 7155997696.0000 - val_mae: 106304.4219 - learning_rate: 0.0010\n",
      "Epoch 303/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 6945185280.0000 - mae: 104079.3359 - val_loss: 7152960000.0000 - val_mae: 106428.7344 - learning_rate: 0.0010\n",
      "Epoch 304/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6932538368.0000 - mae: 103886.3906 - val_loss: 7152460800.0000 - val_mae: 106540.3516 - learning_rate: 0.0010\n",
      "Epoch 305/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6945629696.0000 - mae: 104077.1016 - val_loss: 7148932608.0000 - val_mae: 106403.6875 - learning_rate: 0.0010\n",
      "Epoch 306/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6929650688.0000 - mae: 103735.2734 - val_loss: 7133658624.0000 - val_mae: 106266.4844 - learning_rate: 0.0010\n",
      "Epoch 307/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 6937053184.0000 - mae: 103971.0625 - val_loss: 7147338752.0000 - val_mae: 106192.4688 - learning_rate: 0.0010\n",
      "Epoch 308/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 6916900352.0000 - mae: 103636.7578 - val_loss: 7141555712.0000 - val_mae: 106250.0703 - learning_rate: 0.0010\n",
      "Epoch 309/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6915074560.0000 - mae: 103701.6797 - val_loss: 7138147328.0000 - val_mae: 106079.2656 - learning_rate: 0.0010\n",
      "Epoch 310/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6925853184.0000 - mae: 103790.1094 - val_loss: 7131572224.0000 - val_mae: 106315.7188 - learning_rate: 0.0010\n",
      "Epoch 311/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6902731776.0000 - mae: 103606.6094 - val_loss: 7157664256.0000 - val_mae: 106524.0938 - learning_rate: 0.0010\n",
      "Epoch 312/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6901042688.0000 - mae: 103519.7266 - val_loss: 7127997440.0000 - val_mae: 106076.6641 - learning_rate: 0.0010\n",
      "Epoch 313/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6908636672.0000 - mae: 103618.5547 - val_loss: 7139940352.0000 - val_mae: 106377.0234 - learning_rate: 0.0010\n",
      "Epoch 314/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6888738304.0000 - mae: 103404.2031 - val_loss: 7136159744.0000 - val_mae: 106410.1484 - learning_rate: 0.0010\n",
      "Epoch 315/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6886238208.0000 - mae: 103374.0859 - val_loss: 7142173184.0000 - val_mae: 106486.6250 - learning_rate: 0.0010\n",
      "Epoch 316/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 6878287360.0000 - mae: 103200.9922 - val_loss: 7137536512.0000 - val_mae: 106477.2578 - learning_rate: 0.0010\n",
      "Epoch 317/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 6872263168.0000 - mae: 103248.5234 - val_loss: 7117110784.0000 - val_mae: 106035.8594 - learning_rate: 0.0010\n",
      "Epoch 318/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 6871884288.0000 - mae: 103321.6484 - val_loss: 7112028672.0000 - val_mae: 105905.3984 - learning_rate: 0.0010\n",
      "Epoch 319/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 6867148288.0000 - mae: 103207.7656 - val_loss: 7122023936.0000 - val_mae: 106400.1094 - learning_rate: 0.0010\n",
      "Epoch 320/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6870038528.0000 - mae: 103179.5859 - val_loss: 7144507904.0000 - val_mae: 106645.6250 - learning_rate: 0.0010\n",
      "Epoch 321/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6821542400.0000 - mae: 102992.7344 - val_loss: 7165278720.0000 - val_mae: 106870.6953 - learning_rate: 0.0010\n",
      "Epoch 322/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 6858335232.0000 - mae: 103078.8594 - val_loss: 7110187520.0000 - val_mae: 106040.7422 - learning_rate: 0.0010\n",
      "Epoch 323/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6867592192.0000 - mae: 103275.5156 - val_loss: 7187445248.0000 - val_mae: 106875.6641 - learning_rate: 0.0010\n",
      "Epoch 324/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6854734848.0000 - mae: 103181.1484 - val_loss: 7100560896.0000 - val_mae: 106065.4453 - learning_rate: 0.0010\n",
      "Epoch 325/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 6837627904.0000 - mae: 102838.8203 - val_loss: 7118661632.0000 - val_mae: 106269.1875 - learning_rate: 0.0010\n",
      "Epoch 326/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6830417920.0000 - mae: 102768.6953 - val_loss: 7120155136.0000 - val_mae: 106177.5469 - learning_rate: 0.0010\n",
      "Epoch 327/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6845662208.0000 - mae: 103069.4609 - val_loss: 7107136000.0000 - val_mae: 105788.6094 - learning_rate: 0.0010\n",
      "Epoch 328/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6835247616.0000 - mae: 102890.3594 - val_loss: 7129067520.0000 - val_mae: 106122.2812 - learning_rate: 0.0010\n",
      "Epoch 329/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 6829442560.0000 - mae: 102829.2812 - val_loss: 7110239744.0000 - val_mae: 105999.0781 - learning_rate: 0.0010\n",
      "Epoch 330/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6820825600.0000 - mae: 102683.3516 - val_loss: 7106198016.0000 - val_mae: 105891.2812 - learning_rate: 0.0010\n",
      "Epoch 331/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 6823920128.0000 - mae: 102764.9141 - val_loss: 7119240192.0000 - val_mae: 105988.2578 - learning_rate: 0.0010\n",
      "Epoch 332/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 6811981824.0000 - mae: 102551.0391 - val_loss: 7122158080.0000 - val_mae: 106113.8125 - learning_rate: 0.0010\n",
      "Epoch 333/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6830384128.0000 - mae: 102842.0156 - val_loss: 7092844032.0000 - val_mae: 106030.4219 - learning_rate: 0.0010\n",
      "Epoch 334/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6800135168.0000 - mae: 102376.1328 - val_loss: 7102814208.0000 - val_mae: 106106.4688 - learning_rate: 0.0010\n",
      "Epoch 335/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6801125376.0000 - mae: 102391.2422 - val_loss: 7117639168.0000 - val_mae: 106160.3828 - learning_rate: 0.0010\n",
      "Epoch 336/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6799237120.0000 - mae: 102493.6875 - val_loss: 7079680000.0000 - val_mae: 105738.2812 - learning_rate: 0.0010\n",
      "Epoch 337/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6788621824.0000 - mae: 102344.5469 - val_loss: 7091733504.0000 - val_mae: 106016.3984 - learning_rate: 0.0010\n",
      "Epoch 338/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6808882688.0000 - mae: 102556.1406 - val_loss: 7086687744.0000 - val_mae: 105770.8984 - learning_rate: 0.0010\n",
      "Epoch 339/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 6787021312.0000 - mae: 102364.5859 - val_loss: 7085028352.0000 - val_mae: 105724.3828 - learning_rate: 0.0010\n",
      "Epoch 340/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 6777184768.0000 - mae: 102163.4531 - val_loss: 7109862912.0000 - val_mae: 105937.4453 - learning_rate: 0.0010\n",
      "Epoch 341/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 6791717376.0000 - mae: 102473.2422 - val_loss: 7085927936.0000 - val_mae: 105589.3984 - learning_rate: 0.0010\n",
      "Epoch 342/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 6780376064.0000 - mae: 102240.9453 - val_loss: 7102982656.0000 - val_mae: 105993.9531 - learning_rate: 0.0010\n",
      "Epoch 343/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 6760343040.0000 - mae: 102088.6406 - val_loss: 7080479744.0000 - val_mae: 105611.6719 - learning_rate: 0.0010\n",
      "Epoch 344/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 6767755776.0000 - mae: 102209.2500 - val_loss: 7101164032.0000 - val_mae: 106036.7188 - learning_rate: 0.0010\n",
      "Epoch 345/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 6765714944.0000 - mae: 102181.1953 - val_loss: 7064216576.0000 - val_mae: 105606.1172 - learning_rate: 0.0010\n",
      "Epoch 346/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 6750208512.0000 - mae: 101991.0000 - val_loss: 7097138176.0000 - val_mae: 105858.5469 - learning_rate: 0.0010\n",
      "Epoch 347/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 6761607680.0000 - mae: 102116.6016 - val_loss: 7079072256.0000 - val_mae: 105728.3359 - learning_rate: 0.0010\n",
      "Epoch 348/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 6758961664.0000 - mae: 102008.5547 - val_loss: 7061398016.0000 - val_mae: 105359.1328 - learning_rate: 0.0010\n",
      "Epoch 349/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 6748840448.0000 - mae: 101929.1250 - val_loss: 7067447296.0000 - val_mae: 105587.7500 - learning_rate: 0.0010\n",
      "Epoch 350/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 6744494592.0000 - mae: 102030.7344 - val_loss: 7063026176.0000 - val_mae: 105475.3125 - learning_rate: 0.0010\n",
      "Epoch 351/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6748298752.0000 - mae: 101946.8750 - val_loss: 7060156416.0000 - val_mae: 105448.2422 - learning_rate: 0.0010\n",
      "Epoch 352/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6740336640.0000 - mae: 101865.4141 - val_loss: 7080271872.0000 - val_mae: 105736.5781 - learning_rate: 0.0010\n",
      "Epoch 353/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6740764160.0000 - mae: 101942.8672 - val_loss: 7059715584.0000 - val_mae: 105401.6562 - learning_rate: 0.0010\n",
      "Epoch 354/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6734766080.0000 - mae: 101720.0078 - val_loss: 7050653184.0000 - val_mae: 105314.1406 - learning_rate: 0.0010\n",
      "Epoch 355/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 6737275904.0000 - mae: 101713.4688 - val_loss: 7069843456.0000 - val_mae: 105593.0547 - learning_rate: 0.0010\n",
      "Epoch 356/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 6743091712.0000 - mae: 101812.5312 - val_loss: 7061636096.0000 - val_mae: 105305.9922 - learning_rate: 0.0010\n",
      "Epoch 357/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 6720533504.0000 - mae: 101526.9844 - val_loss: 7049878528.0000 - val_mae: 105354.0312 - learning_rate: 0.0010\n",
      "Epoch 358/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 6712980992.0000 - mae: 101516.2344 - val_loss: 7044870656.0000 - val_mae: 105284.6016 - learning_rate: 0.0010\n",
      "Epoch 359/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6743495680.0000 - mae: 101861.4922 - val_loss: 7059361792.0000 - val_mae: 105425.9844 - learning_rate: 0.0010\n",
      "Epoch 360/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 6732726784.0000 - mae: 101742.8594 - val_loss: 7047777280.0000 - val_mae: 105266.9609 - learning_rate: 0.0010\n",
      "Epoch 361/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 6716137984.0000 - mae: 101501.5625 - val_loss: 7113048064.0000 - val_mae: 106021.1250 - learning_rate: 0.0010\n",
      "Epoch 362/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 6721735680.0000 - mae: 101750.3359 - val_loss: 7070609920.0000 - val_mae: 105517.3672 - learning_rate: 0.0010\n",
      "Epoch 363/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6700910080.0000 - mae: 101362.9609 - val_loss: 7050887168.0000 - val_mae: 105394.4219 - learning_rate: 0.0010\n",
      "Epoch 364/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 6704467968.0000 - mae: 101416.5469 - val_loss: 7047473664.0000 - val_mae: 105215.9375 - learning_rate: 0.0010\n",
      "Epoch 365/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 6682596864.0000 - mae: 101161.0391 - val_loss: 7097430528.0000 - val_mae: 105845.6172 - learning_rate: 0.0010\n",
      "Epoch 366/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 6699515904.0000 - mae: 101370.0547 - val_loss: 7047474176.0000 - val_mae: 105502.8984 - learning_rate: 0.0010\n",
      "Epoch 367/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 6711548928.0000 - mae: 101536.3125 - val_loss: 7065733120.0000 - val_mae: 105661.8828 - learning_rate: 0.0010\n",
      "Epoch 368/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 6702218752.0000 - mae: 101454.0625 - val_loss: 7048967168.0000 - val_mae: 105086.5625 - learning_rate: 0.0010\n",
      "Epoch 369/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 6665781248.0000 - mae: 100948.3906 - val_loss: 7051557888.0000 - val_mae: 105249.6875 - learning_rate: 5.0000e-04\n",
      "Epoch 370/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 6673075200.0000 - mae: 101026.6953 - val_loss: 7046885376.0000 - val_mae: 105329.2031 - learning_rate: 5.0000e-04\n",
      "Epoch 371/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 6671001088.0000 - mae: 101025.9531 - val_loss: 7034181632.0000 - val_mae: 104967.3203 - learning_rate: 5.0000e-04\n",
      "Epoch 372/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 6659457536.0000 - mae: 100853.9922 - val_loss: 7045537792.0000 - val_mae: 105253.7891 - learning_rate: 5.0000e-04\n",
      "Epoch 373/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 6672314880.0000 - mae: 101093.4609 - val_loss: 7042621952.0000 - val_mae: 105148.7578 - learning_rate: 5.0000e-04\n",
      "Epoch 374/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 6656326144.0000 - mae: 100886.8906 - val_loss: 7032854016.0000 - val_mae: 105295.1953 - learning_rate: 5.0000e-04\n",
      "Epoch 375/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 6653527040.0000 - mae: 100871.9609 - val_loss: 7046799360.0000 - val_mae: 105512.6797 - learning_rate: 5.0000e-04\n",
      "Epoch 376/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - loss: 6658622464.0000 - mae: 100902.5078 - val_loss: 7034997760.0000 - val_mae: 105104.9062 - learning_rate: 5.0000e-04\n",
      "Epoch 377/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 6650864128.0000 - mae: 100790.6094 - val_loss: 7034409472.0000 - val_mae: 105036.2500 - learning_rate: 5.0000e-04\n",
      "Epoch 378/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 6653627392.0000 - mae: 100767.5000 - val_loss: 7020715520.0000 - val_mae: 104973.9844 - learning_rate: 5.0000e-04\n",
      "Epoch 379/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 6654937088.0000 - mae: 100825.1484 - val_loss: 7044787712.0000 - val_mae: 105262.1484 - learning_rate: 5.0000e-04\n",
      "Epoch 380/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 6659709440.0000 - mae: 100974.3750 - val_loss: 7026646016.0000 - val_mae: 104968.9531 - learning_rate: 5.0000e-04\n",
      "Epoch 381/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6654518784.0000 - mae: 100762.5625 - val_loss: 7028269056.0000 - val_mae: 105130.2266 - learning_rate: 5.0000e-04\n",
      "Epoch 382/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6657025024.0000 - mae: 100900.3516 - val_loss: 7021556736.0000 - val_mae: 104928.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 383/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6654792192.0000 - mae: 100792.5547 - val_loss: 7035662336.0000 - val_mae: 105381.4531 - learning_rate: 5.0000e-04\n",
      "Epoch 384/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6647937024.0000 - mae: 100714.7031 - val_loss: 7027266048.0000 - val_mae: 105020.0625 - learning_rate: 5.0000e-04\n",
      "Epoch 385/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 6646997504.0000 - mae: 100706.5547 - val_loss: 7016410624.0000 - val_mae: 104901.4141 - learning_rate: 5.0000e-04\n",
      "Epoch 386/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6643055104.0000 - mae: 100707.8984 - val_loss: 7066337792.0000 - val_mae: 105443.6172 - learning_rate: 5.0000e-04\n",
      "Epoch 387/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 6649423360.0000 - mae: 100724.7500 - val_loss: 7028637696.0000 - val_mae: 105043.4062 - learning_rate: 5.0000e-04\n",
      "Epoch 388/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 6635381248.0000 - mae: 100525.4688 - val_loss: 7025143296.0000 - val_mae: 104943.0781 - learning_rate: 5.0000e-04\n",
      "Epoch 389/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 6641069056.0000 - mae: 100620.3828 - val_loss: 7019979264.0000 - val_mae: 105021.8281 - learning_rate: 5.0000e-04\n",
      "Epoch 390/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 6640424448.0000 - mae: 100696.8281 - val_loss: 7027086336.0000 - val_mae: 105009.3438 - learning_rate: 5.0000e-04\n",
      "Epoch 391/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 6638558208.0000 - mae: 100595.1953 - val_loss: 7023200256.0000 - val_mae: 104942.5547 - learning_rate: 5.0000e-04\n",
      "Epoch 392/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 6637136896.0000 - mae: 100674.8516 - val_loss: 7016400384.0000 - val_mae: 104803.4297 - learning_rate: 5.0000e-04\n",
      "Epoch 393/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 6634222080.0000 - mae: 100585.9453 - val_loss: 7015160832.0000 - val_mae: 104867.1641 - learning_rate: 5.0000e-04\n",
      "Epoch 394/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6632161792.0000 - mae: 100538.6719 - val_loss: 7025353728.0000 - val_mae: 105092.2578 - learning_rate: 5.0000e-04\n",
      "Epoch 395/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 6632839168.0000 - mae: 100625.1328 - val_loss: 7019861504.0000 - val_mae: 104876.2500 - learning_rate: 5.0000e-04\n",
      "Epoch 396/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 6630056960.0000 - mae: 100539.4609 - val_loss: 7017494016.0000 - val_mae: 105002.4219 - learning_rate: 5.0000e-04\n",
      "Epoch 397/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6621858816.0000 - mae: 100424.8125 - val_loss: 7017275392.0000 - val_mae: 104922.1250 - learning_rate: 5.0000e-04\n",
      "Epoch 398/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6625786880.0000 - mae: 100467.2500 - val_loss: 7013188608.0000 - val_mae: 104717.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 399/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6620359168.0000 - mae: 100353.6953 - val_loss: 7028802048.0000 - val_mae: 105027.7969 - learning_rate: 5.0000e-04\n",
      "Epoch 400/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 6619535872.0000 - mae: 100387.7656 - val_loss: 7013327872.0000 - val_mae: 104900.8750 - learning_rate: 5.0000e-04\n",
      "Epoch 401/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 6608866304.0000 - mae: 100234.7969 - val_loss: 7007754240.0000 - val_mae: 104677.3594 - learning_rate: 5.0000e-04\n",
      "Epoch 402/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6611447808.0000 - mae: 100263.0703 - val_loss: 7029031424.0000 - val_mae: 105015.1484 - learning_rate: 5.0000e-04\n",
      "Epoch 403/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 6618447360.0000 - mae: 100362.2812 - val_loss: 7009701376.0000 - val_mae: 104854.2734 - learning_rate: 5.0000e-04\n",
      "Epoch 404/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 6619827712.0000 - mae: 100489.4609 - val_loss: 7014112768.0000 - val_mae: 104856.0859 - learning_rate: 5.0000e-04\n",
      "Epoch 405/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 6622078464.0000 - mae: 100449.7812 - val_loss: 7002930688.0000 - val_mae: 104706.7109 - learning_rate: 5.0000e-04\n",
      "Epoch 406/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6613713920.0000 - mae: 100353.1562 - val_loss: 7009504768.0000 - val_mae: 104857.7734 - learning_rate: 5.0000e-04\n",
      "Epoch 407/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 6602872832.0000 - mae: 100171.0938 - val_loss: 7004491264.0000 - val_mae: 104784.5234 - learning_rate: 5.0000e-04\n",
      "Epoch 408/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6611960320.0000 - mae: 100327.4766 - val_loss: 7030129152.0000 - val_mae: 105008.0781 - learning_rate: 5.0000e-04\n",
      "Epoch 409/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 6606112768.0000 - mae: 100248.2812 - val_loss: 7004560896.0000 - val_mae: 104668.2109 - learning_rate: 5.0000e-04\n",
      "Epoch 410/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6601855488.0000 - mae: 100154.2031 - val_loss: 7016259584.0000 - val_mae: 104960.7656 - learning_rate: 5.0000e-04\n",
      "Epoch 411/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6591768064.0000 - mae: 99984.4453 - val_loss: 7003173376.0000 - val_mae: 104874.0781 - learning_rate: 5.0000e-04\n",
      "Epoch 412/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 6597081600.0000 - mae: 100105.2812 - val_loss: 7013367296.0000 - val_mae: 104902.3672 - learning_rate: 5.0000e-04\n",
      "Epoch 413/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 6582667264.0000 - mae: 99958.6328 - val_loss: 7020257792.0000 - val_mae: 104963.2734 - learning_rate: 5.0000e-04\n",
      "Epoch 414/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 6614826496.0000 - mae: 100360.6953 - val_loss: 7002442240.0000 - val_mae: 104703.2031 - learning_rate: 5.0000e-04\n",
      "Epoch 415/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 6590876160.0000 - mae: 99964.6016 - val_loss: 7001595392.0000 - val_mae: 104844.8672 - learning_rate: 5.0000e-04\n",
      "Epoch 416/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 6590521856.0000 - mae: 100055.1484 - val_loss: 7004591104.0000 - val_mae: 104910.2656 - learning_rate: 5.0000e-04\n",
      "Epoch 417/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 6597675008.0000 - mae: 100139.1562 - val_loss: 6993894912.0000 - val_mae: 104615.9609 - learning_rate: 5.0000e-04\n",
      "Epoch 418/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 6591552512.0000 - mae: 99993.2109 - val_loss: 6990682112.0000 - val_mae: 104563.8906 - learning_rate: 5.0000e-04\n",
      "Epoch 419/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 6580566528.0000 - mae: 99916.6016 - val_loss: 6993163776.0000 - val_mae: 104592.3438 - learning_rate: 5.0000e-04\n",
      "Epoch 420/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 6578000384.0000 - mae: 99864.2891 - val_loss: 7013481984.0000 - val_mae: 105106.1641 - learning_rate: 5.0000e-04\n",
      "Epoch 421/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 6591101440.0000 - mae: 100073.9531 - val_loss: 6984875008.0000 - val_mae: 104497.9141 - learning_rate: 5.0000e-04\n",
      "Epoch 422/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 6578189824.0000 - mae: 99852.9688 - val_loss: 6987581952.0000 - val_mae: 104493.7188 - learning_rate: 5.0000e-04\n",
      "Epoch 423/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 6585395200.0000 - mae: 99937.0312 - val_loss: 6980931072.0000 - val_mae: 104446.9766 - learning_rate: 5.0000e-04\n",
      "Epoch 424/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 6577786880.0000 - mae: 99871.6562 - val_loss: 6987119104.0000 - val_mae: 104510.9297 - learning_rate: 5.0000e-04\n",
      "Epoch 425/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6575203328.0000 - mae: 99812.1641 - val_loss: 6998625280.0000 - val_mae: 104785.7812 - learning_rate: 5.0000e-04\n",
      "Epoch 426/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 6575776768.0000 - mae: 99914.6953 - val_loss: 6978439680.0000 - val_mae: 104453.8516 - learning_rate: 5.0000e-04\n",
      "Epoch 427/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 6570596864.0000 - mae: 99819.9297 - val_loss: 6992632320.0000 - val_mae: 104569.8438 - learning_rate: 5.0000e-04\n",
      "Epoch 428/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 6577046016.0000 - mae: 99891.9688 - val_loss: 6983262720.0000 - val_mae: 104491.6328 - learning_rate: 5.0000e-04\n",
      "Epoch 429/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 6562406912.0000 - mae: 99678.9141 - val_loss: 6982601728.0000 - val_mae: 104461.7969 - learning_rate: 5.0000e-04\n",
      "Epoch 430/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 6561463808.0000 - mae: 99659.2812 - val_loss: 6983435776.0000 - val_mae: 104516.6172 - learning_rate: 5.0000e-04\n",
      "Epoch 431/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 6560937984.0000 - mae: 99664.1016 - val_loss: 6987156480.0000 - val_mae: 104589.9375 - learning_rate: 5.0000e-04\n",
      "Epoch 432/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 6565238272.0000 - mae: 99699.4766 - val_loss: 6982343168.0000 - val_mae: 104605.7578 - learning_rate: 5.0000e-04\n",
      "Epoch 433/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 6564525568.0000 - mae: 99669.5469 - val_loss: 6977869824.0000 - val_mae: 104368.6328 - learning_rate: 5.0000e-04\n",
      "Epoch 434/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6555347456.0000 - mae: 99615.8828 - val_loss: 6978945536.0000 - val_mae: 104528.3516 - learning_rate: 5.0000e-04\n",
      "Epoch 435/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 6569822720.0000 - mae: 99775.5781 - val_loss: 6984212992.0000 - val_mae: 104498.6016 - learning_rate: 5.0000e-04\n",
      "Epoch 436/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6553951744.0000 - mae: 99659.1094 - val_loss: 6979127808.0000 - val_mae: 104489.5156 - learning_rate: 5.0000e-04\n",
      "Epoch 437/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6553486336.0000 - mae: 99564.2188 - val_loss: 6981307392.0000 - val_mae: 104528.4688 - learning_rate: 5.0000e-04\n",
      "Epoch 438/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6546365440.0000 - mae: 99490.4531 - val_loss: 6969415680.0000 - val_mae: 104206.2188 - learning_rate: 5.0000e-04\n",
      "Epoch 439/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 6553040896.0000 - mae: 99558.9844 - val_loss: 6974690816.0000 - val_mae: 104349.8828 - learning_rate: 5.0000e-04\n",
      "Epoch 440/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 6547900928.0000 - mae: 99569.4141 - val_loss: 6989115392.0000 - val_mae: 104780.2734 - learning_rate: 5.0000e-04\n",
      "Epoch 441/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 6548481536.0000 - mae: 99653.0703 - val_loss: 6977800704.0000 - val_mae: 104430.1484 - learning_rate: 5.0000e-04\n",
      "Epoch 442/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 6539469824.0000 - mae: 99410.3594 - val_loss: 6976558592.0000 - val_mae: 104417.8672 - learning_rate: 5.0000e-04\n",
      "Epoch 443/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 6545856000.0000 - mae: 99504.2656 - val_loss: 6976315904.0000 - val_mae: 104354.2734 - learning_rate: 5.0000e-04\n",
      "Epoch 444/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 6543125504.0000 - mae: 99461.2891 - val_loss: 6989186560.0000 - val_mae: 104560.7266 - learning_rate: 5.0000e-04\n",
      "Epoch 445/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6541833728.0000 - mae: 99529.5312 - val_loss: 6977498112.0000 - val_mae: 104417.9531 - learning_rate: 5.0000e-04\n",
      "Epoch 446/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 6542899712.0000 - mae: 99453.4062 - val_loss: 6975838208.0000 - val_mae: 104349.3828 - learning_rate: 5.0000e-04\n",
      "Epoch 447/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6538638336.0000 - mae: 99480.3125 - val_loss: 6988572160.0000 - val_mae: 104735.6641 - learning_rate: 5.0000e-04\n",
      "Epoch 448/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - loss: 6529195008.0000 - mae: 99325.8906 - val_loss: 6975599104.0000 - val_mae: 104353.5703 - learning_rate: 5.0000e-04\n",
      "Epoch 449/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 6527261184.0000 - mae: 99293.1953 - val_loss: 6974166016.0000 - val_mae: 104392.3438 - learning_rate: 2.5000e-04\n",
      "Epoch 450/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 6521336832.0000 - mae: 99158.0469 - val_loss: 6970019328.0000 - val_mae: 104248.1562 - learning_rate: 2.5000e-04\n",
      "Epoch 451/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 6519506944.0000 - mae: 99229.4141 - val_loss: 6971237888.0000 - val_mae: 104271.9453 - learning_rate: 2.5000e-04\n",
      "Epoch 452/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 6522411008.0000 - mae: 99159.2500 - val_loss: 6968015360.0000 - val_mae: 104271.0156 - learning_rate: 2.5000e-04\n",
      "Epoch 453/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6518768640.0000 - mae: 99156.9297 - val_loss: 6967339008.0000 - val_mae: 104204.2734 - learning_rate: 2.5000e-04\n",
      "Epoch 454/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 6520257024.0000 - mae: 99171.1016 - val_loss: 6969356288.0000 - val_mae: 104259.6641 - learning_rate: 2.5000e-04\n",
      "Epoch 455/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 6515702272.0000 - mae: 99067.7812 - val_loss: 6970390016.0000 - val_mae: 104241.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 456/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 6514224128.0000 - mae: 99117.3203 - val_loss: 6969237504.0000 - val_mae: 104221.4766 - learning_rate: 2.5000e-04\n",
      "Epoch 457/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6512971264.0000 - mae: 99041.7031 - val_loss: 6968333824.0000 - val_mae: 104223.0078 - learning_rate: 2.5000e-04\n",
      "Epoch 458/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 6515524608.0000 - mae: 99081.7109 - val_loss: 6968359424.0000 - val_mae: 104233.6016 - learning_rate: 2.5000e-04\n",
      "Epoch 459/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 6517089792.0000 - mae: 99160.6406 - val_loss: 6970761728.0000 - val_mae: 104256.4297 - learning_rate: 2.5000e-04\n",
      "Epoch 460/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 6514676224.0000 - mae: 99093.8672 - val_loss: 6966334464.0000 - val_mae: 104234.9922 - learning_rate: 2.5000e-04\n",
      "Epoch 461/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6510858240.0000 - mae: 99115.1562 - val_loss: 6963287552.0000 - val_mae: 104155.1953 - learning_rate: 2.5000e-04\n",
      "Epoch 462/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 6512333824.0000 - mae: 99087.7031 - val_loss: 6968699392.0000 - val_mae: 104261.0859 - learning_rate: 2.5000e-04\n",
      "Epoch 463/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 6509254144.0000 - mae: 99055.2656 - val_loss: 6961788928.0000 - val_mae: 104116.1562 - learning_rate: 2.5000e-04\n",
      "Epoch 464/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 6509019136.0000 - mae: 99032.4453 - val_loss: 6963997696.0000 - val_mae: 104176.4844 - learning_rate: 2.5000e-04\n",
      "Epoch 465/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6508865024.0000 - mae: 98976.3906 - val_loss: 6967400448.0000 - val_mae: 104282.2656 - learning_rate: 2.5000e-04\n",
      "Epoch 466/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6510190080.0000 - mae: 99104.1094 - val_loss: 6962458624.0000 - val_mae: 104129.8047 - learning_rate: 2.5000e-04\n",
      "Epoch 467/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 6507317248.0000 - mae: 98994.5078 - val_loss: 6962925056.0000 - val_mae: 104165.2969 - learning_rate: 2.5000e-04\n",
      "Epoch 468/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6504916480.0000 - mae: 99047.7188 - val_loss: 6961329152.0000 - val_mae: 104125.1328 - learning_rate: 2.5000e-04\n",
      "Epoch 469/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 6503702016.0000 - mae: 98999.7734 - val_loss: 6964626432.0000 - val_mae: 104178.4922 - learning_rate: 2.5000e-04\n",
      "Epoch 470/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 6497943552.0000 - mae: 98997.7578 - val_loss: 6977083904.0000 - val_mae: 104451.0938 - learning_rate: 2.5000e-04\n",
      "Epoch 471/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6510269440.0000 - mae: 99121.8359 - val_loss: 6962219008.0000 - val_mae: 104126.2266 - learning_rate: 2.5000e-04\n",
      "Epoch 472/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 6503024128.0000 - mae: 98951.8359 - val_loss: 6964460544.0000 - val_mae: 104208.1094 - learning_rate: 2.5000e-04\n",
      "Epoch 473/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 6504647168.0000 - mae: 99030.3828 - val_loss: 6963843072.0000 - val_mae: 104165.0234 - learning_rate: 2.5000e-04\n",
      "Epoch 474/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 6501990400.0000 - mae: 98970.4375 - val_loss: 6965071872.0000 - val_mae: 104167.6250 - learning_rate: 2.5000e-04\n",
      "Epoch 475/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 6501518336.0000 - mae: 98979.0156 - val_loss: 6962744832.0000 - val_mae: 104142.4922 - learning_rate: 2.5000e-04\n",
      "Epoch 476/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 6499203072.0000 - mae: 98986.1641 - val_loss: 6967696384.0000 - val_mae: 104263.2031 - learning_rate: 2.5000e-04\n",
      "Epoch 477/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 6499021824.0000 - mae: 98914.8750 - val_loss: 6962434048.0000 - val_mae: 104131.3828 - learning_rate: 2.5000e-04\n",
      "Epoch 478/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 6500178432.0000 - mae: 98969.3906 - val_loss: 6963025408.0000 - val_mae: 104166.2031 - learning_rate: 2.5000e-04\n",
      "Epoch 479/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6489333248.0000 - mae: 98814.7578 - val_loss: 6963098624.0000 - val_mae: 104164.7656 - learning_rate: 1.2500e-04\n",
      "Epoch 480/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 6493593088.0000 - mae: 98900.3828 - val_loss: 6963490304.0000 - val_mae: 104174.2969 - learning_rate: 1.2500e-04\n",
      "Epoch 481/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 6490375680.0000 - mae: 98786.3125 - val_loss: 6960634880.0000 - val_mae: 104128.6484 - learning_rate: 1.2500e-04\n",
      "Epoch 482/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6490219520.0000 - mae: 98832.7812 - val_loss: 6962727424.0000 - val_mae: 104183.8281 - learning_rate: 1.2500e-04\n",
      "Epoch 483/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 6489004032.0000 - mae: 98814.8516 - val_loss: 6959687680.0000 - val_mae: 104110.8281 - learning_rate: 1.2500e-04\n",
      "Epoch 484/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 6489169920.0000 - mae: 98812.2812 - val_loss: 6959260160.0000 - val_mae: 104078.0391 - learning_rate: 1.2500e-04\n",
      "Epoch 485/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 6490008576.0000 - mae: 98787.9766 - val_loss: 6960471040.0000 - val_mae: 104104.3594 - learning_rate: 1.2500e-04\n",
      "Epoch 486/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 6489450496.0000 - mae: 98829.6641 - val_loss: 6960587776.0000 - val_mae: 104128.2031 - learning_rate: 1.2500e-04\n",
      "Epoch 487/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 6487282688.0000 - mae: 98781.4297 - val_loss: 6959822336.0000 - val_mae: 104103.0391 - learning_rate: 1.2500e-04\n",
      "Epoch 488/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 6487204864.0000 - mae: 98768.5703 - val_loss: 6961112064.0000 - val_mae: 104131.4844 - learning_rate: 1.2500e-04\n",
      "Epoch 489/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 6491423744.0000 - mae: 98826.7188 - val_loss: 6959778304.0000 - val_mae: 104120.5312 - learning_rate: 1.2500e-04\n",
      "Epoch 490/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 6486771712.0000 - mae: 98765.6406 - val_loss: 6960617984.0000 - val_mae: 104126.3125 - learning_rate: 1.2500e-04\n",
      "Epoch 491/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 6487625728.0000 - mae: 98821.5234 - val_loss: 6959791104.0000 - val_mae: 104101.0938 - learning_rate: 1.2500e-04\n",
      "Epoch 492/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 6485875712.0000 - mae: 98767.5000 - val_loss: 6961208320.0000 - val_mae: 104151.8203 - learning_rate: 1.2500e-04\n",
      "Epoch 493/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 6485010944.0000 - mae: 98842.7812 - val_loss: 6958075904.0000 - val_mae: 104083.1406 - learning_rate: 1.2500e-04\n",
      "Epoch 494/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 6484663808.0000 - mae: 98775.0547 - val_loss: 6960248320.0000 - val_mae: 104118.7891 - learning_rate: 1.2500e-04\n",
      "Epoch 495/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 6484883456.0000 - mae: 98763.9062 - val_loss: 6960069120.0000 - val_mae: 104117.9844 - learning_rate: 1.2500e-04\n",
      "Epoch 496/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 6484353536.0000 - mae: 98812.8125 - val_loss: 6960613376.0000 - val_mae: 104110.5625 - learning_rate: 1.2500e-04\n",
      "Epoch 497/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 6485536768.0000 - mae: 98756.8594 - val_loss: 6960563200.0000 - val_mae: 104138.1719 - learning_rate: 1.2500e-04\n",
      "Epoch 498/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 6482215936.0000 - mae: 98758.4062 - val_loss: 6959467520.0000 - val_mae: 104107.5156 - learning_rate: 1.2500e-04\n",
      "Epoch 499/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6483371008.0000 - mae: 98739.9062 - val_loss: 6959385088.0000 - val_mae: 104114.7031 - learning_rate: 1.2500e-04\n",
      "Epoch 500/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 6482898432.0000 - mae: 98781.5703 - val_loss: 6959361536.0000 - val_mae: 104095.1719 - learning_rate: 1.2500e-04\n",
      "Epoch 501/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6482341376.0000 - mae: 98728.2188 - val_loss: 6958794752.0000 - val_mae: 104063.4531 - learning_rate: 1.2500e-04\n",
      "Epoch 502/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6481211392.0000 - mae: 98726.1172 - val_loss: 6959954944.0000 - val_mae: 104108.5391 - learning_rate: 1.2500e-04\n",
      "Epoch 503/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6479794176.0000 - mae: 98739.9922 - val_loss: 6960616960.0000 - val_mae: 104146.8438 - learning_rate: 1.2500e-04\n",
      "Epoch 504/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6477900800.0000 - mae: 98677.3047 - val_loss: 6959370240.0000 - val_mae: 104091.6875 - learning_rate: 6.2500e-05\n",
      "Epoch 505/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6477348352.0000 - mae: 98677.9219 - val_loss: 6958927360.0000 - val_mae: 104083.2656 - learning_rate: 6.2500e-05\n",
      "Epoch 506/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 6476786176.0000 - mae: 98677.5391 - val_loss: 6958955520.0000 - val_mae: 104084.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 507/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6476767232.0000 - mae: 98658.7891 - val_loss: 6958874112.0000 - val_mae: 104075.3125 - learning_rate: 6.2500e-05\n",
      "Epoch 508/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6476807680.0000 - mae: 98649.7188 - val_loss: 6959139840.0000 - val_mae: 104078.7344 - learning_rate: 6.2500e-05\n",
      "Epoch 509/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6475773440.0000 - mae: 98641.9062 - val_loss: 6957765632.0000 - val_mae: 104067.5469 - learning_rate: 6.2500e-05\n",
      "Epoch 510/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6476171776.0000 - mae: 98643.3906 - val_loss: 6957970432.0000 - val_mae: 104064.3906 - learning_rate: 6.2500e-05\n",
      "Epoch 511/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6475346432.0000 - mae: 98618.0547 - val_loss: 6958390784.0000 - val_mae: 104082.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 512/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6475506688.0000 - mae: 98635.5234 - val_loss: 6957747200.0000 - val_mae: 104082.0859 - learning_rate: 6.2500e-05\n",
      "Epoch 513/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6475465728.0000 - mae: 98636.3047 - val_loss: 6957349888.0000 - val_mae: 104071.0938 - learning_rate: 6.2500e-05\n",
      "Epoch 514/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 6475730944.0000 - mae: 98652.1641 - val_loss: 6957607424.0000 - val_mae: 104074.1016 - learning_rate: 6.2500e-05\n",
      "Epoch 515/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 6475581952.0000 - mae: 98640.4844 - val_loss: 6956813312.0000 - val_mae: 104077.0391 - learning_rate: 6.2500e-05\n",
      "Epoch 516/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6474534912.0000 - mae: 98633.4609 - val_loss: 6956784128.0000 - val_mae: 104069.6797 - learning_rate: 6.2500e-05\n",
      "Epoch 517/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 6474413056.0000 - mae: 98608.4922 - val_loss: 6956404736.0000 - val_mae: 104066.3984 - learning_rate: 6.2500e-05\n",
      "Epoch 518/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 6474012160.0000 - mae: 98612.7500 - val_loss: 6956396032.0000 - val_mae: 104056.1719 - learning_rate: 6.2500e-05\n",
      "Epoch 519/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6474531328.0000 - mae: 98612.0547 - val_loss: 6956945408.0000 - val_mae: 104059.4766 - learning_rate: 6.2500e-05\n",
      "Epoch 520/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6473453056.0000 - mae: 98604.9766 - val_loss: 6956910592.0000 - val_mae: 104067.4062 - learning_rate: 6.2500e-05\n",
      "Epoch 521/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 6473672704.0000 - mae: 98612.1484 - val_loss: 6957435904.0000 - val_mae: 104075.2266 - learning_rate: 6.2500e-05\n",
      "Epoch 522/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 6473598976.0000 - mae: 98640.2891 - val_loss: 6956850176.0000 - val_mae: 104069.1406 - learning_rate: 6.2500e-05\n",
      "Epoch 523/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6473532416.0000 - mae: 98634.6875 - val_loss: 6957041152.0000 - val_mae: 104071.8438 - learning_rate: 6.2500e-05\n",
      "Epoch 524/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 6473424896.0000 - mae: 98626.9375 - val_loss: 6956381184.0000 - val_mae: 104059.8906 - learning_rate: 6.2500e-05\n",
      "Epoch 525/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 6472577024.0000 - mae: 98610.8203 - val_loss: 6956393472.0000 - val_mae: 104057.7578 - learning_rate: 6.2500e-05\n",
      "Epoch 526/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 6471987712.0000 - mae: 98610.7734 - val_loss: 6957160448.0000 - val_mae: 104058.8828 - learning_rate: 6.2500e-05\n",
      "Epoch 527/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6472048640.0000 - mae: 98585.6250 - val_loss: 6956656640.0000 - val_mae: 104053.4062 - learning_rate: 6.2500e-05\n",
      "Epoch 528/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 6472378880.0000 - mae: 98616.8281 - val_loss: 6956178432.0000 - val_mae: 104065.7656 - learning_rate: 6.2500e-05\n",
      "Epoch 529/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 6471905792.0000 - mae: 98599.7578 - val_loss: 6956333568.0000 - val_mae: 104061.7109 - learning_rate: 6.2500e-05\n",
      "Epoch 530/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6471356928.0000 - mae: 98606.4453 - val_loss: 6955935744.0000 - val_mae: 104050.5859 - learning_rate: 6.2500e-05\n",
      "Epoch 531/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 6471966720.0000 - mae: 98614.8281 - val_loss: 6956582912.0000 - val_mae: 104047.9844 - learning_rate: 6.2500e-05\n",
      "Epoch 532/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6470880256.0000 - mae: 98578.4609 - val_loss: 6956014592.0000 - val_mae: 104047.8125 - learning_rate: 6.2500e-05\n",
      "Epoch 533/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6471216128.0000 - mae: 98611.0625 - val_loss: 6956621312.0000 - val_mae: 104054.5547 - learning_rate: 6.2500e-05\n",
      "Epoch 534/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6471196672.0000 - mae: 98586.9297 - val_loss: 6956231680.0000 - val_mae: 104044.7188 - learning_rate: 6.2500e-05\n",
      "Epoch 535/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6469877248.0000 - mae: 98588.5547 - val_loss: 6955703808.0000 - val_mae: 104049.0234 - learning_rate: 6.2500e-05\n",
      "Epoch 536/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6470072320.0000 - mae: 98564.1562 - val_loss: 6955564032.0000 - val_mae: 104042.7500 - learning_rate: 6.2500e-05\n",
      "Epoch 537/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6470361088.0000 - mae: 98594.1562 - val_loss: 6955524608.0000 - val_mae: 104051.8047 - learning_rate: 6.2500e-05\n",
      "Epoch 538/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6470118400.0000 - mae: 98574.8594 - val_loss: 6955998208.0000 - val_mae: 104045.8438 - learning_rate: 6.2500e-05\n",
      "Epoch 539/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6469482496.0000 - mae: 98564.9688 - val_loss: 6955501056.0000 - val_mae: 104053.1953 - learning_rate: 6.2500e-05\n",
      "Epoch 540/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 6469855232.0000 - mae: 98629.8672 - val_loss: 6956002304.0000 - val_mae: 104059.4766 - learning_rate: 6.2500e-05\n",
      "Epoch 541/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6471344128.0000 - mae: 98624.1094 - val_loss: 6956056064.0000 - val_mae: 104050.5000 - learning_rate: 6.2500e-05\n",
      "Epoch 542/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6469137920.0000 - mae: 98568.1094 - val_loss: 6956067840.0000 - val_mae: 104054.1328 - learning_rate: 6.2500e-05\n",
      "Epoch 543/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6469036032.0000 - mae: 98583.7969 - val_loss: 6955657216.0000 - val_mae: 104049.6484 - learning_rate: 6.2500e-05\n",
      "Epoch 544/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6468448768.0000 - mae: 98558.8203 - val_loss: 6954075648.0000 - val_mae: 104023.3203 - learning_rate: 6.2500e-05\n",
      "Epoch 545/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6468264448.0000 - mae: 98562.0312 - val_loss: 6953958400.0000 - val_mae: 104031.6328 - learning_rate: 6.2500e-05\n",
      "Epoch 546/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6468175360.0000 - mae: 98565.2109 - val_loss: 6954980352.0000 - val_mae: 104045.8516 - learning_rate: 6.2500e-05\n",
      "Epoch 547/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6468315136.0000 - mae: 98574.0625 - val_loss: 6954616320.0000 - val_mae: 104020.5781 - learning_rate: 6.2500e-05\n",
      "Epoch 548/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 6468272640.0000 - mae: 98587.6953 - val_loss: 6954172928.0000 - val_mae: 104015.9453 - learning_rate: 6.2500e-05\n",
      "Epoch 549/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 6467835904.0000 - mae: 98561.0156 - val_loss: 6954427904.0000 - val_mae: 104015.2109 - learning_rate: 6.2500e-05\n",
      "Epoch 550/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6467109888.0000 - mae: 98564.4141 - val_loss: 6954708992.0000 - val_mae: 104030.8750 - learning_rate: 6.2500e-05\n",
      "Epoch 551/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6468210688.0000 - mae: 98576.2812 - val_loss: 6955634176.0000 - val_mae: 104070.7734 - learning_rate: 6.2500e-05\n",
      "Epoch 552/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 6466959360.0000 - mae: 98533.9219 - val_loss: 6954370048.0000 - val_mae: 104015.3984 - learning_rate: 6.2500e-05\n",
      "Epoch 553/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6466513920.0000 - mae: 98547.7266 - val_loss: 6953509888.0000 - val_mae: 104018.3750 - learning_rate: 6.2500e-05\n",
      "Epoch 554/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 6466770432.0000 - mae: 98572.9062 - val_loss: 6954491392.0000 - val_mae: 104033.0938 - learning_rate: 6.2500e-05\n",
      "Epoch 555/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6466976768.0000 - mae: 98555.5781 - val_loss: 6954257920.0000 - val_mae: 104021.3750 - learning_rate: 6.2500e-05\n",
      "Epoch 556/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 6465210880.0000 - mae: 98509.1250 - val_loss: 6954148864.0000 - val_mae: 104026.2266 - learning_rate: 6.2500e-05\n",
      "Epoch 557/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 6465165312.0000 - mae: 98519.0938 - val_loss: 6952904704.0000 - val_mae: 104026.3906 - learning_rate: 6.2500e-05\n",
      "Epoch 558/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 6464855040.0000 - mae: 98543.5625 - val_loss: 6953263616.0000 - val_mae: 104005.1406 - learning_rate: 6.2500e-05\n",
      "Epoch 559/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 6464447488.0000 - mae: 98533.0781 - val_loss: 6953606656.0000 - val_mae: 104018.5703 - learning_rate: 6.2500e-05\n",
      "Epoch 560/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6464269824.0000 - mae: 98521.8594 - val_loss: 6954217984.0000 - val_mae: 104020.6719 - learning_rate: 6.2500e-05\n",
      "Epoch 561/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6464080896.0000 - mae: 98501.5156 - val_loss: 6954046976.0000 - val_mae: 104014.0078 - learning_rate: 6.2500e-05\n",
      "Epoch 562/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 6463849984.0000 - mae: 98516.7812 - val_loss: 6953614848.0000 - val_mae: 104004.4766 - learning_rate: 6.2500e-05\n",
      "Epoch 563/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6464516608.0000 - mae: 98582.2500 - val_loss: 6956186624.0000 - val_mae: 104065.8594 - learning_rate: 6.2500e-05\n",
      "Epoch 564/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 6463835648.0000 - mae: 98521.9766 - val_loss: 6953784320.0000 - val_mae: 104008.7969 - learning_rate: 6.2500e-05\n",
      "Epoch 565/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 6463805952.0000 - mae: 98506.0703 - val_loss: 6954130944.0000 - val_mae: 104015.3359 - learning_rate: 6.2500e-05\n",
      "Epoch 566/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 6463350272.0000 - mae: 98498.1719 - val_loss: 6954558464.0000 - val_mae: 104028.1719 - learning_rate: 6.2500e-05\n",
      "Epoch 567/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 6463567360.0000 - mae: 98510.4219 - val_loss: 6953150976.0000 - val_mae: 103999.6953 - learning_rate: 6.2500e-05\n",
      "Epoch 568/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6461933056.0000 - mae: 98497.6484 - val_loss: 6953603584.0000 - val_mae: 104007.9297 - learning_rate: 3.1250e-05\n",
      "Epoch 569/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 6461097984.0000 - mae: 98472.4844 - val_loss: 6953811456.0000 - val_mae: 104015.8203 - learning_rate: 3.1250e-05\n",
      "Epoch 570/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 6461457920.0000 - mae: 98485.5938 - val_loss: 6954045952.0000 - val_mae: 104010.0156 - learning_rate: 3.1250e-05\n",
      "Epoch 571/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6461039616.0000 - mae: 98471.6719 - val_loss: 6953606144.0000 - val_mae: 104006.5156 - learning_rate: 3.1250e-05\n",
      "Epoch 572/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6460999680.0000 - mae: 98467.7188 - val_loss: 6953655808.0000 - val_mae: 104006.2344 - learning_rate: 3.1250e-05\n",
      "Epoch 573/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 6460916736.0000 - mae: 98492.3672 - val_loss: 6953521664.0000 - val_mae: 104010.7109 - learning_rate: 3.1250e-05\n",
      "Epoch 574/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 6460330496.0000 - mae: 98484.1641 - val_loss: 6953721344.0000 - val_mae: 104016.8281 - learning_rate: 3.1250e-05\n",
      "Epoch 575/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 6460091904.0000 - mae: 98471.1250 - val_loss: 6953464832.0000 - val_mae: 104004.5625 - learning_rate: 3.1250e-05\n",
      "Epoch 576/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6460257280.0000 - mae: 98462.5078 - val_loss: 6953488896.0000 - val_mae: 104007.0938 - learning_rate: 3.1250e-05\n",
      "Epoch 577/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6460612096.0000 - mae: 98477.0703 - val_loss: 6953796608.0000 - val_mae: 104013.3984 - learning_rate: 3.1250e-05\n",
      "Epoch 578/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 6459328000.0000 - mae: 98455.5859 - val_loss: 6953718272.0000 - val_mae: 104012.8516 - learning_rate: 1.5625e-05\n",
      "Epoch 579/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6459413504.0000 - mae: 98458.2812 - val_loss: 6953529344.0000 - val_mae: 104010.9688 - learning_rate: 1.5625e-05\n",
      "Epoch 580/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 6459330560.0000 - mae: 98454.4375 - val_loss: 6953385472.0000 - val_mae: 104008.0703 - learning_rate: 1.5625e-05\n",
      "Epoch 581/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 6459326976.0000 - mae: 98458.8047 - val_loss: 6953466368.0000 - val_mae: 104004.3359 - learning_rate: 1.5625e-05\n",
      "Epoch 582/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6459099136.0000 - mae: 98460.9141 - val_loss: 6953584128.0000 - val_mae: 104008.0547 - learning_rate: 1.5625e-05\n",
      "Epoch 583/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6459188224.0000 - mae: 98451.6797 - val_loss: 6953710080.0000 - val_mae: 104010.6250 - learning_rate: 1.5625e-05\n",
      "Epoch 584/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6459312128.0000 - mae: 98462.1953 - val_loss: 6953417728.0000 - val_mae: 104008.0156 - learning_rate: 1.5625e-05\n",
      "Epoch 585/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 6458820608.0000 - mae: 98454.3906 - val_loss: 6953424384.0000 - val_mae: 104011.1250 - learning_rate: 1.5625e-05\n",
      "Epoch 586/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 6459000832.0000 - mae: 98460.4531 - val_loss: 6953332224.0000 - val_mae: 104007.4766 - learning_rate: 1.5625e-05\n",
      "Epoch 587/3000\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 6458942464.0000 - mae: 98462.0625 - val_loss: 6953434624.0000 - val_mae: 104007.9688 - learning_rate: 1.5625e-05\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265us/step\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step\n",
      "Mean absolute error in train dataset using Neural Network Model: 99616.41\n",
      "Mean absolute error in test dataset using Neural Network Model: 103219.16\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the car price dataset from a CSV file into a Pandas DataFrame \n",
    "df = pd.read_csv(\"Car details v3.csv\")\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())\n",
    "# print(df.columns)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df[[\"year\", \"km_driven\", \"seller_type\", \"transmission\", \"owner\", \"mileage\", \"engine\", \"max_power\", \"seats\"]].copy()\n",
    "y = df[[\"selling_price\"]]\n",
    "\n",
    "# Extract numeric values from mileage, engine, and max_power columns and convert them to floats\n",
    "for col in [\"mileage\", \"engine\", \"max_power\"]:\n",
    "    X[col] = pd.to_numeric(\n",
    "        X[col].astype(str).str.extract(r\"(\\d+\\.?\\d*)\")[0],\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "# Separate numeric and categorical columns for preprocessing\n",
    "numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Impute missing numeric values using the median of each column\n",
    "for col in numeric_cols:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Impute missing categorical values using the most frequent category (mode)\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "# Split data into train (70%) and test (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define preprocessing pipeline: standardize numeric columns and one-hot encode categorical columns\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Fit preprocessing on training data and apply the same transformation to both train and test sets\n",
    "X_train_scaled = preprocess.fit_transform(X_train)\n",
    "X_test_scaled = preprocess.transform(X_test)\n",
    "\n",
    "# Build a neural network model to predict car selling price\n",
    "nn_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(80, activation='relu',),\n",
    "    tf.keras.layers.Dense(80, activation='relu',),\n",
    "    tf.keras.layers.Dense(80, activation='relu',),\n",
    "    tf.keras.layers.Dense(y.shape[1])\n",
    "])\n",
    "\n",
    "# Compile the neural network using Adam optimizer and Huber loss for regression\n",
    "nn_model.compile(\n",
    "    tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.Huber(delta=100000.0),  # delta in INR\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Reduce learning rate when validation loss stops improving\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=10, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Stop training early and restore the best model weights\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=30, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the neural network using validation split and adaptive callbacks\n",
    "nn_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    epochs=3000,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    #verbose=0\n",
    ")\n",
    "\n",
    "# Generate predictions for the train and test dataset\n",
    "nn_model_prediction_train = nn_model.predict(X_train_scaled)\n",
    "nn_model_prediction_test = nn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate and display model accuracy with Mean Absolute Error for train and test datasets\n",
    "print(f\"Mean absolute error in train dataset using Neural Network Model: {mean_absolute_error(y_train, nn_model_prediction_train):.2f}\")\n",
    "print(f\"Mean absolute error in test dataset using Neural Network Model: {mean_absolute_error(y_test, nn_model_prediction_test):.2f}\")\n",
    "\n",
    "# Plot Predicted Vs Actual Selling Prices of the cars in the test dataset\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_test, nn_model_prediction_test, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"red\", linewidth=2)\n",
    "plt.xlabel(\"Actual Selling Price\")\n",
    "plt.ylabel(\"Predicted Selling Price\")\n",
    "plt.title(\"Actual vs Predicted Selling Price (Test Data)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
