{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac2cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0648d4",
   "metadata": {},
   "source": [
    "This document explains three important machine learning concepts\n",
    "**Overfitting**, **RFE**, and **K-Fold Cross Validation** using\n",
    " **house price dataset** from **Problem 4**\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "# 1. Overfitting\n",
    "\n",
    "## What is Overfitting?\n",
    "\n",
    "Overfitting happens when a machine learning model **memorizes the\n",
    "training data** instead of learning general patterns.\\\n",
    "The model becomes too tailored to the specific examples it has seen and\n",
    "performs poorly on new, unseen data.\n",
    "\n",
    "It's like a student who memorizes answers to practice questions instead\n",
    "of understanding the underlying concepts.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## Example Using House Price Data\n",
    "\n",
    "Imagine your model learns the exact price of each house based on\n",
    "specific combinations:\n",
    "\n",
    "-   *Area = 7420, Bathrooms = 2 → Price = 13,300,000*\n",
    "-   *Area = 8960, Bathrooms = 4 → Price = 12,250,000*\n",
    "\n",
    "This is memorized, not learned.\n",
    "\n",
    "When you show it a new house:\n",
    "\n",
    "    Area = 8200\n",
    "    Bathrooms = 3\n",
    "    Stories = 2\n",
    "\n",
    "The model struggles because it has **not learned a general rule** like:\n",
    "\n",
    "> \"Higher area and more bathrooms tend to increase price.\"\n",
    "\n",
    "Instead, it learned only the *exact* examples.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## Symptoms of Overfitting\n",
    "\n",
    "-   Very low error on training set\n",
    "-   High error on test set\n",
    "-   Complex or unnecessarily large models\n",
    "\n",
    "Example:\n",
    "\n",
    "  Model        Train Error   Test Error\n",
    "  ------------ ------------- ------------\n",
    "  Overfitted   Very low      Very high\n",
    "  Good model   Balanced      Balanced\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## Why Overfitting Happens\n",
    "\n",
    "Overfitting typically occurs when:\n",
    "\n",
    "-   The model is too complex (too many coefficients or features)\n",
    "-   Too many irrelevant features\n",
    "-   Not enough training data\n",
    "-   No regularization used\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "# 2. RFE --- Recursive Feature Elimination\n",
    "\n",
    "## What is RFE?\n",
    "\n",
    "RFE is a **feature selection technique** that automatically selects the\n",
    "most important predictors by **removing the weakest features one at a\n",
    "time**.\n",
    "\n",
    "This continues until only the strongest features remain.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## Example Using House Price Data\n",
    "\n",
    "Suppose your dataset has the following features:\n",
    "\n",
    "-   `area`\n",
    "-   `bedrooms`\n",
    "-   `bathrooms`\n",
    "-   `stories`\n",
    "-   `parking`\n",
    "-   `mainroad`\n",
    "-   `guestroom`\n",
    "-   `basement`\n",
    "-   `airconditioning`\n",
    "-   `prefarea`\n",
    "-   dummy variables from `furnishingstatus`\n",
    "\n",
    "RFE works like this:\n",
    "\n",
    "### Step 1: Fit the model using all features\n",
    "\n",
    "RFE evaluates feature importance.\n",
    "\n",
    "### Step 2: Remove the least important feature\n",
    "\n",
    "Maybe `guestroom` is weak.\n",
    "\n",
    "### Step 3: Fit again without it\n",
    "\n",
    "Evaluate remaining features.\n",
    "\n",
    "### Step 4: Remove the next weakest\n",
    "\n",
    "Maybe `prefarea`.\n",
    "\n",
    "### Step 5: Continue until the desired number of features remain\n",
    "\n",
    "For example, RFE might conclude that the **top 2 best predictors** are:\n",
    "\n",
    "-   `area`\n",
    "-   `bathrooms`\n",
    "\n",
    "RFE finds features that *truly matter* for predicting house prices.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## Why Use RFE?\n",
    "\n",
    "-   Removes noise\n",
    "-   Simplifies the model\n",
    "-   Avoids unnecessary complexity\n",
    "-   Improves generalization (helps prevent overfitting)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "# 3. K-Fold Cross Validation\n",
    "\n",
    "## What is K-Fold CV?\n",
    "\n",
    "K-Fold Cross Validation tests your model's performance more reliably by\n",
    "splitting the data into **K parts** (folds) and training/testing the\n",
    "model **K times**, each time using a different fold for testing.\n",
    "\n",
    "It gives a more stable and fair estimation of your model's performance.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## ⭐ Example Using House Price Data\n",
    "\n",
    "Assume you choose **K = 5**.\n",
    "\n",
    "Your dataset is split into 5 equal folds:\n",
    "\n",
    "    Fold 1: rows 1–109\n",
    "    Fold 2: rows 110–218\n",
    "    Fold 3: rows 219–327\n",
    "    Fold 4: rows 328–436\n",
    "    Fold 5: rows 437–545\n",
    "\n",
    "### The model is trained and tested 5 times:\n",
    "\n",
    "| Round | Train On       | Test On |\n",
    "|-------|----------------|---------|\n",
    "| 1     | Folds 2–5      | Fold 1  |\n",
    "| 2     | Folds 1,3–5    | Fold 2  |\n",
    "| 3     | Folds 1–2,4–5  | Fold 3  |\n",
    "| 4     | Folds 1–3,5    | Fold 4  |\n",
    "| 5     | Folds 1–4      | Fold 5  |\n",
    "\n",
    "### Each round produces a score (e.g., R²):\n",
    "\n",
    "| Fold | R² Score |\n",
    "|------|----------|\n",
    "| 1    | 0.64     |\n",
    "| 2    | 0.66     |\n",
    "| 3    | 0.62     |\n",
    "| 4    | 0.68     |\n",
    "| 5    | 0.65     |\n",
    "### The final performance is the average:\n",
    "\n",
    "\\[ ext{Final R}\\^2 = 0.65 \\]\n",
    "\n",
    "This is **more reliable** than a single train-test split (which might\n",
    "give 0.55 or 0.75 depending on luck).\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## Why Use K-Fold CV?\n",
    "\n",
    "-   Reduces the effect of randomness\n",
    "-   Uses all data for both training AND testing\n",
    "-   Gives a robust estimate of true model performance\n",
    "-   Helps detect overfitting\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
