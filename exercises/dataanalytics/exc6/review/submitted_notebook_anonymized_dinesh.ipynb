{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebabbbab-c235-4789-a004-14e69d06ec9d",
   "metadata": {},
   "source": [
    "# Data Analytics Fall 2025 &mdash; Exercises 6\n",
    "\n",
    "### XXXXX XXXXX (last modified: Tue 18 Nov)\n",
    "\n",
    "- Five problems + round 5 peer review\n",
    "- Theme: logistic regression\n",
    "- Keep your originals up to date by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde89ee5-64f7-4289-8065-d36dfc25c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('/usr/bin/bash /home/varpha/dan/config.sh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6e4d7-46db-465b-a0f6-0fe5ba56aaf3",
   "metadata": {},
   "source": [
    "## Round 5 peer review\n",
    "\n",
    "As before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759fa3a4-19aa-414c-b4d5-b1215f64165f",
   "metadata": {},
   "source": [
    "## Use of AI in this exercise\n",
    "I leveraged AI tools (ie chatgpt) to:\n",
    "- Learn new concepts related to tasks\n",
    "- Brainstorm solutions\n",
    "- Generate and adapt sample code to solve the problems in different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe4d8d-c0fc-43f7-b336-3fc95dd0dd76",
   "metadata": {},
   "source": [
    "\n",
    "### Problem 1. Wines\n",
    "\n",
    "\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p01_wine.csv) is some data on Portuguese wines. \n",
    "\n",
    "Drop rows with missing values.\n",
    "\n",
    "Use logistic regression to predict the type (white/red) from the other fields.\n",
    "\n",
    "Split train/test set 70/30 %. Print the score and the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59221c0b-30ea-4557-a048-821bc6f378ac",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74f6997-390c-4f3c-80a8-3f304265e84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with Logistic Regression Model: 0.9737\n",
      "\n",
      "Confusion Matrix with Logistic Regression Model:\n",
      "[[ 466   12]\n",
      " [  39 1422]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "csv_location = \"exrc06p01_wine.csv\"\n",
    "\n",
    "# Load input CSV which contains data related to Portuguese wines into pandas.DataFrame\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "# print(df.head())  # prints first five rows - default\n",
    "\n",
    "# Drop rows with missing values ie nan entries\n",
    "df_clean = df.dropna().reset_index(drop=True)   # removes null/nan entries and reset index\n",
    "# print(df_clean.info()) # check if there are no null values\n",
    "\n",
    "# Extract Features (X) and Target (y) using ´iloc´ indexer\n",
    "X = df_clean.iloc[:, 1:]    # Features (all rows and columns except 1st column)\n",
    "y = df_clean.iloc[:, 0]     # Target (all rows with 1st column Only)\n",
    "\n",
    "# # Lets print sample data and datatypes for Features and Target\n",
    "# # Note: Regression models works only with numeric data\n",
    "# print(X.head())\n",
    "# print(X.info())   # All Features are numeric\n",
    "# print(y.head())\n",
    "# print(y.info())   # Target value is non-numeric needs to convert to numeric\n",
    "\n",
    "# Lets print what diff values on Target column ie ´type´.\n",
    "# print(y.value_counts())   # values are either \"white\" or \"red\"\n",
    "\n",
    "# Map ´type´ column ie Target to binary: white -> 1, red -> 0\n",
    "# Note: Regression models works only with numeric data\n",
    "y = y.map({\"white\": 1, \"red\": 0})\n",
    "\n",
    "# print(y.info())           # confirm the datatype again\n",
    "# print(y.value_counts())   # confirm the values / distribution for Target ie ´type´ column\n",
    "# # Target values ie classes are imbalanced 1 (white) -> 4870 and 0 (red) -> 1593\n",
    "\n",
    "# Split train/test set 70/30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    train_size=0.7, # to split data as 70% for training and rest 30% for testing\n",
    "    stratify=y,     # to keep the same class ratio (for Target Column) in training and test sets\n",
    "    random_state=42 # to ensure same rows go to train and test sets in every run for consistency purpose\n",
    ")\n",
    "\n",
    "# Create Logistic Regression Model\n",
    "model = LogisticRegression(\n",
    "    class_weight=\"balanced\",    # automatically handle imbalanced classes (Target) by adjusting weights\n",
    "    max_iter=2000,              # allow more steps so the model can fully converge\n",
    "    solver=\"liblinear\"          # best solver for binary classification and smaller datasets   \n",
    ")\n",
    "\n",
    "# Train the Logistic Regression odel\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score = accuracy_score(y_test, y_pred)      \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Score with Logistic Regression Model: {acc_score:.4f}\")\n",
    "print(f\"\\nConfusion Matrix with Logistic Regression Model:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82629f-43fd-4272-a4a2-97addd6614b6",
   "metadata": {},
   "source": [
    "### Problem 2. Voices\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p02_voice.csv) is some data on human voices ([column info](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p02_voice.txt)).\n",
    " \n",
    "Predict the label from the other fields using a support vector machine.\n",
    "\n",
    "Split train/test set 70/30 %.\n",
    "\n",
    "Print the score and the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55651ae-8bc7-4374-981d-251e22bec793",
   "metadata": {},
   "source": [
    "### Solution 2\n",
    "\n",
    "While working with **Opiton 1 - without Scaling** it was observed that the dataset contains features with very different numeric ranges. Because SVM relies on distance-based calculations, features with large values dominate the learning process, while smaller-scale features barely influence the model. As a result, the SVM model becomes confused, fails to learn meaningful patterns, and produces poor accuracy. In simple terms, without scaling, SVM cannot properly understand the data, which leads to weak model performance.\n",
    "\n",
    "While working with **Option 2 - with Scaling**, the performance improves significantly because scaling brings all features to a similar range. After scaling, every feature contributes equally to the model, allowing SVM to correctly identify patterns and draw better decision boundaries. This helps the model train more effectively, reduces the dominance of large-range features, and results in much higher accuracy and more stable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06beab0-9f63-451f-864f-d97e6307e6f2",
   "metadata": {},
   "source": [
    "### Solution 2 (Option 1 - without scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3f2add-ceb8-4fd3-adb0-796458c105ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with SVM Model: 0.6614\n",
      "\n",
      "Confusion Matrix with SVM Model:\n",
      "[[377  99]\n",
      " [223 252]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "csv_location = \"exrc06p02_voice.csv\"\n",
    "\n",
    "# Load input CSV which contains data related to human voices into pandas.DataFrame\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "# print(df.head())  # prints first five rows - default\n",
    "\n",
    "# Extract Features (X) and Target (y) using ´iloc´ indexer\n",
    "X = df.iloc[:, :-1]   # Features (all rows and columns except last column)\n",
    "y = df.iloc[:, -1]    # Target (all rows with last column Only)\n",
    "\n",
    "# # Lets print info related to datatypes for Features and Target\n",
    "# # Note: Regression models works only with numeric data\n",
    "# print(X.info())   # All Features are numeric\n",
    "# print(y.info())   # Target value is non-numeric needs to convert to numeric\n",
    "\n",
    "# Lets print what diff values on Target ie ´label´ column \n",
    "# print(y.value_counts())   # values are either male or female\n",
    "\n",
    "# Map ´label´ column ie Target to binary: male -> 0, female -> 1\n",
    "y = y.map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# print(y.info())         # confirm the datatype again\n",
    "# print(y.value_counts()) # confirm the values and distribution for Target ie ´label´ column \n",
    "\n",
    "# Target values ie classes are equally distributed 50% male ie 0 and 50% female ie 1\n",
    "\n",
    "# Split train/test set 70/30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    train_size=0.7, # to split data as 70% for training and rest 30% for testing\n",
    "    stratify=y,     # to keep the same class ratio in training and test sets\n",
    "    random_state=42 # to ensure same rows go to train and test sets in every run for consistency purpose\n",
    ")\n",
    "\n",
    "# Create SVM model (Support Vector Classifier)\n",
    "model = SVC(\n",
    "    kernel=\"rbf\",             # use RBF kernel to learn non-linear decision boundaries\n",
    "    random_state=42           # ensure reproducible and consistent results\n",
    ")\n",
    "\n",
    "# Train the SVM model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Score with SVM Model: {acc_score:.4f}\")\n",
    "print(f\"\\nConfusion Matrix with SVM Model:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b4c3b-ba28-4fba-a1a4-5748554a7b3c",
   "metadata": {},
   "source": [
    "### Solution 2 (Option 2 - with scaling)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9335178c-57f9-45d8-84a1-8b6da967fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with SVM Model: 0.9811\n",
      "\n",
      "Confusion Matrix with SVM Model:\n",
      "[[465  11]\n",
      " [  7 468]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "csv_location = \"exrc06p02_voice.csv\"\n",
    "\n",
    "# Load input CSV which contains data related to human voices into pandas.DataFrame\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "# print(df.head())  # prints first five rows - default\n",
    "\n",
    "# Extract Features (X) and Target (y) using ´iloc´ indexer\n",
    "X = df.iloc[:, :-1]   # Features (all rows and columns except last column)\n",
    "y = df.iloc[:, -1]    # Target (all rows with last column Only)\n",
    "\n",
    "# # Lets print info related to datatypes for Features and Target\n",
    "# # Note: Regression models works only with numeric data\n",
    "# print(X.info())   # All Features are numeric\n",
    "# print(y.info())   # Target value is non-numeric needs to convert to numeric\n",
    "\n",
    "# Lets print what diff values on Target ie ´label´ column \n",
    "# print(y.value_counts())   # values are either male or female\n",
    "\n",
    "# Map ´label´ column ie Target to binary: male -> 0, female -> 1\n",
    "y = y.map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# print(y.info())         # confirm the datatype again\n",
    "\n",
    "# print(y.value_counts()) # confirm the values and distribution for Target ie ´label´ column \n",
    "# Target values ie classes are equally distributed 50% male ie 0 and 50% female ie 1\n",
    "\n",
    "# Split train/test set 70/30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    train_size=0.7, # to split data as 70% for training and rest 30% for testing\n",
    "    stratify=y,     # to keep the same class ratio in training and test sets\n",
    "    random_state=42 # to ensure same rows go to train and test sets in every run for consistency purpose\n",
    ")\n",
    "\n",
    "# Standardize features for SVM model\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Create SVM model (Support Vector Classifier)\n",
    "model = SVC(\n",
    "    kernel=\"rbf\",             # use RBF kernel to learn non-linear decision boundaries\n",
    "    random_state=42           # ensure reproducible and consistent results\n",
    ")\n",
    "\n",
    "# Train the SVM model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score = accuracy_score(y_test, y_pred)      \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Score with SVM Model: {acc_score:.4f}\")\n",
    "print(f\"\\nConfusion Matrix with SVM Model:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc3925-ea46-4069-a059-1adc344dd929",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problem 3. NBA\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p03_nba.csv) is some data on NBA basketball players in their first season ([column info](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p03_nba.csv)).\n",
    "\n",
    "The last column tells if a player's career has exceed 5 years or not.\n",
    "\n",
    "Fill any missing values with the field median.\n",
    "\n",
    "Try to predict if the career has exceeded 5 years or not by using both logistic regression and a support vector machine. Print scores and confusion matrices. Split train/test data as you wish. Compare the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5f716-8890-4d2a-b1c2-cb85fa2d7b15",
   "metadata": {},
   "source": [
    "### Solution 3\n",
    "I tried to solve the problem with two different ways like Solution 2 **Opiton 1 - without Scaling**  and **Opiton 2 - with Scaling** but not much difference this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f871df2-2f92-4a49-b8c7-6a4f83e614c3",
   "metadata": {},
   "source": [
    "### Solution 3 (Option 1 - without scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3983eedd-a8df-4c04-836b-ad2f5f3180a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with SVM Model: 0.6998\n",
      "Confusion Matrix with SVM Model:\n",
      "[[ 73  80]\n",
      " [ 41 209]]\n",
      "\n",
      "Accuracy Score with Logistic Regression Model: 0.7097\n",
      "Confusion Matrix with Logistic Regression Model:\n",
      "[[ 83  70]\n",
      " [ 47 203]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "csv_location = \"exrc06p03_nba.csv\"\n",
    "\n",
    "# Load input CSV which contains data related to human voices into pandas.DataFrame\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "# print(df.head())  # prints first five rows - default\n",
    "\n",
    "# Extract Feature (X) and Target (y)\n",
    "# Drop non-feature column ie ´Name´\n",
    "X = df.drop(columns=[\"TARGET_5Yrs\", \"Name\"])\n",
    "y = df[\"TARGET_5Yrs\"]\n",
    "\n",
    "# Lets print sample data and datatypes for Features and Target\n",
    "# Note: Regression models works only with numeric data\n",
    "# print(X.head())\n",
    "# print(X.info())   # All Features are numeric but contains null values\n",
    "# print(y.head())\n",
    "# print(y.info())   # Target value is numeric\n",
    "\n",
    "# Replace missing values with the median of each column\n",
    "# print(\"\\nMissing values on Features:\\n\", X.isna().sum())\n",
    "X_cleaned = X.fillna(df.median(numeric_only=True))\n",
    "# print(\"\\nCheck missing values after imputation:\\n\", X_cleaned.isna().sum())\n",
    "\n",
    "# Lets print what diff values on Target ie ´TARGET_5Yrs´ column \n",
    "# print(y.value_counts())   # confirm the values / distribution for Target ie ´TARGET_5Yrs´ column\n",
    "\n",
    "# Split train/test set 70/30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cleaned,\n",
    "    y,\n",
    "    train_size=0.7, # to split data as 70% for training and rest 30% for testing\n",
    "    stratify=y,     # to keep the same class ratio in training and test sets\n",
    "    random_state=42 # to ensure same rows go to train and test sets in every run for consistency purpose\n",
    ")\n",
    "\n",
    "# Create SVM model (Support Vector Classifier)\n",
    "svm_model = SVC(\n",
    "    #class_weight=\"balanced\",  # adjust importance of classes to handle imbalanced data\n",
    "    kernel=\"rbf\",             # use RBF kernel to learn non-linear decision boundaries\n",
    "    random_state=42           # ensure reproducible and consistent results\n",
    ")\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score_svm = accuracy_score(y_test, y_pred_svm)          # Calculate Accuracy score\n",
    "confusion_matrix_svm = confusion_matrix(y_test, y_pred_svm) # Calculate Confusion Matrix\n",
    "\n",
    "print(f\"Accuracy Score with SVM Model: {acc_score_svm:.4f}\")\n",
    "print(f\"Confusion Matrix with SVM Model:\\n{confusion_matrix_svm}\")\n",
    "\n",
    "# Create Logistic Regression Model\n",
    "model_lr = LogisticRegression(\n",
    "    #class_weight=\"balanced\",    # automatically handle imbalanced classes by adjusting weights\n",
    "    max_iter=2000,              # allow more steps so the model can fully converge\n",
    "    solver=\"liblinear\"          # best solver for binary classification and smaller datasets   \n",
    ")\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score_lr = accuracy_score(y_test, y_pred_lr)\n",
    "confusion_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nAccuracy Score with Logistic Regression Model: {acc_score_lr:.4f}\")\n",
    "print(f\"Confusion Matrix with Logistic Regression Model:\\n{confusion_matrix_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20671936-2528-48d9-9168-7e9aae33b77a",
   "metadata": {},
   "source": [
    "### Solution 3 (Option 2 - with scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96dd890b-5496-4ded-bbad-9d880e06009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with SVM Model: 0.7047\n",
      "Confusion Matrix with SVM Model:\n",
      "[[ 82  71]\n",
      " [ 48 202]]\n",
      "\n",
      "Accuracy Score with Logistic Regression Model: 0.7022\n",
      "Confusion Matrix with Logistic Regression Model:\n",
      "[[ 79  74]\n",
      " [ 46 204]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "csv_location = \"exrc06p03_nba.csv\"\n",
    "\n",
    "# Load input CSV which contains data related to human voices into pandas.DataFrame\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "# print(df.head())  # prints first five rows - default\n",
    "\n",
    "# Extract Features (X) and Target (y)\n",
    "# Drop non-feature column ie ´Name´ \n",
    "X = df.drop(columns=[\"TARGET_5Yrs\", \"Name\"])\n",
    "y = df[\"TARGET_5Yrs\"]\n",
    "\n",
    "# Lets print sample data and datatypes for Features and Target\n",
    "# Note: Regression models works only with numeric data\n",
    "# print(X.head())\n",
    "# print(X.info())   # All Features are numeric but contains null values\n",
    "# print(y.head())\n",
    "# print(y.info())   # Target value is numeric\n",
    "\n",
    "# Replace missing values with the median of each column\n",
    "# print(\"\\nMissing values on Features:\\n\", X.isna().sum())\n",
    "X_cleaned = X.fillna(df.median(numeric_only=True))\n",
    "# print(\"\\nCheck missing values after imputation:\\n\", X_cleaned.isna().sum())\n",
    "\n",
    "# Lets print what diff values on Target ie ´TARGET_5Yrs´ column \n",
    "# print(y.value_counts())   # confirm the values / distribution for Target ie ´TARGET_5Yrs´ column\n",
    "\n",
    "# Split train/test set 70/30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cleaned,\n",
    "    y,\n",
    "    train_size=0.7, # to split data as 70% for training and rest 30% for testing\n",
    "    stratify=y,     # to keep the same class ratio in training and test sets\n",
    "    random_state=42 # to ensure same rows go to train and test sets in every run for consistency purpose\n",
    ")\n",
    "\n",
    "# Standardize features for SVM and Logistic Regression models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create SVM model (Support Vector Classifier)\n",
    "svm_model = SVC(\n",
    "    # class_weight=\"balanced\",  # adjust importance of classes to handle imbalanced data\n",
    "    kernel=\"rbf\",             # use RBF kernel to learn non-linear decision boundaries\n",
    "    random_state=42           # ensure reproducible and consistent results\n",
    ")\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score_svm = accuracy_score(y_test, y_pred_svm)          # Calculate Accuracy score\n",
    "confusion_matrix_svm = confusion_matrix(y_test, y_pred_svm) # Calculate Confusion Matrix\n",
    "\n",
    "print(f\"Accuracy Score with SVM Model: {acc_score_svm:.4f}\")\n",
    "print(f\"Confusion Matrix with SVM Model:\\n{confusion_matrix_svm}\")\n",
    "\n",
    "# Create Logistic Regression Model\n",
    "# Use liblinear solver, good for smaller datasets and binary classification\n",
    "model_lr = LogisticRegression(\n",
    "    # class_weight=\"balanced\",    # automatically handle imbalanced classes by adjusting weights\n",
    "    max_iter=2000,              # allow more steps so the model can fully converge\n",
    "    solver=\"liblinear\"          # best solver for binary classification and smaller datasets   \n",
    ")\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred_lr = model_lr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score_lr = accuracy_score(y_test, y_pred_lr)\n",
    "confusion_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nAccuracy Score with Logistic Regression Model: {acc_score_lr:.4f}\")\n",
    "print(f\"Confusion Matrix with Logistic Regression Model:\\n{confusion_matrix_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670cdbf-167d-45b5-b2b3-24e1bc8ae4e6",
   "metadata": {},
   "source": [
    "### Problem 4.  Mushrooms\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p04_mushrooms.csv) is some data on mushrooms ([column info](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p04_mushrooms.txt)).\n",
    "\n",
    "Try to predict the class (edible or poisonous) from the other fields. Use whatever you want!\n",
    "\n",
    "Fields are categorial so one-hot-encoding (or dummy encoding) is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabbec4-014c-4678-8c65-a2fb03652d9b",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ae435e-bfad-4803-aedb-421baa6eb486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with Logistic Regression Model: 0.9996\n",
      "\n",
      "Confusion Matrix with Logistic Regression Model:\n",
      "[[1263    0]\n",
      " [   1 1174]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "csv_location = \"exrc06p04_mushrooms.csv\"\n",
    "\n",
    "# Load input CSV which contains some data on mushrooms into pandas.DataFrame\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "# print(df.head())  # prints first five rows - default\n",
    "\n",
    "# Extract Features (X) and Target (y) using ´iloc´ indexer\n",
    "X = df.iloc[:, 1:]    # Features (all rows and columns except 1st column)\n",
    "y = df.iloc[:, 0]     # Target (all rows with 1st column Only)\n",
    "\n",
    "# All columns are categorical, so we can use one-hot encode with ´get_dummies()´ method\n",
    "X_encoded = pd.get_dummies(\n",
    "    X, \n",
    "    drop_first=False # to keep all dummy columns\n",
    ")\n",
    "\n",
    "# Split train/test set 70/30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, \n",
    "    y, \n",
    "    train_size=0.7, # to split data as 70% for training and rest 30% for testing\n",
    "    stratify=y,     # to keep the same class ratio in training and test sets\n",
    "    random_state=42 # to ensure same rows go to train and test sets in every run for consistency purpose\n",
    ")\n",
    "\n",
    "# Create Logistic Regression Model\n",
    "model = LogisticRegression(\n",
    "    class_weight=\"balanced\",    # automatically handle imbalanced classes by adjusting weights\n",
    "    max_iter=2000,              # allow more steps so the model can fully converge\n",
    "    solver=\"liblinear\"          # best solver for binary classification and smaller datasets   \n",
    ")\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model's Accuracy Score and Confusion Matrix\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Score with Logistic Regression Model: {acc_score:.4f}\")\n",
    "print(f\"\\nConfusion Matrix with Logistic Regression Model:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf511d-2bff-4d3b-8cd3-2231732df527",
   "metadata": {},
   "source": [
    "### Problem 5. Loan status\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p05_loan.txt) is some data on loanees. The last column (Loan_Status Y/N) should be predicted from the other fields. Use whatever you want.  \n",
    "\n",
    "\n",
    "Do modifications:\n",
    "* categorial fields to numeric (two-value fields to 0/1, multivalue as dummies/onehot)\n",
    "* replace missing values with median\n",
    "* remove rows with outliers: ApplicantIncome, CoapplicantIncome or LoanAmount over 3 standard deviations away from field average\n",
    "\n",
    "\n",
    "Check what would be model's probability to Loan_status = Yes with values:\n",
    "\n",
    "```\n",
    "Gender                   Male\n",
    "Married                    No\n",
    "Dependents                  0\n",
    "Education            Graduate\n",
    "Self_Employed              No\n",
    "ApplicantIncome          2400\n",
    "CoapplicantIncome        2000\n",
    "LoanAmount                 36\n",
    "Loan_Amount_Term          360\n",
    "Credit_History              1\n",
    "Property_Area           Urban\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef55aee-0b0e-4f86-8aad-f1e92fadab79",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f24c53e-2d80-4076-9dbb-a9b20479ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score with Logistic Regression Model: 0.8233\n",
      "Confusion Matrix with Logistic Regression Model:\n",
      "[[ 48  29]\n",
      " [ 21 185]]\n",
      "\n",
      "Probability of Loan Approval (Yes) for the given case: 0.7402\n",
      "Predicted Loan_Status for the given case: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "csv_location = \"exrc06p05_loan.csv\"\n",
    "\n",
    "# Load input CSV which contains some data on loanees into pandas.DataFrame\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "# # Get basic information about data\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "# print(df.head())  # prints first five rows - default\n",
    "\n",
    "# Drop ´Loan_ID´ column not a Feature to be used\n",
    "df = df.drop(columns=[\"Loan_ID\"])\n",
    "# print(df.info())  # prints concise summary about DataFrame's structure\n",
    "\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "# print(\"\\nMissing values on numeric columns:\\n\", df[numeric_cols].isna().sum())\n",
    "\n",
    "# Replace missing values in numeric columns with median\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# print(\"\\nCheck missing values on numeric columns after imputation:\\n\", df[numeric_cols].isna().sum())\n",
    "\n",
    "# Columns to check for outliers\n",
    "outlier_cols = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\"]\n",
    "\n",
    "# Compute mean and standard deviation for selected outlier columns\n",
    "means = df[outlier_cols].mean()\n",
    "stds  = df[outlier_cols].std()\n",
    "\n",
    "# print(\"Shape before removing outliers\", df.shape)\n",
    "\n",
    "# Keep only rows where ALL selected columns are within ±3 standard deviation\n",
    "df = df[\n",
    "    ((df[outlier_cols] - means).abs() <= 3 * stds).all(axis=1)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# print(\"Shape after removing outliers\", df.shape)\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_cols = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "\n",
    "# print(\"\\nMissing values on non-numeric columns:\\n\", df[non_numeric_cols].isna().sum())\n",
    "# There are few columns (Gender-21, Married-3, Self_Employed-52) where values are missing\n",
    "# Will use mode() method to fill the missing data with with most frequent value\n",
    "\n",
    "for col in non_numeric_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# print(\"\\nCheck missing values on non-numeric columns post imputation:\\n\", df[non_numeric_cols].isna().sum())\n",
    "\n",
    "\n",
    "# Find the diff values on non_numeric or categorical columns\n",
    "# for col in non_numeric_cols:\n",
    "#     print(f\"\\n--- {col} ---\")\n",
    "#     print(df[col].value_counts())\n",
    "\n",
    "# There are columns which has only two possible values \n",
    "# For those columns lets map with 0 and 1\n",
    "mappings = {\n",
    "    \"Loan_Status\": {\"Y\": 1, \"N\": 0},\n",
    "    \"Married\": {\"Yes\": 1, \"No\": 0},\n",
    "    \"Gender\": {\"Male\": 1, \"Female\": 0},\n",
    "    \"Self_Employed\": {\"Yes\": 1, \"No\": 0},\n",
    "    \"Education\": {\"Graduate\": 1, \"Not Graduate\": 0}\n",
    "}\n",
    "\n",
    "for col, mp in mappings.items():\n",
    "    df[col] = df[col].map(mp)\n",
    "\n",
    "\n",
    "# There is a column ´Property_Area´ which is multivalue ie more than two values\n",
    "# Add a dummy 1/0 variable to each of the ´Property_Area´ column value\n",
    "df = pd.get_dummies(df, columns=[\"Property_Area\"], drop_first=False, dtype=int)\n",
    "\n",
    "# # Let see sample and information post preprocessing and feature engineering\n",
    "# print(df.head())\n",
    "# print(df.info())\n",
    "\n",
    "# # Extract Features (X) and Target (y)\n",
    "X = df.drop(columns=[\"Loan_Status\"]) \n",
    "y = df[\"Loan_Status\"]\n",
    "\n",
    "# print(y.value_counts())   # confirm the values / distribution for Target ie ´type´ column\n",
    "\n",
    "# Split train/test set 70/30 %\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    train_size=0.7, # to split data as 70% for training and rest 30% for testing\n",
    "    stratify=y,     # to keep the same class ratio in training and test sets\n",
    "    random_state=42 # to ensure same rows go to train and test sets in every run for consistency purpose\n",
    ")\n",
    "\n",
    "# Create Logistic Regression Model\n",
    "model = LogisticRegression(\n",
    "    class_weight=\"balanced\",    # automatically handle imbalanced classes by adjusting weights\n",
    "    max_iter=2000,              # allow more steps so the model can fully converge\n",
    "    solver=\"liblinear\"          # best solver for binary classification and smaller datasets   \n",
    ")\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction with test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model with Accuracy Score and Confusion Matrix\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Score with Logistic Regression Model: {acc_score:.4f}\")\n",
    "print(f\"Confusion Matrix with Logistic Regression Model:\\n{conf_matrix}\")\n",
    "\n",
    "# Check Model's probability to Loan_status = Yes with below data\n",
    "new_applicant = pd.DataFrame({\n",
    "    \"Gender\": [1],\n",
    "    \"Married\": [0],\n",
    "    \"Dependents\": [0],\n",
    "    \"Education\": [1],\n",
    "    \"Self_Employed\": [0],\n",
    "    \"ApplicantIncome\": [2400],\n",
    "    \"CoapplicantIncome\": [2000],\n",
    "    \"LoanAmount\": [36],\n",
    "    \"Loan_Amount_Term\": [360],\n",
    "    \"Credit_History\": [1],\n",
    "    \"Property_Area_Rural\": [0],\n",
    "    \"Property_Area_Semiurban\": [0],\n",
    "    \"Property_Area_Urban\": [1]\n",
    "})\n",
    "\n",
    "# Ensure correct column order for the above data\n",
    "new_applicant = new_applicant[X.columns]\n",
    "\n",
    "# Compute probability and Prediction\n",
    "prob_yes = model.predict_proba(new_applicant)[0, 1]\n",
    "prediction = model.predict(new_applicant)[0]\n",
    "\n",
    "print(f\"\\nProbability of Loan Approval (Yes) for the given case: {prob_yes:.4f}\")\n",
    "print(\"Predicted Loan_Status for the given case:\", \"Yes\" if prediction == 1 else \"No\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
