{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebabbbab-c235-4789-a004-14e69d06ec9d",
   "metadata": {},
   "source": [
    "# Data Analytics Fall 2025 &mdash; Exercises 6\n",
    "\n",
    "### XXXXX XXXXX (last modified: Tue 18 Nov)\n",
    "\n",
    "- Five problems + round 5 peer review\n",
    "- Theme: logistic regression\n",
    "- Keep your originals up to date by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde89ee5-64f7-4289-8065-d36dfc25c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuring...\n",
      "\n",
      "  created the ~/dan directory tree\n",
      "  changed all ~/dan subdir permissions to 700\n",
      "  removed any broken filelinks under ~/dan\n",
      "  copied filelinks from /home/varpha/dan to ~/dan\n",
      "  removed any python cache dirs\n",
      "  creating answers workbook (Darren's idea)\n",
      "  answers workbook /home/XXXXX/dan/private/exrc_06/exrc_06_answers.ipynb already exists, skipping copy\n",
      "\n",
      "  upgrading jupyterlab etc. (may take a while)...\n",
      "  done (you may need to restart your server in order for the upgrades to take effect)\n",
      "\n",
      "All Done!\n",
      "\n",
      "Please run this config script whenever you start working on the hub.\n",
      "\n",
      "If you encountered errors, please re-run the script. If the errors persist, please report to our Teams channel.\n",
      "\n",
      "Also, please do 'File -> Hub Control Panel -> Stop My Server'\n",
      "whenever you stop working on the hub.\n",
      "\n",
      "Thank you!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('/usr/bin/bash /home/varpha/dan/config.sh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6e4d7-46db-465b-a0f6-0fe5ba56aaf3",
   "metadata": {},
   "source": [
    "## Round 5 peer review\n",
    "\n",
    "As before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d08e71-c49c-4c1b-ba11-97185558b8ce",
   "metadata": {},
   "source": [
    "### General note of AI use in the problem solutions\n",
    "\n",
    "It is obvious that AI (ChatGPT) has been used quite a lot during the following solution process. I mainly use AI in two ways. First, I use it to clarify the task when I am unsure about the instructions. This way I can better understand what is required and why each step is needed. Second, I use AI to help generate or correct code, especially in situations where certain functions, preprocessing steps, or model-related concepts are new to me. All AI-generated code is checked carefully, because there are sometimes unnecessary or too complicated steps included.\n",
    "\n",
    "I also divide the solution into clear steps myself and go through each step so that I understand what the code is doing. AI helps me by providing explanations for unfamiliar concepts (such as encoding, z-scores, model evaluation metrics, or multicollinearity), which makes the learning process faster and more structured. It also helps me write cleaner explanation cells. \n",
    "\n",
    "Although I cannot say that I fully understand every detail immediately, I have noticed that my understanding has improved after each exercise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe4d8d-c0fc-43f7-b336-3fc95dd0dd76",
   "metadata": {},
   "source": [
    "\n",
    "### Problem 1. Wines\n",
    "\n",
    "\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p01_wine.csv) is some data on Portuguese wines. \n",
    "\n",
    "Drop rows with missing values.\n",
    "\n",
    "Use logistic regression to predict the type (white/red) from the other fields.\n",
    "\n",
    "Split train/test set 70/30 %. Print the score and the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ecac21-7713-4877-bf44-00180b751e4b",
   "metadata": {},
   "source": [
    "#### Task clarification\n",
    "\n",
    "Goal: Use Portuguese wine data to build a logistic regression model that predicts whether a wine is white or red based on its physicochemical properties.\n",
    "\n",
    "Steps to complete the task:\n",
    "\n",
    "- Load the dataset and inspect its structure.\n",
    "- Drop rows with missing values.\n",
    "- Prepare the features and the target variable (type).\n",
    "- Split the data into train and test sets (70/30)\n",
    "- Fit a logistic regression model.\n",
    "- Evaluate the model with accuracy and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7855701d-9be6-4c05-94ce-19fe348edfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "# - pandas: loading and manipulating tabular data\n",
    "# - train_test_split: splitting data into train and test parts\n",
    "# - LogisticRegression: classification model for binary target (white/red)\n",
    "# - accuracy_score, confusion_matrix: metrics for model evaluation\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d9b7f-aa3c-4726-b168-6bec97936fdd",
   "metadata": {},
   "source": [
    "#### 1. Load the and inspect the data\n",
    "\n",
    "Load the given CSV file, display the first rows and basic information (column names, data types, and missing values) to understand what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a451ec19-990c-441f-8e67-d6f2f49fe301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  white            7.0              0.27         0.36            20.7   \n",
       "1  white            6.3              0.30         0.34             1.6   \n",
       "2  white            8.1              0.28         0.40             6.9   \n",
       "3  white            7.2              0.23         0.32             8.5   \n",
       "4  white            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.45      8.8        6  \n",
       "1       0.49      9.5        6  \n",
       "2       0.44     10.1        6  \n",
       "3       0.40      9.9        6  \n",
       "4       0.40      9.9        6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values per column:\n",
      "type                     0\n",
      "fixed acidity           10\n",
      "volatile acidity         8\n",
      "citric acid              3\n",
      "residual sugar           2\n",
      "chlorides                2\n",
      "free sulfur dioxide      0\n",
      "total sulfur dioxide     0\n",
      "density                  0\n",
      "pH                       9\n",
      "sulphates                4\n",
      "alcohol                  0\n",
      "quality                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the wine dataset from CSV\n",
    "file_path = 'exrc06p01_wine.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show the first rows \n",
    "display(df.head())\n",
    "\n",
    "# Check the number of missing values per column\n",
    "print('\\nNumber of missing values per column:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c4650-1275-4653-abbf-b1f1e129ceea",
   "metadata": {},
   "source": [
    "#### 2. Drop rows with missing values\n",
    "\n",
    "Remove all rows that contain at least one missing value.\n",
    "After dropping these rows check the new shape of the dataset and verify that\n",
    "no missing values remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90bfc05-42ba-42cd-bc97-0e971f50af55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (6497, 13)\n",
      "Shape after dropping missing values: (6463, 13)\n",
      "\n",
      "Missing values after cleaning:\n",
      "type                    0\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Store the original shape before cleaning\n",
    "print('Original shape:', df.shape)\n",
    "\n",
    "# Drop rows that contain any missing values\n",
    "df = df.dropna()\n",
    "\n",
    "print('Shape after dropping missing values:', df.shape)\n",
    "\n",
    "# Confirm that there are no missing values left\n",
    "print('\\nMissing values after cleaning:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1fb0b-e5d3-41c8-9aeb-d3b58c26592c",
   "metadata": {},
   "source": [
    "#### 3. Prepare features (X) and target (y)\n",
    "\n",
    "The target variable is the column `type` (white or red).\n",
    "Machine learning models typically need numeric targets, so we map:\n",
    "\n",
    "- `white` → 0\n",
    "- `red` → 1\n",
    "\n",
    "All other columns are used as numeric features to predict the wine type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904c378f-ceea-4299-a17d-6fb126e01667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type value counts after mapping (0 = white, 1 = red):\n",
      "type\n",
      "0    4870\n",
      "1    1593\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature columns:\n",
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
      "\n",
      "X shape: (6463, 12)\n",
      "y length: 6463\n"
     ]
    }
   ],
   "source": [
    "# white -> 0, red -> 1\n",
    "df['type'] = df['type'].map({'white': 0, 'red': 1})\n",
    "\n",
    "# Check that the mapping worked correctly\n",
    "print('Type value counts after mapping (0 = white, 1 = red):')\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "# Define features X (all columns except type) and target y (type)\n",
    "X = df.drop('type', axis=1)\n",
    "y = df['type']\n",
    "\n",
    "print('\\nFeature columns:')\n",
    "print(X.columns.tolist())\n",
    "print('\\nX shape:', X.shape)\n",
    "print('y length:', len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28f10d-7926-439d-bedd-4ba399a7d272",
   "metadata": {},
   "source": [
    "#### 4. Train/test split (70/30)\n",
    "\n",
    "Split the data into **training** and **test** sets:\n",
    "\n",
    "- 70% of the data for training the model\n",
    "- 30% of the data for testing (evaluating) the model\n",
    "\n",
    "Use `stratify=y` so that the class balance (white vs. red) stays roughly the\n",
    "same in both splits. A fixed `random_state` makes the split reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46e1b06-e39c-4137-b2fa-aea493c28a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4524, 12)\n",
      "Test set shape: (1939, 12)\n",
      "\n",
      "Training target distribution (relative):\n",
      "type\n",
      "0    0.753537\n",
      "1    0.246463\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test target distribution (relative):\n",
      "type\n",
      "0    0.753481\n",
      "1    0.246519\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,      # 30% for testing, 70% for training\n",
    "    random_state=42,     # fixed seed for reproducibility\n",
    "    stratify=y           # preserve class distribution\n",
    ")\n",
    "\n",
    "print('Training set shape:', X_train.shape)\n",
    "print('Test set shape:', X_test.shape)\n",
    "print('\\nTraining target distribution (relative):')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('\\nTest target distribution (relative):')\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd138e10-27e9-462b-b213-e8df2ab6fcca",
   "metadata": {},
   "source": [
    "#### 5. Fit the logistic regression model\n",
    "\n",
    "Create a `LogisticRegression` model and fit it on the training data.\n",
    "\n",
    "Increase `max_iter` to make sure that the optimization converges.\n",
    "\n",
    "The model learns how each feature is associated with the probability that a wine is red (1) rather than white (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61539760-72dd-4678-9131-d1dd773e775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler to standardize the feature values. I had to use this because the logistic regression solver initially struggled to converge with the dataset.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaler and logistic regression model\n",
    "scaler = StandardScaler()\n",
    "log_reg = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Fit the scaler on the training data ONLY\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the logistic regression model on the scaled data\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model fitted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec43223-d65b-4257-9acf-47e4ef0cc4e2",
   "metadata": {},
   "source": [
    "#### 6. Evaluate the model\n",
    "\n",
    "A trained model was used  to predict wine type on the **test set**.\n",
    "Then calculate:\n",
    "\n",
    "- **Accuracy**: fraction of correct predictions.\n",
    "- **Confusion matrix**: counts of true vs. predicted classes.\n",
    "\n",
    "In the confusion matrix:\n",
    "\n",
    "- Rows correspond to the **true** class.\n",
    "- Columns correspond to the **predicted** class.\n",
    "- Class 0 = white, class 1 = red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e7eb5aa-7f17-46c3-9a23-f96ed00fad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9948\n",
      "\n",
      "Confusion matrix (rows = true, columns = predicted):\n",
      "[[1455    6]\n",
      " [   4  474]]\n",
      "\n",
      "Confusion matrix with labels:\n",
      "              Pred 0 (white)   Pred 1 (red)\n",
      "True 0 (white)     1455                6\n",
      "True 1 (red)          4              474\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions for the (scaled) test set\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy (correct predictions / all predictions)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix (rows = true, columns = predicted):\")\n",
    "print(cm)\n",
    "\n",
    "# Print a slightly nicer formatted version\n",
    "print(\"\\nConfusion matrix with labels:\")\n",
    "print(\"              Pred 0 (white)   Pred 1 (red)\")\n",
    "print(f\"True 0 (white)   {cm[0,0]:>6}           {cm[0,1]:>6}\")\n",
    "print(f\"True 1 (red)     {cm[1,0]:>6}           {cm[1,1]:>6}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ceb076-b1b4-4988-a9c8-64ad33508c23",
   "metadata": {},
   "source": [
    "#### 7. Short conclusion\n",
    "\n",
    "- In this task a logistic regression model was traunedt to classify wines as **white** or **red**\n",
    "  based on their physicochemical properties.\n",
    "- The dataset was cleaned by **dropping rows with missing values**.\n",
    "- A **70/30 train/test split** was used and evaluated the model on the test set.\n",
    "- The **accuracy** and **confusion matrix** show how well the model performs. Results show the model is very accurate.\n",
    "\n",
    "The test accuracy is 99.48%, meaning that almost all wines in the test set were classified correctly. The confusion matrix confirms this: only 6 white wines were incorrectly predicted as red, and 4 red wines were incorrectly predicted as white. These results indicate that the physicochemical properties in the dataset (such as density, alcohol, and sulfur dioxide levels) provide a strong and easily separable signal between the two wine types. Overall, the model offers highly reliable classification performance for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82629f-43fd-4272-a4a2-97addd6614b6",
   "metadata": {},
   "source": [
    "### Problem 2. Voices\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p02_voice.csv) is some data on human voices ([column info](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p02_voice.txt)).\n",
    " \n",
    "Predict the label from the other fields using a support vector machine.\n",
    "\n",
    "Split train/test set 70/30 %.\n",
    "\n",
    "Print the score and the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15b096-f066-43e9-ad9b-dd61453fb69f",
   "metadata": {},
   "source": [
    "#### Task clarification\n",
    "\n",
    "The task is to predict the **voice label** (male / female) from acoustic features using a Support Vector Machine (SVM).  \n",
    "The given dataset `exrc06p02_voice.csv` is used. The data is split into a training set and a test set (70/30), and the model performance is evaluated using accuracy and a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2562dbb-e574-4f95-a33f-f86988bb7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd41406-4fc2-442f-80e3-d62c7d9a6dbf",
   "metadata": {},
   "source": [
    "#### 2. Loading and inspecting the data\n",
    "\n",
    "The CSV file `exrc06p02_voice.csv` is loaded into a pandas DataFrame.  \n",
    "The first rows and basic information about the columns are shown to verify that the data has been read correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef20ccc3-1dc4-4164-b30f-ab5fdc917df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       " 0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       " 1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       " 2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       " 3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       " 4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       " \n",
       "           kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       " 0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       " 1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       " 2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       " 3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       " 4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       " \n",
       "      maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       " 0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       " 1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       " 2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       " 3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       " 4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       " \n",
       " [5 rows x 21 columns],\n",
       " None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the voice dataset\n",
    "file_path = 'exrc06p02_voice.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show first rows and basic info\n",
    "df.head(), df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb9a76-c156-4b48-a496-f2e51d681a07",
   "metadata": {},
   "source": [
    "#### 3. Separating features and target\n",
    "\n",
    "The column `label` contains the class (male/female).  \n",
    "All other columns are used as input features for the model.\n",
    "\n",
    "* `X` contains all feature columns.  \n",
    "* `y` contains the target labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42ebbede-a959-48c0-a115-ce7f7194574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3168, 20), (3168,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3a501-e706-4f62-86f4-92b4cc630361",
   "metadata": {},
   "source": [
    "#### 4. Train/test split (70/30)\n",
    "\n",
    "The data is split into training and test sets:\n",
    "\n",
    "* 70% of the data is used for training the model.  \n",
    "* 30% of the data is used for testing.  \n",
    "\n",
    "The `stratify` parameter is used to keep the class distribution similar in both sets, ie. the same proportion of each class (male/female) is kept in both the training and test sets.\n",
    "A fixed `random_state` is used so that the split is reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c7d91e5-9ad6-4a82-83e9-39b082b32b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2217, 20), (951, 20))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a234d-4405-4edd-9cca-8bd514bdce5d",
   "metadata": {},
   "source": [
    "#### 5. Feature scaling\n",
    "\n",
    "Support Vector Machines are sensitive to the scale of the features.  \n",
    "Therefore, standardization is applied so that each feature has mean 0 and standard deviation 1.\n",
    "\n",
    "* The scaler is **fitted** using only the training data.  \n",
    "* The same transformation is then **applied** to both training and test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba5a9801-9918-4fdd-88fd-55d8839c64a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.33976135,  1.86998758, -3.89359252, -2.81034902, -3.43832933,\n",
       "         1.33029263,  1.3438502 ,  0.3916648 , -1.36467551,  0.21056682,\n",
       "        -2.09064132, -3.33976135, -1.44927114, -1.0398237 , -0.29012984,\n",
       "        -1.12694529, -0.70589169,  0.35770462,  0.37037954, -0.90144033],\n",
       "       [-0.56447353,  0.60409484,  0.09212436, -0.75069486, -0.50326088,\n",
       "         0.58289193, -0.2012391 , -0.20076542,  0.70567727,  0.79168467,\n",
       "         0.61312288, -0.56447353, -1.22048632, -0.22237399, -0.29012984,\n",
       "        -0.79123821, -0.70589169, -1.25762982, -1.24559682,  0.74321158],\n",
       "       [ 0.16084766, -0.60318431, -0.24835739,  0.36721053, -0.18502088,\n",
       "        -0.52145344, -0.18975906, -0.20250995, -0.27549667, -0.27598092,\n",
       "        -0.07767985,  0.16084766,  0.32636631,  0.62261449,  0.61577302,\n",
       "         0.92894687, -0.45788707,  0.57117525,  0.5795318 , -0.14501822]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both train and test sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled[:3]  # show first 3 scaled rows as a check\n",
    "\n",
    "# The values (positive and negative) indicate how far each observation is from the mean in units of standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb983284-cb84-4be9-8d96-a78b325bfab0",
   "metadata": {},
   "source": [
    "#### 6. Training the Support Vector Machine model\n",
    "\n",
    "An SVM classifier with an RBF kernel is created and trained on the scaled training data. \n",
    "- A Support Vector Machine is a machine-learning model that tries to separate the classes (male vs female) as well as possible.\n",
    "- The kernel tells the SVM how it is allowed to draw the boundary between the classes.\n",
    "- RBF kernel = allows curved and flexible boundaries\n",
    "- `kernel='rbf'` is a common default choice for non-linear decision boundaries.  \n",
    "\n",
    "Good when the relationship between features and the class is not a straight line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ce8178be-e8f1-4fd6-88a3-2fb477ea4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f89e5-2a17-41fe-8c75-92d4e6aa2778",
   "metadata": {},
   "source": [
    "#### 7. Making predictions and calculating accuracy\n",
    "\n",
    "The trained model is used to predict labels for the test set.  \n",
    "The predictions are compared with the true labels to calculate the **accuracy score**, which gives the proportion of correctly classified samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "436d0855-33d8-4f59-807e-8ba6eaab61c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9832\n"
     ]
    }
   ],
   "source": [
    "# Predictions for the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d6618-19f6-4be0-9399-1c19cc992556",
   "metadata": {},
   "source": [
    "## 8. Confusion matrix\n",
    "\n",
    "The confusion matrix shows how many samples of each class were predicted correctly or incorrectly.\n",
    "\n",
    "For a binary classification problem with labels `[male, female]`, the matrix has the form:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "TN & FP \\\\\n",
    "FN & TP\n",
    "\\end{bmatrix}\n",
    "\n",
    "* **TN (True Negative)** – male predicted as male  \n",
    "* **FP (False Positive)** – male predicted as female  \n",
    "* **FN (False Negative)** – female predicted as male  \n",
    "* **TP (True Positive)** – female predicted as female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84cf51cf-4470-4f5b-adfd-4be33507e519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[468,   7],\n",
       "       [  9, 467]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=['male', 'female'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f392f-2f23-4baf-83ac-fc8cb0a7f529",
   "metadata": {},
   "source": [
    "#### Intepretation & conclusions\n",
    "\n",
    "- 468 male voices were correctly classified as male (TN)\n",
    "\n",
    "- 467 female voices were correctly classified as female (TP)\n",
    "\n",
    "- 7 male voices were incorrectly classified as female (FP)\n",
    "\n",
    "- 9 female voices were incorrectly classified as male (FN)\n",
    "\n",
    "Overall meaning\n",
    "\n",
    "The model makes very few mistakes (only 16 out of 951 test samples). Both classes (male / female) are predicted almost equally well. This confirms that the SVM model is performing accurately, which matches the high accuracy score (~0.983).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc3925-ea46-4069-a059-1adc344dd929",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problem 3. NBA\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p03_nba.csv) is some data on NBA basketball players in their first season ([column info](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p03_nba.csv)).\n",
    "\n",
    "The last column tells if a player's career has exceed 5 years or not.\n",
    "\n",
    "Fill any missing values with the field median.\n",
    "\n",
    "Try to predict if the career has exceeded 5 years or not by using both logistic regression and a support vector machine. Print scores and confusion matrices. Split train/test data as you wish. Compare the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f9db79-0405-46b1-9606-295f15911d9c",
   "metadata": {},
   "source": [
    "#### 1. Imports\n",
    "\n",
    "Load the csv into Pandas DF and check the first rows of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88093528-2aa0-4ba9-a3db-9060e862d66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0   Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1  Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2   JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3      Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4      Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "\n",
       "   FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0  2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3          0.0  \n",
       "1  3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6          0.0  \n",
       "2  1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0          0.0  \n",
       "3  1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0          1.0  \n",
       "4  1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8          1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "df = pd.read_csv('exrc06p03_nba.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f7b9a-3366-4330-b09c-99e7cc0e7435",
   "metadata": {},
   "source": [
    "#### 2. Handling Missing Values\n",
    "Missing values are replaced with the **median**, which is the middle value. This is a simple method that is not affected by extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1128bf28-8501-4016-8e7b-ce924347984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name           0\n",
       "GP             0\n",
       "MIN            0\n",
       "PTS            0\n",
       "FGM            0\n",
       "FGA            0\n",
       "FG%            0\n",
       "3P Made        0\n",
       "3PA            0\n",
       "3P%            0\n",
       "FTM            0\n",
       "FTA            0\n",
       "FT%            0\n",
       "OREB           0\n",
       "DREB           0\n",
       "REB            0\n",
       "AST            0\n",
       "STL            0\n",
       "BLK            0\n",
       "TOV            0\n",
       "TARGET_5Yrs    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620df204-5245-46ab-8cae-f59fe488b445",
   "metadata": {},
   "source": [
    "#### 3. Selecting Features and Target\n",
    "The model predicts the column `TARGET_5Yrs`. The text column `Name` is removed from the features because machine learning models require numeric inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "009d8d1f-d985-498f-baa2-f42c4fbcb4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  1.6  2.3  69.9   0.7   \n",
       "1  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  2.6  3.4  76.5   0.5   \n",
       "2  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  0.9  1.3  67.0   0.5   \n",
       "3  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  0.9  1.3  68.9   1.0   \n",
       "4  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  1.3  1.9  67.4   1.0   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  \n",
       "0   3.4  4.1  1.9  0.4  0.4  1.3  \n",
       "1   2.0  2.4  3.7  1.1  0.5  1.6  \n",
       "2   1.7  2.2  1.0  0.5  0.3  1.0  \n",
       "3   0.9  1.9  0.8  0.6  0.1  1.0  \n",
       "4   1.5  2.5  0.3  0.3  0.4  0.8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['Name', 'TARGET_5Yrs'])\n",
    "y = data['TARGET_5Yrs']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b757d8-bb16-4a08-8c46-7269f82da48e",
   "metadata": {},
   "source": [
    "#### 4. Train–Test Split\n",
    "The data are divided into two parts:\n",
    "- **Training set**: used to teach the model.\n",
    "- **Test set**: used to evaluate the model.\n",
    "\n",
    "Stratification keeps the class proportions similar in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d4edde6-2669-4d14-9ae3-68720128b3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET_5Yrs\n",
       "1.0    0.620336\n",
       "0.0    0.379664\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f1e07-3234-49d9-a877-5ab011b45e26",
   "metadata": {},
   "source": [
    "##### Intepretation\n",
    "\n",
    "- 62% of the players in the training set had a career longer than 5 years (TARGET_5Yrs = 1)\n",
    "\n",
    "- 38% of the players in the training set had a career 5 years or less (TARGET_5Yrs = 0)\n",
    "\n",
    "\n",
    "The dataset is imbalanced: there are more long-career players than short-career players. Because stratify=y is used, this proportion is kept the same in both the training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab25b52-a9df-4ffd-bc21-fe68896b8bc3",
   "metadata": {},
   "source": [
    "#### 5. Feature Scaling\n",
    "Some models work better when all numbers are on a similar scale. Standardisation changes each column so that it has mean 0 and standard deviation 1. This helps SVM especially, and improves stability of Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3a21eae-ef0d-4578-9e85-f0a5e9a4d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9aaab-4389-4007-b095-0ffd6bccbd6d",
   "metadata": {},
   "source": [
    "#### 6. Logistic Regression\n",
    "Logistic regression is a simple classification model. It predicts the probability that a player belongs to class 1 (career > 5 years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38d9f04d-e8e2-46c4-a0cd-2b8ee697cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7201492537313433\n",
      "[[ 55  47]\n",
      " [ 28 138]]\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "pred_log = log_reg.predict(X_test_scaled)\n",
    "print('Accuracy:', accuracy_score(y_test, pred_log))\n",
    "print(confusion_matrix(y_test, pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441bbbc4-1c1d-47e2-b84a-7f147b0621cd",
   "metadata": {},
   "source": [
    "##### Intepretation\n",
    "\n",
    "- 55 players were correctly predicted as short careers → true negatives\n",
    "- 47 players were predicted incorrectly as long careers → false positives\n",
    "- 138 players correctly predicted as long careers → true positives\n",
    "- 28 players predicted incorrectly as short careers → false negatives\n",
    "\n",
    "The model is much better at identifying long-career players. This makes sense because the dataset contains more long-career players."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36152787-47cf-490d-9dfa-020f56d93436",
   "metadata": {},
   "source": [
    "#### 7. Support Vector Machine (SVM)\n",
    "SVM tries to draw a boundary that separates the two classes as well as possible. It can form more flexible shapes than logistic regression, which may improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b93cbcd-1b38-41af-a2e8-5469facf57c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7313432835820896\n",
      "[[ 55  47]\n",
      " [ 25 141]]\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='rbf', random_state=42)\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "pred_svm = svm_clf.predict(X_test_scaled)\n",
    "print('Accuracy:', accuracy_score(y_test, pred_svm))\n",
    "print(confusion_matrix(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea652d-7d0e-45e3-88bd-2cca450f5c2c",
   "metadata": {},
   "source": [
    "##### Intepretation\n",
    "\n",
    "- 55 players correctly predicted as short-career\n",
    "- 47 players incorrectly predicted as long-career\n",
    "- 141 players correctly predicted as long-career\n",
    "- 25 players incorrectly predicted as short-career\n",
    "\n",
    "SVM does not improve short-career predictions. Misses fewer long-career players.\n",
    "\n",
    "SVM performs slightly better for this dataset, mainly because it is more flexible and can capture non-linear relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7cb45-cf7b-4e22-bdd4-1d16e2e3f003",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "The results suggest that first-season player statistics contain meaningful information for predicting future NBA career length. While both models performed well, SVM produced slightly better classification results. Further improvements could involve tuning model parameters, experimenting with class weights, or testing additional algorithms such as Random Forest or Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670cdbf-167d-45b5-b2b3-24e1bc8ae4e6",
   "metadata": {},
   "source": [
    "### Problem 4.  Mushrooms\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p04_mushrooms.csv) is some data on mushrooms ([column info](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p04_mushrooms.txt)).\n",
    "\n",
    "Try to predict the class (edible or poisonous) from the other fields. Use whatever you want!\n",
    "\n",
    "Fields are categorial so one-hot-encoding (or dummy encoding) is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638eb310-ecb5-4da5-b985-efa8eecf3f0d",
   "metadata": {},
   "source": [
    "#### Task clarification\n",
    "\n",
    "Steps:\n",
    "\n",
    "- load the mushroom data\n",
    "- one‑hot encode (dummy encode) the categorical variables. One-hot encoding = converting each category into separate 0/1 columns so ML models can use the data.\n",
    "- train a classification model to predict whether a mushroom is **edible** or **poisonous**\n",
    "- evaluate the model and interpret the results briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae687c-3405-40fb-9f22-7ac90e88b6a9",
   "metadata": {},
   "source": [
    "#### 1. Imports, load & check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5fc34fe-8a5b-4197-b729-fcc220126e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting (optional small checks)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit‑learn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a04e12eb-5b66-49cf-9826-c38053ca981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the mushroom data\n",
    "file_path = 'exrc06p04_mushrooms.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Print first rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700aa67d-797e-4871-afc7-36a8eb07ecc7",
   "metadata": {},
   "source": [
    "Each row describes one mushroom. Columns are coded with single letters. The column `class` is the target:\n",
    "\n",
    "- `e` = edible\n",
    "- `p` = poisonous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a797f7-f5c3-4ab5-bfb8-134c5071bab7",
   "metadata": {},
   "source": [
    "#### 2. Basic exploration\n",
    "\n",
    "Some quick checks are done to understand the data shape and the class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "638bfe1e-814d-4b80-90cd-518bb15fcd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the dataset (rows, columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04aa3f86-7e9e-422e-8dc0-845c910af3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "e    4208\n",
       "p    3916\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many edible vs poisonous mushrooms there are\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd06fe0-d91c-4153-9263-4944a231ec2d",
   "metadata": {},
   "source": [
    "The classes seem to be relatively balanced, which is good for training a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32d67a-ba81-4859-9cf7-dcd6170dfc83",
   "metadata": {},
   "source": [
    "#### 3. Categorical variables and one‑hot encoding\n",
    "\n",
    "All input columns (cap shape, color, odor, etc.) are **categorical**. This means that the values are labels or categories (`'b'`, `'c'`, `'x'`, ...) instead of numeric values.\n",
    "\n",
    "For machine‑learning purposes the categories must be converted to numbers (**one‑hot encoding**):\n",
    "\n",
    "- One new column is created for each possible category, e.g. `cap-shape_bell`, `cap-shape_flat`, ...\n",
    "- A row gets value 1 in the column that matches its category and 0 in all others.\n",
    "\n",
    "In this notebook one‑hot encoding is done with `pandas.get_dummies`, which is a simple wrapper around this idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40a0ed-0645-4f24-a2d5-44bdbb6bf41b",
   "metadata": {},
   "source": [
    "##### 3.1 Split into features and target\n",
    "\n",
    "The target `y` is the mushroom class (edible / poisonous). All other columns are used as features `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71f3527c-da20-4f65-b4fb-02710f14de69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cap-shape cap-surface cap-color bruises odor gill-attachment gill-spacing  \\\n",
       "0         x           s         n       t    p               f            c   \n",
       "1         x           s         y       t    a               f            c   \n",
       "2         b           s         w       t    l               f            c   \n",
       "3         x           y         w       t    p               f            c   \n",
       "4         x           s         g       f    n               f            w   \n",
       "\n",
       "  gill-size gill-color stalk-shape  ... stalk-surface-below-ring  \\\n",
       "0         n          k           e  ...                        s   \n",
       "1         b          k           e  ...                        s   \n",
       "2         b          n           e  ...                        s   \n",
       "3         n          n           e  ...                        s   \n",
       "4         b          k           t  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a5de3-2efe-4398-aae8-1eced54339bb",
   "metadata": {},
   "source": [
    "##### 3.2 Apply one‑hot encoding with `get_dummies`\n",
    "\n",
    "`pandas.get_dummies` creates the dummy / one‑hot‑encoded columns automatically. The parameter `drop_first=True` drops one category per original column to avoid perfectly collinear columns, which often helps models like logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15b7aee9-d437-4dac-873c-4e97d4b3e076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape_c</th>\n",
       "      <th>cap-shape_f</th>\n",
       "      <th>cap-shape_k</th>\n",
       "      <th>cap-shape_s</th>\n",
       "      <th>cap-shape_x</th>\n",
       "      <th>cap-surface_g</th>\n",
       "      <th>cap-surface_s</th>\n",
       "      <th>cap-surface_y</th>\n",
       "      <th>cap-color_c</th>\n",
       "      <th>cap-color_e</th>\n",
       "      <th>...</th>\n",
       "      <th>population_n</th>\n",
       "      <th>population_s</th>\n",
       "      <th>population_v</th>\n",
       "      <th>population_y</th>\n",
       "      <th>habitat_g</th>\n",
       "      <th>habitat_l</th>\n",
       "      <th>habitat_m</th>\n",
       "      <th>habitat_p</th>\n",
       "      <th>habitat_u</th>\n",
       "      <th>habitat_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-shape_c  cap-shape_f  cap-shape_k  cap-shape_s  cap-shape_x  \\\n",
       "0        False        False        False        False         True   \n",
       "1        False        False        False        False         True   \n",
       "2        False        False        False        False        False   \n",
       "3        False        False        False        False         True   \n",
       "4        False        False        False        False         True   \n",
       "\n",
       "   cap-surface_g  cap-surface_s  cap-surface_y  cap-color_c  cap-color_e  ...  \\\n",
       "0          False           True          False        False        False  ...   \n",
       "1          False           True          False        False        False  ...   \n",
       "2          False           True          False        False        False  ...   \n",
       "3          False          False           True        False        False  ...   \n",
       "4          False           True          False        False        False  ...   \n",
       "\n",
       "   population_n  population_s  population_v  population_y  habitat_g  \\\n",
       "0         False          True         False         False      False   \n",
       "1          True         False         False         False       True   \n",
       "2          True         False         False         False      False   \n",
       "3         False          True         False         False      False   \n",
       "4         False         False         False         False       True   \n",
       "\n",
       "   habitat_l  habitat_m  habitat_p  habitat_u  habitat_w  \n",
       "0      False      False      False       True      False  \n",
       "1      False      False      False      False      False  \n",
       "2      False       True      False      False      False  \n",
       "3      False      False      False       True      False  \n",
       "4      False      False      False      False      False  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One‑hot encode all categorical features\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "300bedbc-be96-4b82-84ff-06f5bc3ed5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 95)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the new shape after encoding\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6c8f8-48ce-4ec2-bf4d-845b85d898d0",
   "metadata": {},
   "source": [
    "#### 4. Train–test split\n",
    "\n",
    "Same method as in previous solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b74b1d9-ae62-428b-8055-e6fef8514f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6499, 95), (1625, 95))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c857a75-c6da-4eb0-8f1d-7f816f47d4cd",
   "metadata": {},
   "source": [
    "#### 5. Model: Logistic regression\n",
    "\n",
    "A **logistic regression** classifier is used. It models the probability that a mushroom is poisonous versus edible.\n",
    "\n",
    "Key ideas:\n",
    "- Input features are combined linearly.\n",
    "- The result is passed through an S‑shaped (sigmoid) function to give a probability between 0 and 1.\n",
    "- A probability above 0.5 is classified as one class, below as the other.\n",
    "\n",
    "The `max_iter` parameter is increased to make sure the optimisation converges with many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d3370da-8fe0-4fd9-a992-188fd2c5dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d494efe-cca0-410d-b071-9e2b87753145",
   "metadata": {},
   "source": [
    "#### 6. Model evaluation\n",
    "\n",
    "The classifier is evaluated on the test set using accuracy and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce4b008a-07ea-4907-a07d-8ca465e5438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# Predictions for the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d01f6ee-8ac3-42f0-b3c5-b202598afa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['e', 'p'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['edible (e)', 'poisonous (p)'])\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix – logistic regression on mushrooms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d7c0290-7906-49ee-8f33-22836d158a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      edible       1.00      1.00      1.00       842\n",
      "   poisonous       1.00      1.00      1.00       783\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More detailed classification metrics\n",
    "print(classification_report(y_test, y_pred, target_names=['edible', 'poisonous']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e2b205-b10c-4dcf-98c7-2fc8bd161894",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 7. Interpretation\n",
    "\n",
    "Accuracy:\n",
    "\n",
    "- The test accuracy is 0.9988 (99.88%). This means the model correctly classifies almost every mushroom as edible or poisonous.\n",
    "\n",
    "Confusion matrix:\n",
    "\n",
    "- The model correctly classified 842 edible mushrooms\n",
    "- It mislabeled 0 edible mushrooms as poisonous\n",
    "- The model correctly classified 781 poisonous mushrooms\n",
    "- It mislabeled 2 poisonous mushrooms as edible\n",
    "\n",
    "→ The 2 poisonous mushrooms predicted as edible (bottom-left corner). Mistake could be critical because the model would \"let through\" a poisonous mushroom.\n",
    "\n",
    "Classification:\n",
    "Both classes have:\n",
    "- precision = 1.00 / recall = 1.00 / f1-score = 1.00\n",
    "\n",
    "→ The model almost never predicts a wrong class. It also finds almost all poisonous mushrooms correctly.\n",
    "\n",
    "The dataset is very easy to learn, so the model performs nearly perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf511d-2bff-4d3b-8cd3-2231732df527",
   "metadata": {},
   "source": [
    "### Problem 5. Loan status\n",
    "[Here](https://student.labranet.jamk.fi/~varpha/data_analytics/exrc06p05_loan.txt) is some data on loanees. The last column (Loan_Status Y/N) should be predicted from the other fields. Use whatever you want.  \n",
    "\n",
    "\n",
    "Do modifications:\n",
    "* categorial fields to numeric (two-value fields to 0/1, multivalue as dummies/onehot)\n",
    "* replace missing values with median\n",
    "* remove rows with outliers: ApplicantIncome, CoapplicantIncome or LoanAmount over 3 standard deviations away from field average\n",
    "\n",
    "\n",
    "Check what would be model's probability to Loan_status = Yes with values:\n",
    "\n",
    "```\n",
    "Gender                   Male\n",
    "Married                    No\n",
    "Dependents                  0\n",
    "Education            Graduate\n",
    "Self_Employed              No\n",
    "ApplicantIncome          2400\n",
    "CoapplicantIncome        2000\n",
    "LoanAmount                 36\n",
    "Loan_Amount_Term          360\n",
    "Credit_History              1\n",
    "Property_Area           Urban\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31c9e9-8145-4560-934d-93ee0f141f52",
   "metadata": {},
   "source": [
    "\n",
    "#### Task clarification\n",
    "\n",
    "*Loan_Status* (Y/N) is predicted from the other fields in the loan dataset.\n",
    "Steps:\n",
    "\n",
    "- Categorical fields are converted to numeric  \n",
    "  - two–value fields are encoded as 0/1  \n",
    "  - multi–value fields are converted to dummy variables (one-hot)\n",
    "- Missing values are replaced with the **median** for numeric variables and **most frequent value** for categorical variables\n",
    "- Rows with outliers in `ApplicantIncome`, `CoapplicantIncome` or `LoanAmount`  \n",
    "  (values more than 3 standard deviations away from the mean) are removed\n",
    "\n",
    "After preprocessing, a **logistic regression** classification model is trained and used to estimate\n",
    "the probability that a new customer will have `Loan_Status = Yes`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe95b9-ea14-4c09-9b31-b756042d5ac3",
   "metadata": {},
   "source": [
    "#### 1. Imports, load & quick check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7e9e694-d68a-4ae0-a3c0-3363cef82bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married  Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No         0.0      Graduate            No   \n",
       "1  LP001003   Male     Yes         1.0      Graduate            No   \n",
       "2  LP001005   Male     Yes         0.0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes         0.0  Not Graduate            No   \n",
       "4  LP001008   Male      No         0.0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting (for check)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn tools for modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load the csv as Pandas DP \n",
    "data_path = \"exrc06p05_loan.txt\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Quick check of the dataset\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec771cd-d400-4199-a909-cc606ab0ae90",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Preprocessing\n",
    "\n",
    "In this step the following operations are carried out:\n",
    "\n",
    "- Target variable `Loan_Status` is encoded to 1 (Y) and 0 (N)\n",
    "- Binary categorical variables are mapped to 0/1\n",
    "    - `Gender` (Male/Female)\n",
    "    - `Married` (Yes/No)\n",
    "    - `Education` (Graduate/Not Graduate)\n",
    "    - `Self_Employed` (Yes/No)\n",
    "- Categorical variables with more than two values\n",
    "    - `Dependents`\n",
    "    - `Property_Area`\n",
    "  are kept as strings for later one-hot encoding.\n",
    "- Numeric columns that may contain missing values are converted to numeric and imputed with the **median**.\n",
    "- Categorical columns with missing values are filled with the **most frequent** value in that column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b681b5f-8e0e-4bc2-96d3-a2396312ef12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Gender               0\n",
       "Married              0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "Dependents           0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy to keep the original data untouched\n",
    "data = df.copy()\n",
    "\n",
    "# 1. Encode target variable Loan_Status (Y -> 1, N -> 0)\n",
    "data[\"Loan_Status\"] = data[\"Loan_Status\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "# 2. Encode binary categorical variables to 0/1\n",
    "binary_maps = {\n",
    "    \"Gender\": {\"Male\": 1, \"Female\": 0},\n",
    "    \"Married\": {\"Yes\": 1, \"No\": 0},\n",
    "    \"Education\": {\"Graduate\": 1, \"Not Graduate\": 0},\n",
    "    \"Self_Employed\": {\"Yes\": 1, \"No\": 0},\n",
    "}\n",
    "\n",
    "for col, mapping in binary_maps.items(): # Turns text categories into numbers\n",
    "    data[col] = data[col].map(mapping)\n",
    "\n",
    "# 3. Prepare 'Dependents': keep as category, ensure '3+' is treated as its own value\n",
    "# Missing values are handled later\n",
    "data[\"Dependents\"] = data[\"Dependents\"].astype(str)\n",
    "data[\"Dependents\"].replace(\"nan\", np.nan, inplace=True)  # turn \"nan\" strings back to NaN\n",
    "\n",
    "# 4. Convert numeric columns that may contain non-numeric values and impute with median\n",
    "numeric_cols = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\",\n",
    "                \"Loan_Amount_Term\", \"Credit_History\"]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Force to numeric, turn problematic values into NaN\n",
    "    data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "    # Replace missing with median\n",
    "    median_value = data[col].median()\n",
    "    data[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# 5. Fill missing values in remaining columns\n",
    "# For binary 0/1 columns: fill with median (equivalent to majority value)\n",
    "bin_cols = [\"Gender\", \"Married\", \"Education\", \"Self_Employed\"]\n",
    "for col in bin_cols:\n",
    "    median_value = data[col].median()\n",
    "    data[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# For multi-category string columns: use most frequent value (mode)\n",
    "cat_cols = [\"Dependents\", \"Property_Area\"]\n",
    "for col in cat_cols:\n",
    "    mode_value = data[col].mode()[0]\n",
    "    data[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Confirm that there are no missing values in the columns used\n",
    "data[numeric_cols + bin_cols + cat_cols + [\"Loan_Status\"]].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b65d4-81ee-4f7f-8316-c78cff1f494e",
   "metadata": {},
   "source": [
    "**Intepretation**: No missing values in the data anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad84c6a-dd88-45c5-85e6-d9693009ec36",
   "metadata": {},
   "source": [
    "\n",
    "#### 3. Removing outliers\n",
    "\n",
    "Rows with very extreme values in income or loan amounts can dominate the model.\n",
    "Here rows are removed where **any** of the following columns is more than\n",
    "3 standard deviations away from its mean:\n",
    "\n",
    "- `ApplicantIncome`\n",
    "- `CoapplicantIncome`\n",
    "- `LoanAmount`\n",
    "\n",
    "This is done using a simple z-score rule. This tells how many standard deviations a value is from the average. Intepretation:\n",
    "\n",
    "z = 0 → value is exactly average\n",
    "z = 1 → 1 standard deviation above average\n",
    "z = −1 → 1 standard deviation below average\n",
    "z = 4 → VERY high value\n",
    "z = −4 → VERY low value\n",
    "\n",
    "Why ±3 SD is chosen in the task? 99.7% of all normal data is within ±3 SD. This is a common statistical rule: anything outside this range is considered unusual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bdea5c2-be1d-48be-8c34-8d0ba1f52801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 981\n",
      "Rows after outlier removal: 943\n"
     ]
    }
   ],
   "source": [
    "# Columns used for outlier detection\n",
    "outlier_cols = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\"]\n",
    "\n",
    "# Compute z-scores and keep rows where all |z| <= 3\n",
    "z_scores = []\n",
    "for col in outlier_cols:\n",
    "    mean = data[col].mean()\n",
    "    std = data[col].std()\n",
    "    z = (data[col] - mean) / std\n",
    "    z_scores.append(z)\n",
    "\n",
    "z_scores = np.vstack(z_scores).T  # shape (n_samples, n_cols)\n",
    "\n",
    "mask = np.all(np.abs(z_scores) <= 3, axis=1)\n",
    "\n",
    "print(\"Original rows:\", data.shape[0])\n",
    "print(\"Rows after outlier removal:\", mask.sum())\n",
    "\n",
    "data_clean = data[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fd457-15b5-452e-ba44-164fa9d17d0f",
   "metadata": {},
   "source": [
    "\n",
    "#### 4. One-hot encoding for multi-valued categorical variables\n",
    "\n",
    "Dependents and Property_Area have more than two distinct categories (checked using unique()), therefore they need dummy/one-hot encoding. Binary variables with only two categories (Yes/No, Male/Female) can be mapped directly to 0/1.\n",
    "\n",
    "After this step the data are ready for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c4ffc8e-89a3-4194-b5b7-62c202f9f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after one-hot encoding:\n",
      "Index(['Loan_ID', 'Gender', 'Married', 'Education', 'Self_Employed',\n",
      "       'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
      "       'Loan_Amount_Term', 'Credit_History', 'Loan_Status', 'Dependents_1.0',\n",
      "       'Dependents_2.0', 'Dependents_3.0', 'Property_Area_Semiurban',\n",
      "       'Property_Area_Urban'],\n",
      "      dtype='object')\n",
      "Feature matrix shape: (943, 14)\n",
      "Target vector shape: (943,)\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables for Dependents and Property_Area\n",
    "data_model = pd.get_dummies(\n",
    "    data_clean,\n",
    "    columns=[\"Dependents\", \"Property_Area\"],\n",
    "    drop_first=True,  # avoid redundant first category\n",
    ")\n",
    "\n",
    "print(\"Columns after one-hot encoding:\")\n",
    "print(data_model.columns)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data_model.drop(columns=[\"Loan_ID\", \"Loan_Status\"])\n",
    "y = data_model[\"Loan_Status\"]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target vector shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256d3ad-1e10-489e-8672-9296aca05a04",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. Train–test split and logistic regression model\n",
    "\n",
    "The cleaned data are split into training and test sets:\n",
    "\n",
    "- 80% of the data are used for training\n",
    "- 20% are kept for testing the model\n",
    "\n",
    "A **logistic regression** classifier is then fitted. Model quality is checked with accuracy score and a confusion matrix. Similar operation as in previous tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7064498-dcd2-4b14-9183-48bc8dc6283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.868\n",
      "Confusion matrix:\n",
      " [[ 27  24]\n",
      " [  1 137]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.53      0.68        51\n",
      "           1       0.85      0.99      0.92       138\n",
      "\n",
      "    accuracy                           0.87       189\n",
      "   macro avg       0.91      0.76      0.80       189\n",
      "weighted avg       0.88      0.87      0.85       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data (stratify keeps the Y/N ratio similar in both sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Create and fit logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Test accuracy:\", round(acc, 3))\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5704f37-aa84-476f-b63a-35a590fabea9",
   "metadata": {},
   "source": [
    "**Intepretation**: The logistic regression model performs well (87% accuracy). It predicts loan approvals very reliably (high recall for class 1),\n",
    "but it has more difficulty identifying rejected applications (lower recall for class 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1454ee5-eb8f-4782-b545-f663e2025bc3",
   "metadata": {},
   "source": [
    "\n",
    "#### 6. Probability for given customer\n",
    "\n",
    "The task asks for the model's probability that `Loan_Status = Yes`\n",
    "for the customer given in the task description. The same preprocessing steps are applied to this single example \n",
    "so that its feature vector matches the columns used to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f78e1f6d-8f22-4f16-bf7e-e1826f9b13e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability of Loan_Status = 'Yes': 0.837\n"
     ]
    }
   ],
   "source": [
    "# Define the raw input as given in the task\n",
    "new_customer = {\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Married\": \"No\",\n",
    "    \"Dependents\": \"0\",\n",
    "    \"Education\": \"Graduate\",\n",
    "    \"Self_Employed\": \"No\",\n",
    "    \"ApplicantIncome\": 2400,\n",
    "    \"CoapplicantIncome\": 2000,\n",
    "    \"LoanAmount\": 36,\n",
    "    \"Loan_Amount_Term\": 360,\n",
    "    \"Credit_History\": 1,\n",
    "    \"Property_Area\": \"Urban\",\n",
    "}\n",
    "\n",
    "# Convert to DataFrame with one row\n",
    "new_df = pd.DataFrame([new_customer])\n",
    "\n",
    "# --- Apply the same preprocessing steps as for the training data ---\n",
    "\n",
    "# Binary encodings (same mapping as earlier)\n",
    "new_df[\"Gender\"] = new_df[\"Gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "new_df[\"Married\"] = new_df[\"Married\"].map({\"Yes\": 1, \"No\": 0})\n",
    "new_df[\"Education\"] = new_df[\"Education\"].map({\"Graduate\": 1, \"Not Graduate\": 0})\n",
    "new_df[\"Self_Employed\"] = new_df[\"Self_Employed\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Ensure numeric types\n",
    "for col in [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\",\n",
    "            \"Loan_Amount_Term\", \"Credit_History\"]:\n",
    "    new_df[col] = pd.to_numeric(new_df[col], errors=\"coerce\")\n",
    "\n",
    "# 'Dependents' kept as string, 'Property_Area' as string for one-hot\n",
    "\n",
    "# One-hot encode Dependents and Property_Area in the same way as training data\n",
    "new_df = pd.get_dummies(new_df, columns=[\"Dependents\", \"Property_Area\"], drop_first=True)\n",
    "\n",
    "# Now we need to align this with the training feature columns\n",
    "# Any missing columns are added with value 0\n",
    "for col in X.columns:\n",
    "    if col not in new_df.columns:\n",
    "        new_df[col] = 0\n",
    "\n",
    "# And extra columns (if any) are removed\n",
    "new_df = new_df[X.columns]\n",
    "\n",
    "# Predict probability for Loan_Status = 1 (\"Yes\")\n",
    "prob_yes = log_reg.predict_proba(new_df)[0, 1]\n",
    "print(f\"Predicted probability of Loan_Status = 'Yes': {prob_yes:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a808a0-19e9-4d07-b91e-a154b15d3c36",
   "metadata": {},
   "source": [
    "#### Intepretation & conclusions\n",
    "\n",
    "Based on the model, the customer has **83.7%** probability of getting the loan approved. This is a realistic value for the given profile (Graduate, stable incomes, good credit history, small loan).\n",
    "\n",
    "The preprocessing pipeline and model training were successfully implemented. The logistic regression model seem to perform well and provides realistic probability estimates. The result for the new customer is meaningful and correctly computed according to the assignment requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
