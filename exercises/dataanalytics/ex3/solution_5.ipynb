{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gitlab\n",
    "import pandas as pd\n",
    "#import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a connection (client) to a Labranet GitLab instance usng own private access token\n",
    "gl = gitlab.Gitlab(\n",
    "    'https://gitlab.labranet.jamk.fi',\n",
    "    private_token='glpat-tJb87CJw4NTRPI78mxsvwm86MQp1OjV4cAk.01.0z0lb1oeg'\n",
    ")\n",
    "\n",
    "# Optional: authenticate explicitly\n",
    "gl.auth()\n",
    "\n",
    "\n",
    "# # This is to find what all the atttributes available on given project and write to txt file for readability\n",
    "# # I used ´data-analytics-fall-2025´ private project which I created on Problem 1\n",
    "# project_info = gl.projects.list(search='data-analytics-fall-2025')\n",
    "# if project_info:\n",
    "#     project = project_info[0]\n",
    "#     print(f\"Project ID: {project.id}, Project Name: {project.name}\")\n",
    "#     keys_list = list(project.attributes.keys())\n",
    "#     with open(\"project_attributes.txt\", \"w\") as f:\n",
    "#         for key in keys_list:\n",
    "#             f.write(key + \"\\n\")\n",
    "#         print(\"Attributes saved to project_attributes.txt\")\n",
    "# else:\n",
    "#     print(\"Project not found.\")\n",
    "\n",
    "\n",
    "# Get all the Public Projects\n",
    "projects = gl.projects.list(visibility=\"public\", iterator=True, per_page=50)\n",
    "projects_list = list(projects)\n",
    "# print(f\"Found {len(projects_list)} public projects.\")\n",
    "\n",
    "\n",
    "# \n",
    "project_data = [\n",
    "    {\n",
    "        \"id\": getattr(project, \"id\", None),\n",
    "        \"name\": getattr(project, \"name\", None),\n",
    "        \"path_with_namespace\": getattr(project, \"path_with_namespace\", None),\n",
    "        \"visibility\": getattr(project, \"visibility\", None),\n",
    "        \"star_count\": getattr(project, \"star_count\",0),\n",
    "        \"forks_count\": getattr(project, \"forks_count\", 0),\n",
    "        \"last_activity_at\": getattr(project, \"last_activity_at\", None)\n",
    "    }\n",
    "    for project in projects_list\n",
    "]\n",
    "# Create a DataFrame from the above project information ie list of dicts (data)\n",
    "df_projects = pd.DataFrame(project_data)\n",
    "\n",
    "# # Get the basic information about DataFrame\n",
    "# df_projects.info()\n",
    "\n",
    "# # Show first few rows\n",
    "# print(df_projects.head())\n",
    "\n",
    "# Change the datatype to datetime for last_activity_at column\n",
    "df_projects['last_activity_at'] = pd.to_datetime(\n",
    "    df_projects['last_activity_at'], errors='coerce'\n",
    ")\n",
    "\n",
    "# # Get the basic information about DataFrame\n",
    "# df_projects.info()\n",
    "\n",
    "# Top 5 projects by star_count\n",
    "top_starred = df_projects.sort_values(by='star_count', ascending=False).head(10)\n",
    "print(\"*************************** Top 10 Most Popular Projects by star_count ******************************\")\n",
    "print(top_starred[['id', 'name', 'star_count', 'forks_count']])\n",
    "\n",
    "# Top 5 projects by forks_count\n",
    "top_forked = df_projects.sort_values(by='forks_count', ascending=False).head(10)\n",
    "print(\"*************************** Top 10 Most Popular Projects by forks_count *****************************\")\n",
    "print(top_forked[['id', 'name', 'forks_count', 'star_count']])\n",
    "\n",
    "\n",
    "print(\"Statistical summary about star_count on projects\")\n",
    "print(df_projects['star_count'].describe())\n",
    "\n",
    "print(\"Statistical summary about forks_count on projects\")\n",
    "print(df_projects['forks_count'].describe())\n",
    "\n",
    "\n",
    "# Group by star_count\n",
    "projects_per_star_count = df_projects.groupby('star_count').size().sort_values(ascending=False)\n",
    "print(\"*************************** no of projects each star_count ***************************\")\n",
    "print(projects_per_star_count.head())\n",
    "\n",
    "# Extract group path (namespace) from project path\n",
    "# e.g., \"my-group/my-project\" → \"my-group\"\n",
    "df_projects['group_name'] = df_projects['path_with_namespace'].apply(lambda x: x.split('/')[0])\n",
    "\n",
    "# Count number of projects per group and sort on descending sequence \n",
    "projects_per_group = df_projects.groupby('group_name').size().sort_values(ascending=False)\n",
    "\n",
    "print(\"*************************** Top 5 Most Popular Groups by no of projects ***************************\")\n",
    "print(projects_per_group.head())\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.hist(df_projects['star_count'] + 1, bins=50)   # add 1 to avoid log(0)\n",
    "# plt.xscale('log')\n",
    "# plt.title('Star Count Distribution (Log Scale)')\n",
    "# plt.xlabel('Stars (log scale)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.hist(df_projects['forks_count'] + 1, bins=50)\n",
    "# plt.xscale('log')\n",
    "# plt.title('Fork Count Distribution (Log Scale)')\n",
    "# plt.xlabel('Forks (log scale)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # This is to find what all the attributes available on given group and write to txt file for readability\n",
    "# # I used ´TRASH-TESTS´ group which I got from GitLab UI\n",
    "# group_info = gl.groups.list(all_available=True, search='TRASH-TESTS') # extract info for TRASH-TESTS\n",
    "# if group_info:\n",
    "#     group = group_info[0]\n",
    "#     print(f\"Group ID: {group.id}, Group Name: {group.name}\")\n",
    "#     keys_list = list(group.attributes.keys()) # extracting only keys ie attributes\n",
    "#     with open(\"group_attributes.txt\", \"w\") as f:\n",
    "#         for key in keys_list:\n",
    "#             f.write(key + \"\\n\")\n",
    "#         print(\"Attributes saved to group_attributes.txt\")\n",
    "# else:\n",
    "#     print(\"Group not found.\")\n",
    "\n",
    "# # Get all the Public Groups\n",
    "# groups = gl.groups.list(all_available=True, visibility=\"public\", iterator=True, per_page=50)\n",
    "# groups_list = list(groups)\n",
    "# print(f\"Found {len(groups_list)} public groups.\")\n",
    "\n",
    "# # \n",
    "# group_data = [\n",
    "#     {\n",
    "#         \"id\": group.id,\n",
    "#         \"name\": group.name,\n",
    "#         \"visibility\": group.visibility,\n",
    "#         \"archived\": group.archived,\n",
    "#     }\n",
    "#     for group in groups_list\n",
    "# ]\n",
    "# # Create a DataFrame from the above project information ie list of dicts (data)\n",
    "# df_groups = pd.DataFrame(group_data)\n",
    "\n",
    "# # Get the basic information about DataFrame\n",
    "# df_groups.info()\n",
    "\n",
    "# # Show first few rows\n",
    "# print(df_groups.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # This is to find what all the atttributes available on given user and write to txt file for readability\n",
    "# # I used ´AH4323´ which my username in GitLab\n",
    "# user_info = gl.users.list(search='AH4323')\n",
    "# if user_info:\n",
    "#     user = user_info[0]\n",
    "#     print(f\"User ID: {user.id}, User Name: {user.name}\")\n",
    "#     keys_list = list(user.attributes.keys())\n",
    "#     with open(\"user_attributes.txt\", \"w\") as f:\n",
    "#         for key in keys_list:\n",
    "#             f.write(key + \"\\n\")\n",
    "#         print(\"Attributes saved to user_attributes.txt\")\n",
    "# else:\n",
    "#     print(\"User not found.\")\n",
    "\n",
    "# Get all the Users\n",
    "users = gl.users.list(iterator=True, per_page=50)\n",
    "users_list = list(users)\n",
    "print(f\"Found {len(users_list)} users.\")\n",
    "\n",
    "# Collect user information into a list of dicts\n",
    "user_data = [\n",
    "    {\n",
    "        \"id\": user.id,\n",
    "        \"name\": user.name,\n",
    "        \"state\": user.state,\n",
    "        \"locked\": user.locked,\n",
    "        \"public_email\": user.public_email\n",
    "    }\n",
    "    for user in users_list\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the above user information ie list of dicts (data)\n",
    "df_users = pd.DataFrame(user_data)\n",
    "\n",
    "# Get the basic information about DataFrame\n",
    "df_users.info()\n",
    "\n",
    "# Show first few rows\n",
    "print(df_users.head())\n",
    "\n",
    "# There are not many attributes on users data, so creating the summary with below stats\n",
    "summary = pd.DataFrame({\n",
    "    'Total Users': [len(df_users)],\n",
    "    'Active Users': [(df_users['state'] == 'active').sum()],\n",
    "    'Locked Users': [df_users['locked'].sum()],\n",
    "    'With Public Email': [df_users['public_email'].notna().sum()],\n",
    "    'Without Public Email': [df_users['public_email'].isna().sum()]\n",
    "})\n",
    "print(\"********************************** User Summary ********************************************\")\n",
    "print(summary)\n",
    "\n",
    "# # Gather information about public projects using ´gl´ GitLab Client object\n",
    "# # 'projects.list()' method queries the GitLab Projects API to list projects\n",
    "# # Used pagination by using ´iterator=True´ to retrieve projects in chunks of 50 per api call\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
