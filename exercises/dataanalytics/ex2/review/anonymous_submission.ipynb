{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebabbbab-c235-4789-a004-14e69d06ec9d",
   "metadata": {},
   "source": [
    "# Data Analytics Fall 2025 &mdash; Exercises 2\n",
    "\n",
    "### XXXXX XXXXX\n",
    "\n",
    "Last modified: Tue 16 Sep before session\n",
    "\n",
    "- Five problems + round 1 peer review\n",
    "- Theme: data wrangling with **pandas** (please use pandas in each problem)\n",
    "- Please make both your code and your notebook readable\n",
    "- Keep your originals up to date by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cde89ee5-64f7-4289-8065-d36dfc25c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuring...\n",
      "\n",
      "  created the ~/dan directory tree\n",
      "  changed all ~/dan subdir permissions to 700\n",
      "  removed any broken filelinks under ~/dan\n",
      "  copied filelinks from /home/varpha/dan to ~/dan\n",
      "  removed any python cache dirs\n",
      "  creating answers workbook (Darren's idea)\n",
      "  answers workbook /home/XXXXX/dan/private/exrc_02/exrc_02_answers.ipynb already exists, skipping copy\n",
      "\n",
      "  upgrading jupyterlab etc. (may take a while)...\n",
      "  done (you may need to restart your server in order for the upgrades to take effect)\n",
      "\n",
      "All Done!\n",
      "\n",
      "Please run this config script whenever you start working on the hub.\n",
      "\n",
      "If you encountered errors, please re-run the script. If the errors persist, please report to our Teams channel.\n",
      "\n",
      "Also, please do 'File -> Hub Control Panel -> Stop My Server'\n",
      "whenever you stop working on the hub.\n",
      "\n",
      "Thank you!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('/usr/bin/bash /home/varpha/dan/config.sh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722411d-45e4-4faa-bafa-06aa0d4bf31b",
   "metadata": {},
   "source": [
    "## Round 1 peer review\n",
    "\n",
    "- Submit your round 01 solutions in the **round 01** menu <br>\n",
    "  (run `/home/varpha/dan/menu.py` in the terminal).\n",
    "- After some effort, you should be able to access an anonymized submission of another student.\n",
    "\n",
    "Write a few paragraphs of text (plain or markdown) into your favourite text editor and submit that text in  the **round 02** menu. \n",
    "\n",
    "Please address the following issues:\n",
    " \n",
    "- Are the solutions okay? Can you understand / run the code?<br/>\n",
    "  (as opposed to some wishful brainless copy-pasting done in a hurry)\n",
    "- What do you think about the solutions? To what extent has AI been used blindly without explaining the usage?\n",
    "- How many points out of 5 do the solutions deserve as a whole?\n",
    "- How many points out of 5 would you give to yourself and why?\n",
    "- Any feedback or comments to Harri?\n",
    "  \n",
    "Harri will read and grade your reviews as follows:\n",
    "- nonexistent or nearly so = 0p\n",
    "- something written = 1-2p\n",
    "- well written 3p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe4d8d-c0fc-43f7-b336-3fc95dd0dd76",
   "metadata": {},
   "source": [
    "## Problem 1. Profiles\n",
    "\n",
    "The file `private/exrc_02/data/XXXXX_prob01_profiles.csv` contains some user profiles.\n",
    "Read the csv into a pandas DataFrame and reorganize it as follows:\n",
    "\n",
    "a) Separate the name and address columns so that there are separate columns for\n",
    "- first name\n",
    "- last name\n",
    "- street address\n",
    "- state\n",
    "- postal code.\n",
    "\n",
    "Keep also the ssn, username, sex, mail and birthdate columns. Drop all the other columns.\n",
    "\n",
    "b) Print all entries where the last name begins with the letter A, sorted by:\n",
    "- sex (ladies first)\n",
    "- state (alphabetically)\n",
    "- age (youngest first).\n",
    "\n",
    "I.e. print the entries three times, in these three different ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "39369ff9-2254-4555-b459-650b41e24fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "user = getuser()\n",
    "csv_location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob01_profiles.csv'\n",
    "df = pd.read_csv(csv_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2fee5-44ac-4aa5-a9d2-258300778b1f",
   "metadata": {},
   "source": [
    "### Problem 1a\n",
    "After observation, the full name is attached with job title. Therefore, it is neccessary to remove prefixes and suffixes such as Dr.X Y PhD.\n",
    "There are some built-in functions of pandas library supporting to handle some issue such as replace with regular expression, split with delimiter.\n",
    "Reference:\n",
    "- https://pandas.pydata.org/docs/user_guide/indexing.html#basics\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html#pandas.Series.str.replace\n",
    "- https://www.geeksforgeeks.org/python/regular-expression-python-examples/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html\n",
    "- https://pandas.pydata.org/docs/user_guide/text.html#splitting-and-replacing-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2fddd70d-d129-4699-b7d8-c6afaaebe931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first name</th>\n",
       "      <th>last name</th>\n",
       "      <th>street address</th>\n",
       "      <th>state</th>\n",
       "      <th>postal code</th>\n",
       "      <th>ssn</th>\n",
       "      <th>username</th>\n",
       "      <th>sex</th>\n",
       "      <th>mail</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "      <td>Jacobson</td>\n",
       "      <td>28344 Selena Terrace Apt. 678</td>\n",
       "      <td>RI</td>\n",
       "      <td>06215</td>\n",
       "      <td>723-29-9823</td>\n",
       "      <td>njackson</td>\n",
       "      <td>M</td>\n",
       "      <td>blakecrawford@hotmail.com</td>\n",
       "      <td>1921-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anne</td>\n",
       "      <td>Lane</td>\n",
       "      <td>0842 White Island Suite 228</td>\n",
       "      <td>VT</td>\n",
       "      <td>29347</td>\n",
       "      <td>505-07-3836</td>\n",
       "      <td>utorres</td>\n",
       "      <td>F</td>\n",
       "      <td>wendy17@yahoo.com</td>\n",
       "      <td>2003-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>06184 Cross Coves</td>\n",
       "      <td>NM</td>\n",
       "      <td>76088</td>\n",
       "      <td>873-10-3692</td>\n",
       "      <td>davidjones</td>\n",
       "      <td>M</td>\n",
       "      <td>lisa98@gmail.com</td>\n",
       "      <td>1992-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edward</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>4849 Sawyer Fork Suite 852</td>\n",
       "      <td>WY</td>\n",
       "      <td>94805</td>\n",
       "      <td>890-28-0010</td>\n",
       "      <td>ericsanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>pottsandrew@yahoo.com</td>\n",
       "      <td>1914-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colleen</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>74968 Cochran Prairie Apt. 798</td>\n",
       "      <td>DC</td>\n",
       "      <td>52775</td>\n",
       "      <td>175-68-5584</td>\n",
       "      <td>melissa90</td>\n",
       "      <td>F</td>\n",
       "      <td>moniquefrye@gmail.com</td>\n",
       "      <td>1933-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kaylee</td>\n",
       "      <td>Wallace</td>\n",
       "      <td>10661 Baker Plains</td>\n",
       "      <td>PR</td>\n",
       "      <td>75753</td>\n",
       "      <td>082-06-8931</td>\n",
       "      <td>patrickgriffin</td>\n",
       "      <td>F</td>\n",
       "      <td>lgonzalez@gmail.com</td>\n",
       "      <td>1965-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shannon</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>43737 Boyle Canyon</td>\n",
       "      <td>MN</td>\n",
       "      <td>52648</td>\n",
       "      <td>899-92-2684</td>\n",
       "      <td>robinkidd</td>\n",
       "      <td>F</td>\n",
       "      <td>kaylaadams@hotmail.com</td>\n",
       "      <td>2010-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brian</td>\n",
       "      <td>Mooney</td>\n",
       "      <td>PSC 7934, Box 1083</td>\n",
       "      <td>AA</td>\n",
       "      <td>53690</td>\n",
       "      <td>321-52-2004</td>\n",
       "      <td>jesse27</td>\n",
       "      <td>M</td>\n",
       "      <td>alexis41@hotmail.com</td>\n",
       "      <td>2010-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kyle</td>\n",
       "      <td>Ortiz</td>\n",
       "      <td>Unit 6152 Box 0015</td>\n",
       "      <td>AE</td>\n",
       "      <td>40634</td>\n",
       "      <td>675-04-9350</td>\n",
       "      <td>xavierdalton</td>\n",
       "      <td>M</td>\n",
       "      <td>david16@gmail.com</td>\n",
       "      <td>2009-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Janet</td>\n",
       "      <td>Williams</td>\n",
       "      <td>98094 Stevens Loaf</td>\n",
       "      <td>VT</td>\n",
       "      <td>76324</td>\n",
       "      <td>797-89-9067</td>\n",
       "      <td>sheilahale</td>\n",
       "      <td>F</td>\n",
       "      <td>rose59@gmail.com</td>\n",
       "      <td>1993-04-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first name last name                  street address state postal code  \\\n",
       "0        David  Jacobson   28344 Selena Terrace Apt. 678    RI       06215   \n",
       "1         Anne      Lane     0842 White Island Suite 228    VT       29347   \n",
       "2  Christopher  Robinson               06184 Cross Coves    NM       76088   \n",
       "3       Edward    Thomas      4849 Sawyer Fork Suite 852    WY       94805   \n",
       "4      Colleen     Kelly  74968 Cochran Prairie Apt. 798    DC       52775   \n",
       "5       Kaylee   Wallace              10661 Baker Plains    PR       75753   \n",
       "6      Shannon   Rogers               43737 Boyle Canyon    MN       52648   \n",
       "7        Brian    Mooney              PSC 7934, Box 1083    AA       53690   \n",
       "8         Kyle     Ortiz              Unit 6152 Box 0015    AE       40634   \n",
       "9        Janet  Williams              98094 Stevens Loaf    VT       76324   \n",
       "\n",
       "           ssn        username sex                       mail   birthdate  \n",
       "0  723-29-9823        njackson   M  blakecrawford@hotmail.com  1921-01-27  \n",
       "1  505-07-3836         utorres   F          wendy17@yahoo.com  2003-10-28  \n",
       "2  873-10-3692      davidjones   M           lisa98@gmail.com  1992-09-26  \n",
       "3  890-28-0010     ericsanchez   M      pottsandrew@yahoo.com  1914-09-27  \n",
       "4  175-68-5584       melissa90   F      moniquefrye@gmail.com  1933-05-05  \n",
       "5  082-06-8931  patrickgriffin   F        lgonzalez@gmail.com  1965-09-22  \n",
       "6  899-92-2684       robinkidd   F     kaylaadams@hotmail.com  2010-04-15  \n",
       "7  321-52-2004         jesse27   M       alexis41@hotmail.com  2010-11-17  \n",
       "8  675-04-9350    xavierdalton   M          david16@gmail.com  2009-07-20  \n",
       "9  797-89-9067      sheilahale   F           rose59@gmail.com  1993-04-04  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sprefixes and suffixes of full name is removed with regular expression  \n",
    "# Use meta-characters such as  ^ means starting with Mr. or Dr. and \\s* means any white space or no white space. If it matches then it replace with nothing.\n",
    "no_prefixes = df[\"name\"].str.replace('^(Mr.|Dr.)s*','', regex=True)\n",
    "# Remove suffixes with $ means ends with PhD or DDS ... and no white space. \n",
    "no_suffixes = no_prefixes.str.replace('s*(PhD|DDS|MD|DVM)$','', regex=True)\n",
    "#Split full name by white space and split into two columns.\n",
    "name = no_suffixes.str.split(' ', expand=True, n=1)\n",
    "#dataframe with string could be accessed with get  or [] \n",
    "df[\"first name\"] =  name[0]\n",
    "df[\"last name\"] = name[1]\n",
    "# Split the whole address into street address and the rest\n",
    "\n",
    "address =  df[\"address\"].str.split('\\n')\n",
    "df[\"street address\"] = address.str[0]\n",
    "#split the rest of address into three parts, the last one [-1] is the postal code and second last one [-2] is state\n",
    "state_code = address.str[1].str.split(' ')\n",
    "df[\"postal code\"] = state_code.str[-1]\n",
    "df[\"state\"] = state_code.str[-2]\n",
    "#combine all of field with [[field, field]] \n",
    "df = df[[\"first name\", \"last name\",\"street address\",\"state\",\"postal code\",\"ssn\",\"username\",\"sex\",\"mail\",\"birthdate\"]]\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b98b73-04ee-484a-a26d-a1b7beba182c",
   "metadata": {},
   "source": [
    "### Problem 1b\n",
    "When implementing the sorting values. It shows warning with **SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame**.\n",
    "The copy() solves the issue. It is possible to check reference.\n",
    "Preference:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html#pandas.Series.str.startswith\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#evaluation-order-matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "652550d0-2ba1-4a88-88d4-058df461aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort by ladies first:\n",
      "    first name      last name                  street address state  \\\n",
      "65      Ashley          Ayers             3471 Singh Turnpike    PW   \n",
      "116    Heather       Arellano  911 Krystal Causeway Suite 485    NM   \n",
      "187    Kaitlyn      Alexander               954 Mcguire Curve    NM   \n",
      "351             Ashley Miller              Unit 9200 Box 5692    AP   \n",
      "352      Paula        Aguirre  4411 Danielle Heights Apt. 725    MO   \n",
      "476     Hannah        Alvarez               09608 Woods Glens    IN   \n",
      "174     Joseph       Alvarado  7805 Smith Stravenue Suite 750    MS   \n",
      "269    Matthew          Allen       679 Gibson Forge Apt. 354    AL   \n",
      "281     Joseph       Alvarado               846 Sutton Bridge    GU   \n",
      "430       Carl          Adams             7971 Samantha Vista    CT   \n",
      "468    Richard        Alvarez             18980 Leslie Garden    WY   \n",
      "\n",
      "    postal code          ssn       username sex                      mail  \\\n",
      "65        21627  239-66-1517    connerbrett   F     fordannette@yahoo.com   \n",
      "116       70545  721-95-3992         zdavis   F   sharpbianca@hotmail.com   \n",
      "187       99650  144-83-0302        gfields   F  jasminebennett@yahoo.com   \n",
      "351       38533  247-38-9272         breese   F        kherring@gmail.com   \n",
      "352       02799  770-14-0862       lleonard   F         wmorris@yahoo.com   \n",
      "476       92620  201-07-7191   valeriegrant   F   martinezjimmy@gmail.com   \n",
      "174       66230  057-50-4437   michaeladams   M       susan07@hotmail.com   \n",
      "269       60926  589-34-4129        lucas23   M         wlittle@gmail.com   \n",
      "281       36145  255-01-6130      melissa38   M          lboyle@gmail.com   \n",
      "430       08003  349-79-7468          rsoto   M        samuel61@yahoo.com   \n",
      "468       72091  827-23-7191  terrygonzalez   M      kevinsmith@gmail.com   \n",
      "\n",
      "      birthdate  \n",
      "65   2019-10-29  \n",
      "116  1927-01-29  \n",
      "187  2017-06-18  \n",
      "351  1939-08-18  \n",
      "352  2013-05-21  \n",
      "476  1948-11-26  \n",
      "174  1929-03-05  \n",
      "269  2009-08-13  \n",
      "281  1923-08-21  \n",
      "430  1970-05-16  \n",
      "468  1991-11-21  \n",
      "Sort by state:\n",
      "    first name      last name                  street address state  \\\n",
      "269    Matthew          Allen       679 Gibson Forge Apt. 354    AL   \n",
      "351             Ashley Miller              Unit 9200 Box 5692    AP   \n",
      "430       Carl          Adams             7971 Samantha Vista    CT   \n",
      "281     Joseph       Alvarado               846 Sutton Bridge    GU   \n",
      "476     Hannah        Alvarez               09608 Woods Glens    IN   \n",
      "352      Paula        Aguirre  4411 Danielle Heights Apt. 725    MO   \n",
      "174     Joseph       Alvarado  7805 Smith Stravenue Suite 750    MS   \n",
      "116    Heather       Arellano  911 Krystal Causeway Suite 485    NM   \n",
      "187    Kaitlyn      Alexander               954 Mcguire Curve    NM   \n",
      "65      Ashley          Ayers             3471 Singh Turnpike    PW   \n",
      "468    Richard        Alvarez             18980 Leslie Garden    WY   \n",
      "\n",
      "    postal code          ssn       username sex                      mail  \\\n",
      "269       60926  589-34-4129        lucas23   M         wlittle@gmail.com   \n",
      "351       38533  247-38-9272         breese   F        kherring@gmail.com   \n",
      "430       08003  349-79-7468          rsoto   M        samuel61@yahoo.com   \n",
      "281       36145  255-01-6130      melissa38   M          lboyle@gmail.com   \n",
      "476       92620  201-07-7191   valeriegrant   F   martinezjimmy@gmail.com   \n",
      "352       02799  770-14-0862       lleonard   F         wmorris@yahoo.com   \n",
      "174       66230  057-50-4437   michaeladams   M       susan07@hotmail.com   \n",
      "116       70545  721-95-3992         zdavis   F   sharpbianca@hotmail.com   \n",
      "187       99650  144-83-0302        gfields   F  jasminebennett@yahoo.com   \n",
      "65        21627  239-66-1517    connerbrett   F     fordannette@yahoo.com   \n",
      "468       72091  827-23-7191  terrygonzalez   M      kevinsmith@gmail.com   \n",
      "\n",
      "      birthdate  \n",
      "269  2009-08-13  \n",
      "351  1939-08-18  \n",
      "430  1970-05-16  \n",
      "281  1923-08-21  \n",
      "476  1948-11-26  \n",
      "352  2013-05-21  \n",
      "174  1929-03-05  \n",
      "116  1927-01-29  \n",
      "187  2017-06-18  \n",
      "65   2019-10-29  \n",
      "468  1991-11-21  \n",
      "Sort by age( youngest first):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first name</th>\n",
       "      <th>last name</th>\n",
       "      <th>street address</th>\n",
       "      <th>state</th>\n",
       "      <th>postal code</th>\n",
       "      <th>ssn</th>\n",
       "      <th>username</th>\n",
       "      <th>sex</th>\n",
       "      <th>mail</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>Ayers</td>\n",
       "      <td>3471 Singh Turnpike</td>\n",
       "      <td>PW</td>\n",
       "      <td>21627</td>\n",
       "      <td>239-66-1517</td>\n",
       "      <td>connerbrett</td>\n",
       "      <td>F</td>\n",
       "      <td>fordannette@yahoo.com</td>\n",
       "      <td>2019-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Kaitlyn</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>954 Mcguire Curve</td>\n",
       "      <td>NM</td>\n",
       "      <td>99650</td>\n",
       "      <td>144-83-0302</td>\n",
       "      <td>gfields</td>\n",
       "      <td>F</td>\n",
       "      <td>jasminebennett@yahoo.com</td>\n",
       "      <td>2017-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Paula</td>\n",
       "      <td>Aguirre</td>\n",
       "      <td>4411 Danielle Heights Apt. 725</td>\n",
       "      <td>MO</td>\n",
       "      <td>02799</td>\n",
       "      <td>770-14-0862</td>\n",
       "      <td>lleonard</td>\n",
       "      <td>F</td>\n",
       "      <td>wmorris@yahoo.com</td>\n",
       "      <td>2013-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Matthew</td>\n",
       "      <td>Allen</td>\n",
       "      <td>679 Gibson Forge Apt. 354</td>\n",
       "      <td>AL</td>\n",
       "      <td>60926</td>\n",
       "      <td>589-34-4129</td>\n",
       "      <td>lucas23</td>\n",
       "      <td>M</td>\n",
       "      <td>wlittle@gmail.com</td>\n",
       "      <td>2009-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Richard</td>\n",
       "      <td>Alvarez</td>\n",
       "      <td>18980 Leslie Garden</td>\n",
       "      <td>WY</td>\n",
       "      <td>72091</td>\n",
       "      <td>827-23-7191</td>\n",
       "      <td>terrygonzalez</td>\n",
       "      <td>M</td>\n",
       "      <td>kevinsmith@gmail.com</td>\n",
       "      <td>1991-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Carl</td>\n",
       "      <td>Adams</td>\n",
       "      <td>7971 Samantha Vista</td>\n",
       "      <td>CT</td>\n",
       "      <td>08003</td>\n",
       "      <td>349-79-7468</td>\n",
       "      <td>rsoto</td>\n",
       "      <td>M</td>\n",
       "      <td>samuel61@yahoo.com</td>\n",
       "      <td>1970-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>Alvarez</td>\n",
       "      <td>09608 Woods Glens</td>\n",
       "      <td>IN</td>\n",
       "      <td>92620</td>\n",
       "      <td>201-07-7191</td>\n",
       "      <td>valeriegrant</td>\n",
       "      <td>F</td>\n",
       "      <td>martinezjimmy@gmail.com</td>\n",
       "      <td>1948-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td></td>\n",
       "      <td>Ashley Miller</td>\n",
       "      <td>Unit 9200 Box 5692</td>\n",
       "      <td>AP</td>\n",
       "      <td>38533</td>\n",
       "      <td>247-38-9272</td>\n",
       "      <td>breese</td>\n",
       "      <td>F</td>\n",
       "      <td>kherring@gmail.com</td>\n",
       "      <td>1939-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Alvarado</td>\n",
       "      <td>7805 Smith Stravenue Suite 750</td>\n",
       "      <td>MS</td>\n",
       "      <td>66230</td>\n",
       "      <td>057-50-4437</td>\n",
       "      <td>michaeladams</td>\n",
       "      <td>M</td>\n",
       "      <td>susan07@hotmail.com</td>\n",
       "      <td>1929-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Heather</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>911 Krystal Causeway Suite 485</td>\n",
       "      <td>NM</td>\n",
       "      <td>70545</td>\n",
       "      <td>721-95-3992</td>\n",
       "      <td>zdavis</td>\n",
       "      <td>F</td>\n",
       "      <td>sharpbianca@hotmail.com</td>\n",
       "      <td>1927-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Alvarado</td>\n",
       "      <td>846 Sutton Bridge</td>\n",
       "      <td>GU</td>\n",
       "      <td>36145</td>\n",
       "      <td>255-01-6130</td>\n",
       "      <td>melissa38</td>\n",
       "      <td>M</td>\n",
       "      <td>lboyle@gmail.com</td>\n",
       "      <td>1923-08-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first name      last name                  street address state  \\\n",
       "65      Ashley          Ayers             3471 Singh Turnpike    PW   \n",
       "187    Kaitlyn      Alexander               954 Mcguire Curve    NM   \n",
       "352      Paula        Aguirre  4411 Danielle Heights Apt. 725    MO   \n",
       "269    Matthew          Allen       679 Gibson Forge Apt. 354    AL   \n",
       "468    Richard        Alvarez             18980 Leslie Garden    WY   \n",
       "430       Carl          Adams             7971 Samantha Vista    CT   \n",
       "476     Hannah        Alvarez               09608 Woods Glens    IN   \n",
       "351             Ashley Miller              Unit 9200 Box 5692    AP   \n",
       "174     Joseph       Alvarado  7805 Smith Stravenue Suite 750    MS   \n",
       "116    Heather       Arellano  911 Krystal Causeway Suite 485    NM   \n",
       "281     Joseph       Alvarado               846 Sutton Bridge    GU   \n",
       "\n",
       "    postal code          ssn       username sex                      mail  \\\n",
       "65        21627  239-66-1517    connerbrett   F     fordannette@yahoo.com   \n",
       "187       99650  144-83-0302        gfields   F  jasminebennett@yahoo.com   \n",
       "352       02799  770-14-0862       lleonard   F         wmorris@yahoo.com   \n",
       "269       60926  589-34-4129        lucas23   M         wlittle@gmail.com   \n",
       "468       72091  827-23-7191  terrygonzalez   M      kevinsmith@gmail.com   \n",
       "430       08003  349-79-7468          rsoto   M        samuel61@yahoo.com   \n",
       "476       92620  201-07-7191   valeriegrant   F   martinezjimmy@gmail.com   \n",
       "351       38533  247-38-9272         breese   F        kherring@gmail.com   \n",
       "174       66230  057-50-4437   michaeladams   M       susan07@hotmail.com   \n",
       "116       70545  721-95-3992         zdavis   F   sharpbianca@hotmail.com   \n",
       "281       36145  255-01-6130      melissa38   M          lboyle@gmail.com   \n",
       "\n",
       "     birthdate  \n",
       "65  2019-10-29  \n",
       "187 2017-06-18  \n",
       "352 2013-05-21  \n",
       "269 2009-08-13  \n",
       "468 1991-11-21  \n",
       "430 1970-05-16  \n",
       "476 1948-11-26  \n",
       "351 1939-08-18  \n",
       "174 1929-03-05  \n",
       "116 1927-01-29  \n",
       "281 1923-08-21  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe where last name starts with A\n",
    "data = df[df[\"last name\"].str.startswith('A')].copy()\n",
    "#sort by sex and by default it is ascending and F is first\n",
    "ladies_first = data.sort_values(by = [\"sex\"])\n",
    "#The same as ladies_first, it starts with 'A' first\n",
    "state =  data.sort_values(by = [\"state\"])\n",
    "#Convert this birthdate to real datetime value\n",
    "data[\"birthdate\"] = pd.to_datetime(data[\"birthdate\"])\n",
    "#pass False to ascending, it means the youngest is sorted first\n",
    "age = data.sort_values(by = [\"birthdate\"], ascending = False)\n",
    "print(\"Sort by ladies first:\") \n",
    "print(ladies_first)\n",
    "print(\"Sort by state:\")\n",
    "print(state)\n",
    "print(\"Sort by age( youngest first):\")\n",
    "age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82629f-43fd-4272-a4a2-97addd6614b6",
   "metadata": {},
   "source": [
    "## Problem 2. Weather (part 1/2)\n",
    "\n",
    "The file `private/exrc_02/data/XXXXX_prob02_weather.csv` contains hourly weather observations from Helsinki during one month, downloaded from [fmi.fi](https://en.ilmatieteenlaitos.fi/open-data-manual-fmi-wfs-services) (not recommended).\n",
    "\n",
    "First, please do some data cleaning and reorganizing as you find suitable. Then, please answer the following questions:\n",
    "\n",
    "a) How many percentages of the `(tmax+tmin)/2` observations are at most one standard deviation away from the total average of `(tmax+tmin)/2`?\n",
    "\n",
    "b) Find the top-5 timestamps for the difference between `tmax` and `tmin`, i.e. for `tmax-tmin`. For the found rows, print out the following information: timestamp, max temperature, min temperature and temperature difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f4c81-639f-4276-a1a6-ae0709a8f6a1",
   "metadata": {},
   "source": [
    "### Problem 2a \n",
    "Preference:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html#pandas.Series.between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a20b981b-fb10-4384-a276-8ec08f5a0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "user = getuser()\n",
    "csv_location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob02_weather.csv'\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "df.index = df.Time\n",
    "\n",
    "df = df.drop('Time', axis=1)\n",
    "\n",
    "df = df.pivot(columns='ParameterName', values='ParameterValue')\n",
    "\n",
    "df = df.drop(['TG_PT12H_min', 'rrday', 'tday', 'snow'], axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "avr = (df['tmin'] + df['tmax'])/2\n",
    "my_mean = ((df['tmin'] + df['tmax'])/2).mean()\n",
    "\n",
    "my_std = ((df['tmin'] + df['tmax'])/2).std()\n",
    "\n",
    "#Get value true if value from lower (my_mean-my_std) to upper (my_mean+my_std)\n",
    "#The purpose is to count all of average value of avr variable form range of  (my_mean-my_std) and (my_mean+my_std)\n",
    "most_deviation = avr.between(my_mean-my_std,my_mean+my_std)\n",
    "# Get average with mean() and get percent when mulptile with 100\n",
    "percent = most_deviation.mean() * 100\n",
    "print(percent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857cc8a-20b2-4c8c-82fe-59b6fc98bf3a",
   "metadata": {},
   "source": [
    "### Problem 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "051d5783-c7a5-485f-a3eb-0e58e236d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      max temperature  min temperature  temperature difference\n",
      "Time                                                                          \n",
      "2018-11-04T00:00:00Z              9.7              2.0                     7.7\n",
      "2018-11-15T00:00:00Z              9.0              3.0                     6.0\n",
      "2018-11-02T00:00:00Z             10.5              4.7                     5.8\n",
      "2018-11-28T00:00:00Z             -0.8             -6.1                     5.3\n",
      "2018-11-26T00:00:00Z             -0.2             -5.3                     5.1\n"
     ]
    }
   ],
   "source": [
    "#Create a new column with difference between max and min temperature\n",
    "df[\"temperature difference\"] = df['tmax'] - df['tmin']\n",
    "## sort out the difference from biggest to smallest\n",
    "sort = df.sort_values(\"temperature difference\",ascending = False)\n",
    "#Change the names of column titles\n",
    "sort.columns = [\"max temperature\",\"min temperature\",\"temperature difference\"]\n",
    "#only show with top 5\n",
    "print(sort.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc3925-ea46-4069-a059-1adc344dd929",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 3. Premier League Table\n",
    "The file `private/exrc_02/data/XXXXX_prob03_epl.csv` has some English Premier League results, downloaded using [this api](https://github.com/miquel-vv/football_data_api).\n",
    "\n",
    "Using the full data, generate a league table which has the team name as the index and columns as follows (a win gives 3 points, a draw gives 1 point, and a loss gives 0 points):\n",
    "* games played\n",
    "* wins\n",
    "* draws\n",
    "* defeats\n",
    "* goals for - goals against\n",
    "* points\n",
    "\n",
    "\n",
    "Sort it with points (most points win). If points are equal, then sorted by\n",
    "* goal difference (goals for - goals against)\n",
    "* goals for\n",
    "\n",
    "\n",
    "The expected result should look something like this (not the same data though):\n",
    "```\n",
    "                games  wins  draws  defeats   goals  points\n",
    "Man City           38    32      4        2  106-27     100\n",
    "Man United         38    25      6        7   68-28      81\n",
    "Tottenham          38    23      8        7   74-36      77\n",
    "Liverpool          38    21     12        5   84-38      75\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e51237-c567-456a-86ae-982bfb2207b0",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "- https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-groupby/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html#pandas.core.groupby.DataFrameGroupBy.agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "848aca0a-7f8a-4533-ab5e-553411c96f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>games</th>\n",
       "      <th>wins</th>\n",
       "      <th>draws</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Liverpool FC</th>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0-20.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nottingham Forest FC</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>36.0-15.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Ham United FC</th>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>24.0-18.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFC Bournemouth</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>41.0-20.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chelsea FC</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0-16.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fulham FC</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>32.0-29.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aston Villa FC</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>31.0-19.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manchester City FC</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>43.0-27.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manchester United FC</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>34.0-18.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brentford FC</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0-22.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leeds United FC</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0-25.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tottenham Hotspur FC</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>37.0-33.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leicester City FC</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>34.0-29.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newcastle United FC</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0-20.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crystal Palace FC</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>22.0-23.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wolverhampton Wanderers FC</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>19.0-20.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southampton FC</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27.0-25.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Everton FC</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>23.0-20.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arsenal FC</th>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>28.0-28.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brighton &amp; Hove Albion FC</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>33.0-31.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            games  wins  draws  defeats      goals  points\n",
       "team                                                                      \n",
       "Liverpool FC                   21    11      5        3  39.0-20.0      38\n",
       "Nottingham Forest FC           21    10      6        4  36.0-15.0      36\n",
       "West Ham United FC             21    11      3        6  24.0-18.0      36\n",
       "AFC Bournemouth                21    10      5        5  41.0-20.0      35\n",
       "Chelsea FC                     21    10      5        5  27.0-16.0      35\n",
       "Fulham FC                      20    10      4        6  32.0-29.0      34\n",
       "Aston Villa FC                 21    10      4        6  31.0-19.0      34\n",
       "Manchester City FC             19    10      3        6  43.0-27.0      33\n",
       "Manchester United FC           19    10      3        6  34.0-18.0      33\n",
       "Brentford FC                   20     8      8        3  38.0-22.0      32\n",
       "Leeds United FC                19     9      5        4  34.0-25.0      32\n",
       "Tottenham Hotspur FC           20     9      3        8  37.0-33.0      30\n",
       "Leicester City FC              21     9      3        8  34.0-29.0      30\n",
       "Newcastle United FC            21     7      9        4  24.0-20.0      30\n",
       "Crystal Palace FC              21     8      6        6  22.0-23.0      30\n",
       "Wolverhampton Wanderers FC     20     8      5        6  19.0-20.0      29\n",
       "Southampton FC                 21     8      3        9  27.0-25.0      27\n",
       "Everton FC                     21     7      6        7  23.0-20.0      27\n",
       "Arsenal FC                     19     8      2        8  28.0-28.0      26\n",
       "Brighton & Hove Albion FC      21     7      4        8  33.0-31.0      25"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from getpass import getuser\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "user = getuser()\n",
    "csv_location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob03_epl.csv'\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "\n",
    "df['fullTime']=df['fullTime'].apply(lambda x: literal_eval(x))\n",
    "##Parse the scores of home team and away team from fullTime to different columns\n",
    "df['homeScore'] = df['fullTime'].apply(lambda x: x['homeTeam'])\n",
    "df['awayScore'] = df['fullTime'].apply(lambda x: x['awayTeam'])\n",
    "#set value 1 for each game in order count the number of games\n",
    "df['games'] = 1\n",
    "\n",
    "##Set two different data frame for hometeam and awayteam\n",
    "## For hometeam, there are homescore(goals for) and awayscore(goal against) and number of games\n",
    "## For awayteam, homescore is set from awayscore of hometeam.\n",
    "##On the other hand, the \"goals for\"/\"homescore\" of awayteam is score from awayscore of hometeam.\n",
    "home = pd.DataFrame({\"team\": df[\"homeTeam\"], \"homeScore\": df[\"homeScore\"], \"awayScore\": df[\"awayScore\"], 'games': df['games']} )\n",
    "away = pd.DataFrame({\"team\": df[\"awayTeam\"], \"awayScore\": df[\"awayScore\"], \"homeScore\": df[\"homeScore\"] ,'games': df['games']})\n",
    "\n",
    "##two datafram is combined  in same coulum name such as team, homescore and away\n",
    "combine = pd.concat([home, away])\n",
    "## Create column wins, draws amd defeats\n",
    "## It simply set it true or false by set condition and convert it to type integer so \n",
    "## it is easier to calculate it later\n",
    "combine['wins'] =  (combine['homeScore'] > combine['awayScore']).astype(int)\n",
    "combine['draws'] = (combine['homeScore'] == combine['awayScore']).astype(int)\n",
    "combine['defeats'] = (combine['homeScore'] < combine['awayScore']).astype(int)\n",
    "\n",
    "## Function groupby will set any function based on team.\n",
    "## For example, team AFC Bournemoth will be filtered and calcuated the sum of game played, scores and so on.  \n",
    "combine = combine.groupby('team').agg(\n",
    "        {'games' : 'sum',\n",
    "        'homeScore' : 'sum',\n",
    "        'awayScore':'sum',\n",
    "        'wins': 'sum',\n",
    "        'draws': 'sum',\n",
    "        'defeats'  : 'sum',}\n",
    ")\n",
    "## set goal difference and points \n",
    "combine['goalDif'] = combine['homeScore'] - combine['awayScore']\n",
    "combine['goals'] = combine['homeScore'].astype(str) + '-'  + combine['awayScore'].astype(str) \n",
    "combine['points'] = combine['wins'] *3  + combine['draws'] \n",
    "##Set all of needed columns \n",
    "##Sort from largest with points first then goals for and then goal difference\n",
    "combine = combine.sort_values(by=[\"points\",\"homeScore\",\"goalDif\"] ,ascending = [False,False,False])\n",
    "df = combine[['games','wins','draws','defeats','goals','points']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670cdbf-167d-45b5-b2b3-24e1bc8ae4e6",
   "metadata": {},
   "source": [
    "## Problem 4. Weather (part 2/2)\n",
    "\n",
    "The file `private/exrc_02/data/XXXXX_prob04_weather.txt` \n",
    "has some (old) weather data from Jyväskylä 1959-2021, again downloaded from [fmi.fi](https://en.ilmatieteenlaitos.fi/open-data-manual-fmi-wfs-services) (not recommended).\n",
    "\n",
    "Calculate the \"snow sum\" (not an official meteorological term) for each winter by adding the snow depths for each day of that winter. Start from winter 1959-60 and end to 2019-20 since 1958-59 and 2020-21 are only partial.\n",
    "\n",
    "Notes:\n",
    "* You need to define \"winter\" by yourself.\n",
    "* FMI uses -1 as snow depth when \"there is absolutely no snow at all\". We don't want to reduce snow sum in that case, so replace -1 with 0.\n",
    "* For missing data, assume that the snow depth has been the same as during the previous day. (Fill any `NaN`s with the previous valid value.)\n",
    "\n",
    "Then produce a DataFrame that has the winter as the index (in form \"1959-1960\") and columns:\n",
    "* snow sum\n",
    "* snow sum rank among winters so that largest = 1\n",
    "* count of days where snow depth has been positive\n",
    "* max snow depth of the winter.\n",
    "\n",
    "\n",
    "The three first and the three last rows should look something like:\n",
    "```\n",
    "           Snow sum  rank  count  max\n",
    "Winter                               \n",
    "1959-1960      5593    18    169   65\n",
    "1960-1961      5082    28    162   60\n",
    "1961-1962      6644    12    156   78\n",
    "\n",
    "...\n",
    "\n",
    "2017-2018      6882     8    161   81\n",
    "2018-2019      4030    42    150   54\n",
    "2019-2020      1432    59    112   30\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0660f-b2c3-41ee-a8a9-a29add9adfb1",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- https://www.geeksforgeeks.org/python/pandas-query-method/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html#pandas.core.groupby.DataFrameGroupBy.rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c4770b46-3ac5-457c-8bec-6c4805cdc54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Snow_sum</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-1960</th>\n",
       "      <td>4956.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>134</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-1961</th>\n",
       "      <td>4344.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>133</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-1962</th>\n",
       "      <td>5546.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>126</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-1963</th>\n",
       "      <td>3594.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>137</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-1964</th>\n",
       "      <td>3762.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>142</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-2016</th>\n",
       "      <td>1958.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>104</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-2017</th>\n",
       "      <td>2378.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>141</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-2018</th>\n",
       "      <td>5765.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>134</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-2019</th>\n",
       "      <td>3640.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>111</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2020</th>\n",
       "      <td>1414.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>107</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Snow_sum  rank  count   max\n",
       "winter                                \n",
       "1959-1960    4956.0  17.0    134  65.0\n",
       "1960-1961    4344.0  28.0    133  60.0\n",
       "1961-1962    5546.0  12.0    126  78.0\n",
       "1962-1963    3594.0  42.0    137  50.0\n",
       "1963-1964    3762.0  40.0    142  49.0\n",
       "...             ...   ...    ...   ...\n",
       "2015-2016    1958.0  55.0    104  40.0\n",
       "2016-2017    2378.0  52.0    141  38.0\n",
       "2017-2018    5765.0  11.0    134  80.0\n",
       "2018-2019    3640.0  41.0    111  54.0\n",
       "2019-2020    1414.0  59.0    107  30.0\n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from getpass import getuser\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "user = getuser()\n",
    "location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob04_weather.csv'\n",
    "df = pd.read_csv(location)\n",
    "## Winter in Finland could happend from December to March. It's still very cold in November and April.\n",
    "##But let's set winter from December to March\n",
    "df = df.query('Month >=11 or Month <=3')\n",
    "#replace -1 wiht 0 and fill Na with previous value with ffill() function\n",
    "df[\"Snow depth (cm)\"]= df[\"Snow depth (cm)\"].replace(-1,0)\n",
    "df[\"Snow depth (cm)\"]= df[\"Snow depth (cm)\"].ffill()\n",
    "##set winter based on month 11-3\n",
    "## The period is set like this\n",
    "##For example, 11-12/1959 and 1,2,3/1960 => winter is set as period 1959-1960 and 11-12/1960 and 1-3/1961 => 1960-1961 and so on\n",
    "df['winter']= df.apply(lambda x: \n",
    "             f'{x.Year}-{x.Year +1}' if\n",
    "             x.Month == 11 or  x.Month == 12 else\n",
    "             f'{x.Year -1}-{x.Year}' if\n",
    "             x.Month in [1,2,3] else None,\n",
    "             axis=1\n",
    "            ) \n",
    "\n",
    "## set index of datafram is based on winter period \n",
    "df.index = df['winter']\n",
    "df = df.drop('winter',axis=1)\n",
    "##Only set winter period from \"1959-1960\" to\"2019-2020\n",
    "df = df[\"1959-1960\":\"2019-2020\"]\n",
    "##Caculation based on winter period\n",
    "df = df.groupby(\"winter\").agg(\n",
    "    Snow_sum = (\"Snow depth (cm)\",\"sum\"),\n",
    "    count = (\"Snow depth (cm)\", lambda x : (x > 0).sum() ),\n",
    "    max = (\"Snow depth (cm)\",\"max\")\n",
    ")\n",
    "#rank from biggest with number 1 \n",
    "df['rank'] = df['Snow_sum'].rank(ascending= False,method='min')\n",
    "df = df[[\"Snow_sum\",\"rank\",\"count\",\"max\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf511d-2bff-4d3b-8cd3-2231732df527",
   "metadata": {},
   "source": [
    "## Problem 5. Statfi data wrangle.\n",
    "- Here we're trying to make some sense out of the data that we downloaded from the statfi service in problem 5 of the first exercises. If you did it successfully, please use your own data. Otherwise you may use the data found in `public/exrc_02/data`.\n",
    "- That data used the keyword `kihi` and the final table `statfin_kihi_pxt_13zt.px`. You may want to replace them in the front end url below.\n",
    "- First use [this front end](https://pxdata.stat.fi/PxWeb/pxweb/en/StatFin/StatFin__kihi/statfin_kihi_pxt_13zt.px/) to produce a meaningful table, and then try to produce a similar table with pandas and your data.\n",
    "- The most elegant solution wins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "205e6306-d55b-4bd3-b7cd-11f387bf47af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               key                               values\n",
      "0  [0, 2012, 0, 0]  [9980, .., 53390, .., 5.3, 3.0, 22]\n",
      "1  [0, 2012, 0, 1]  [7670, .., 51330, .., 6.7, 4.0, 29]\n",
      "2  [0, 2012, 0, 2]    [1380, .., 2060, .., 1.5, 1.0, .]\n",
      "3  [0, 2012, 0, 3]        [920, .., 0, .., 0.0, 0.0, .]\n",
      "4  [0, 2012, 1, 0]  [3140, .., 17510, .., 5.6, 3.0, 21]\n",
      "5  [0, 2012, 1, 1]    [2370, ., 16710, ., 7.1, 4.0, 28]\n",
      "6  [0, 2012, 1, 2]        [500, ., 800, ., 1.6, 2.0, .]\n",
      "7  [0, 2012, 1, 3]        [270, .., 0, .., 0.0, 0.0, .]\n",
      "8  [0, 2012, 2, 0]  [3670, .., 20290, .., 5.5, 3.0, 24]\n",
      "9  [0, 2012, 2, 1]  [2930, .., 19680, .., 6.7, 4.0, 30]\n",
      "['Trip purpose', 'Year', 'Season', 'Type of trip abroad']\n",
      "['Trips, thousand trips', 'Change of trips, %', 'Overnight stays, thousand overnight stays', 'Change of nights, %', 'Average length of trip, nights', 'Median length of trip, nights', 'Share of package trips, %']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Trips, thousand trips</th>\n",
       "      <th>Average length of trip, nights</th>\n",
       "      <th>Average length of trip, nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>9980</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>7670</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>3140</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>2370</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012</td>\n",
       "      <td>3670</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>2930</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>430</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>3170</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012</td>\n",
       "      <td>2370</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012</td>\n",
       "      <td>460</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012</td>\n",
       "      <td>340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013</td>\n",
       "      <td>9530</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013</td>\n",
       "      <td>7200</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013</td>\n",
       "      <td>1360</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013</td>\n",
       "      <td>960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year Trips, thousand trips Average length of trip, nights  \\\n",
       "0   2012                  9980                            5.3   \n",
       "1   2012                  7670                            6.7   \n",
       "2   2012                  1380                            1.5   \n",
       "3   2012                   920                            0.0   \n",
       "4   2012                  3140                            5.6   \n",
       "5   2012                  2370                            7.1   \n",
       "6   2012                   500                            1.6   \n",
       "7   2012                   270                            0.0   \n",
       "8   2012                  3670                            5.5   \n",
       "9   2012                  2930                            6.7   \n",
       "10  2012                   430                            1.4   \n",
       "11  2012                   320                            0.0   \n",
       "12  2012                  3170                            4.9   \n",
       "13  2012                  2370                            6.3   \n",
       "14  2012                   460                            1.4   \n",
       "15  2012                   340                            0.0   \n",
       "16  2013                  9530                            5.1   \n",
       "17  2013                  7200                            6.5   \n",
       "18  2013                  1360                            1.4   \n",
       "19  2013                   960                            0.0   \n",
       "\n",
       "   Average length of trip, nights  \n",
       "0                             5.3  \n",
       "1                             6.7  \n",
       "2                             1.5  \n",
       "3                             0.0  \n",
       "4                             5.6  \n",
       "5                             7.1  \n",
       "6                             1.6  \n",
       "7                             0.0  \n",
       "8                             5.5  \n",
       "9                             6.7  \n",
       "10                            1.4  \n",
       "11                            0.0  \n",
       "12                            4.9  \n",
       "13                            6.3  \n",
       "14                            1.4  \n",
       "15                            0.0  \n",
       "16                            5.1  \n",
       "17                            6.5  \n",
       "18                            1.4  \n",
       "19                            0.0  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from getpass import getuser\n",
    "\n",
    "user = getuser()\n",
    "# let's read the data into a plain python dict first\n",
    "with open(\"test.json\",\"r\") as handle:\n",
    "    statfi_data = json.load(handle)\n",
    "\n",
    "df = pd.json_normalize(statfi_data, record_path = 'data')\n",
    "print(df.head(10))\n",
    "\n",
    "key_exploded = df['key'].apply(pd.Series)\n",
    "\n",
    "values_exploded = df['values'].apply(pd.Series)\n",
    "\n",
    "df = pd.concat([key_exploded, values_exploded], axis=1)\n",
    "##In test file, there are total 11 items in columns but there are only 4 items in key of data\n",
    "#That's why it needs to be get data in two parts below\n",
    "##Get key name based on the length of key_exploded.columns\n",
    "key_names = [c[\"text\"] for c in statfi_data[\"columns\"][:len(key_exploded.columns)]]\n",
    "print(key_names)\n",
    "##Get value name from the rest of data of statfi_data[\"columns\"]\n",
    "value_names = [c[\"text\"] for c in statfi_data[\"columns\"][len(key_exploded.columns):]]\n",
    "print(value_names)\n",
    "df.columns = key_names + value_names\n",
    "## For some fields about trips\n",
    "\n",
    "df = df[[\"Year\",\"Trips, thousand trips\",\"Average length of trip, nights\",\"Average length of trip, nights\"]]\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0e70b-1a6e-40f7-aba7-d12ae5968d8a",
   "metadata": {},
   "source": [
    "## How to submit my solutions?\n",
    "\n",
    "Open a Terminal tab (e.g. <tt>File $\\rightarrow$ New $\\rightarrow$ Terminal</tt>, copy-paste the following into the Terminal command prompt, and press enter:\n",
    "<pre>\n",
    "  /home/varpha/dan/menu.py\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
