{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebabbbab-c235-4789-a004-14e69d06ec9d",
   "metadata": {},
   "source": [
    "# Data Analytics Fall 2025 &mdash; Exercises 2\n",
    "\n",
    "### XXXXX XXXXX\n",
    "\n",
    "Last modified: Tue 16 Sep before session\n",
    "\n",
    "- Five problems + round 1 peer review\n",
    "- Theme: data wrangling with **pandas** (please use pandas in each problem)\n",
    "- Please make both your code and your notebook readable\n",
    "- Keep your originals up to date by running the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cde89ee5-64f7-4289-8065-d36dfc25c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuring...\n",
      "\n",
      "  created the ~/dan directory tree\n",
      "  changed all ~/dan subdir permissions to 700\n",
      "  removed any broken filelinks under ~/dan\n",
      "  copied filelinks from /home/varpha/dan to ~/dan\n",
      "  removed any python cache dirs\n",
      "  creating answers workbook (Darren's idea)\n",
      "  answers workbook /home/XXXXX/dan/private/exrc_02/exrc_02_answers.ipynb already exists, skipping copy\n",
      "\n",
      "  upgrading jupyterlab etc. (may take a while)...\n",
      "  done (you may need to restart your server in order for the upgrades to take effect)\n",
      "\n",
      "All Done!\n",
      "\n",
      "Please run this config script whenever you start working on the hub.\n",
      "\n",
      "If you encountered errors, please re-run the script. If the errors persist, please report to our Teams channel.\n",
      "\n",
      "Also, please do 'File -> Hub Control Panel -> Stop My Server'\n",
      "whenever you stop working on the hub.\n",
      "\n",
      "Thank you!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('/usr/bin/bash /home/varpha/dan/config.sh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722411d-45e4-4faa-bafa-06aa0d4bf31b",
   "metadata": {},
   "source": [
    "## Round 1 peer review\n",
    "\n",
    "- Submit your round 01 solutions in the **round 01** menu <br>\n",
    "  (run `/home/varpha/dan/menu.py` in the terminal).\n",
    "- After some effort, you should be able to access an anonymized submission of another student.\n",
    "\n",
    "Write a few paragraphs of text (plain or markdown) into your favourite text editor and submit that text in  the **round 02** menu. \n",
    "\n",
    "Please address the following issues:\n",
    " \n",
    "- Are the solutions okay? Can you understand / run the code?<br/>\n",
    "  (as opposed to some wishful brainless copy-pasting done in a hurry)\n",
    "- What do you think about the solutions? To what extent has AI been used blindly without explaining the usage?\n",
    "- How many points out of 5 do the solutions deserve as a whole?\n",
    "- How many points out of 5 would you give to yourself and why?\n",
    "- Any feedback or comments to Harri?\n",
    "  \n",
    "Harri will read and grade your reviews as follows:\n",
    "- nonexistent or nearly so = 0p\n",
    "- something written = 1-2p\n",
    "- well written 3p."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe4d8d-c0fc-43f7-b336-3fc95dd0dd76",
   "metadata": {},
   "source": [
    "## Problem 1. Profiles\n",
    "\n",
    "The file `private/exrc_02/data/XXXXX_prob01_profiles.csv` contains some user profiles.\n",
    "Read the csv into a pandas DataFrame and reorganize it as follows:\n",
    "\n",
    "a) Separate the name and address columns so that there are separate columns for\n",
    "- first name\n",
    "- last name\n",
    "- street address\n",
    "- state\n",
    "- postal code.\n",
    "\n",
    "Keep also the ssn, username, sex, mail and birthdate columns. Drop all the other columns.\n",
    "\n",
    "b) Print all entries where the last name begins with the letter A, sorted by:\n",
    "- sex (ladies first)\n",
    "- state (alphabetically)\n",
    "- age (youngest first).\n",
    "\n",
    "I.e. print the entries three times, in these three different ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39369ff9-2254-4555-b459-650b41e24fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "user = getuser()\n",
    "csv_location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob01_profiles.csv'\n",
    "csv_location = \"ah4323_prob01_profiles.csv\"\n",
    "df = pd.read_csv(csv_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2fee5-44ac-4aa5-a9d2-258300778b1f",
   "metadata": {},
   "source": [
    "### Problem 1a\n",
    "After observation, the full name is attached with job title. Therefore, it is neccessary to remove prefixes and suffixes such as Dr.X Y PhD.\n",
    "There are some built-in functions of pandas library supporting to handle some issue such as replace with regular expression, split with delimiter.\n",
    "Reference:\n",
    "- https://pandas.pydata.org/docs/user_guide/indexing.html#basics\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html#pandas.Series.str.replace\n",
    "- https://www.geeksforgeeks.org/python/regular-expression-python-examples/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html\n",
    "- https://pandas.pydata.org/docs/user_guide/text.html#splitting-and-replacing-strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fddd70d-d129-4699-b7d8-c6afaaebe931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first name</th>\n",
       "      <th>last name</th>\n",
       "      <th>street address</th>\n",
       "      <th>state</th>\n",
       "      <th>postal code</th>\n",
       "      <th>ssn</th>\n",
       "      <th>username</th>\n",
       "      <th>sex</th>\n",
       "      <th>mail</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Hebert</td>\n",
       "      <td>206 William Stream</td>\n",
       "      <td>HI</td>\n",
       "      <td>29419</td>\n",
       "      <td>452-50-6924</td>\n",
       "      <td>russell23</td>\n",
       "      <td>M</td>\n",
       "      <td>robertnguyen@yahoo.com</td>\n",
       "      <td>1987-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emily</td>\n",
       "      <td>Parker</td>\n",
       "      <td>8871 Diaz Land</td>\n",
       "      <td>MD</td>\n",
       "      <td>65719</td>\n",
       "      <td>738-16-1005</td>\n",
       "      <td>caitlinanthony</td>\n",
       "      <td>F</td>\n",
       "      <td>annaramos@hotmail.com</td>\n",
       "      <td>1942-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sylvia</td>\n",
       "      <td>James</td>\n",
       "      <td>USNV Cannon</td>\n",
       "      <td>AA</td>\n",
       "      <td>37496</td>\n",
       "      <td>773-80-3323</td>\n",
       "      <td>anthony18</td>\n",
       "      <td>F</td>\n",
       "      <td>michael45@hotmail.com</td>\n",
       "      <td>2005-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kelly</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>615 Jamie Fields Suite 849</td>\n",
       "      <td>KY</td>\n",
       "      <td>02301</td>\n",
       "      <td>171-20-4761</td>\n",
       "      <td>reedjames</td>\n",
       "      <td>F</td>\n",
       "      <td>bartlettdanielle@yahoo.com</td>\n",
       "      <td>1914-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ronald</td>\n",
       "      <td>Huff</td>\n",
       "      <td>8193 Jensen Overpass</td>\n",
       "      <td>RI</td>\n",
       "      <td>74715</td>\n",
       "      <td>870-48-6252</td>\n",
       "      <td>uprince</td>\n",
       "      <td>M</td>\n",
       "      <td>jonesjoseph@yahoo.com</td>\n",
       "      <td>1930-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Darren</td>\n",
       "      <td>Smith</td>\n",
       "      <td>237 Barr Courts Suite 750</td>\n",
       "      <td>DE</td>\n",
       "      <td>02297</td>\n",
       "      <td>774-49-8839</td>\n",
       "      <td>jameschristopher</td>\n",
       "      <td>M</td>\n",
       "      <td>michaelwilson@hotmail.com</td>\n",
       "      <td>2015-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashley</td>\n",
       "      <td>Smith</td>\n",
       "      <td>3548 Murphy Square Suite 253</td>\n",
       "      <td>MP</td>\n",
       "      <td>41931</td>\n",
       "      <td>162-48-2753</td>\n",
       "      <td>vrichards</td>\n",
       "      <td>F</td>\n",
       "      <td>mitchelltiffany@yahoo.com</td>\n",
       "      <td>1944-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Justin</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>985 Rodriguez Shores</td>\n",
       "      <td>KS</td>\n",
       "      <td>23375</td>\n",
       "      <td>621-35-5815</td>\n",
       "      <td>hughesemily</td>\n",
       "      <td>M</td>\n",
       "      <td>williamvelez@hotmail.com</td>\n",
       "      <td>2010-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Antonio</td>\n",
       "      <td>Porter</td>\n",
       "      <td>Unit 7846 Box 2605</td>\n",
       "      <td>AP</td>\n",
       "      <td>03305</td>\n",
       "      <td>620-38-1679</td>\n",
       "      <td>keith75</td>\n",
       "      <td>M</td>\n",
       "      <td>wendy00@hotmail.com</td>\n",
       "      <td>1994-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gregory</td>\n",
       "      <td>Williams</td>\n",
       "      <td>2531 Amanda Curve Apt. 964</td>\n",
       "      <td>NE</td>\n",
       "      <td>41899</td>\n",
       "      <td>898-05-3838</td>\n",
       "      <td>zschultz</td>\n",
       "      <td>M</td>\n",
       "      <td>charlesgentry@gmail.com</td>\n",
       "      <td>1981-03-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first name last name                street address state postal code  \\\n",
       "0    Michael    Hebert            206 William Stream    HI       29419   \n",
       "1      Emily    Parker                8871 Diaz Land    MD       65719   \n",
       "2     Sylvia     James                   USNV Cannon    AA       37496   \n",
       "3      Kelly   Edwards    615 Jamie Fields Suite 849    KY       02301   \n",
       "4     Ronald      Huff          8193 Jensen Overpass    RI       74715   \n",
       "5     Darren     Smith     237 Barr Courts Suite 750    DE       02297   \n",
       "6     Ashley     Smith  3548 Murphy Square Suite 253    MP       41931   \n",
       "7     Justin   Edwards          985 Rodriguez Shores    KS       23375   \n",
       "8    Antonio    Porter            Unit 7846 Box 2605    AP       03305   \n",
       "9    Gregory  Williams    2531 Amanda Curve Apt. 964    NE       41899   \n",
       "\n",
       "           ssn          username sex                        mail   birthdate  \n",
       "0  452-50-6924         russell23   M      robertnguyen@yahoo.com  1987-12-24  \n",
       "1  738-16-1005    caitlinanthony   F       annaramos@hotmail.com  1942-03-10  \n",
       "2  773-80-3323         anthony18   F       michael45@hotmail.com  2005-01-01  \n",
       "3  171-20-4761         reedjames   F  bartlettdanielle@yahoo.com  1914-07-05  \n",
       "4  870-48-6252           uprince   M       jonesjoseph@yahoo.com  1930-05-11  \n",
       "5  774-49-8839  jameschristopher   M   michaelwilson@hotmail.com  2015-02-13  \n",
       "6  162-48-2753         vrichards   F   mitchelltiffany@yahoo.com  1944-06-25  \n",
       "7  621-35-5815       hughesemily   M    williamvelez@hotmail.com  2010-07-27  \n",
       "8  620-38-1679           keith75   M         wendy00@hotmail.com  1994-05-26  \n",
       "9  898-05-3838          zschultz   M     charlesgentry@gmail.com  1981-03-29  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sprefixes and suffixes of full name is removed with regular expression  \n",
    "# Use meta-characters such as  ^ means starting with Mr. or Dr. and \\s* means any white space or no white space. If it matches then it replace with nothing.\n",
    "no_prefixes = df[\"name\"].str.replace('^(Mr.|Dr.)s*','', regex=True)\n",
    "# Remove suffixes with $ means ends with PhD or DDS ... and no white space. \n",
    "no_suffixes = no_prefixes.str.replace('s*(PhD|DDS|MD|DVM)$','', regex=True)\n",
    "#Split full name by white space and split into two columns.\n",
    "name = no_suffixes.str.split(' ', expand=True, n=1)\n",
    "#dataframe with string could be accessed with get  or [] \n",
    "df[\"first name\"] =  name[0]\n",
    "df[\"last name\"] = name[1]\n",
    "# Split the whole address into street address and the rest\n",
    "\n",
    "address =  df[\"address\"].str.split('\\n')\n",
    "df[\"street address\"] = address.str[0]\n",
    "#split the rest of address into three parts, the last one [-1] is the postal code and second last one [-2] is state\n",
    "state_code = address.str[1].str.split(' ')\n",
    "df[\"postal code\"] = state_code.str[-1]\n",
    "df[\"state\"] = state_code.str[-2]\n",
    "#combine all of field with [[field, field]] \n",
    "df = df[[\"first name\", \"last name\",\"street address\",\"state\",\"postal code\",\"ssn\",\"username\",\"sex\",\"mail\",\"birthdate\"]]\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b98b73-04ee-484a-a26d-a1b7beba182c",
   "metadata": {},
   "source": [
    "### Problem 1b\n",
    "When implementing the sorting values. It shows warning with **SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame**.\n",
    "The copy() solves the issue. It is possible to check reference.\n",
    "Preference:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.str.startswith.html#pandas.Series.str.startswith\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#evaluation-order-matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652550d0-2ba1-4a88-88d4-058df461aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort by ladies first:\n",
      "    first name  last name                    street address state postal code  \\\n",
      "94      Alyssa   Anderson      12509 Jordan Rapid Suite 221    RI       67312   \n",
      "117   Patricia    Andrade                  037 Warner Place    VI       46571   \n",
      "164   Kathleen     Arroyo       7433 Joshua Light Suite 423    GU       35854   \n",
      "172     Gloria    Aguilar         435 Escobar Wall Apt. 304    ME       71133   \n",
      "221    Jessica   Anderson      323 Vasquez Village Apt. 866    ND       62196   \n",
      "230       Beth   Arellano     3585 Tanner Mission Suite 928    NM       91034   \n",
      "236    Chelsea      Adams       560 Cynthia Summit Apt. 271    MN       51695   \n",
      "294     Andrea    Andrews      620 Sanders Summit Suite 382    NY       95796   \n",
      "356    Melinda      Allen                    736 Reese Loaf    FL       60678   \n",
      "378    Rebecca      Allen                  827 Jason Island    PA       29406   \n",
      "15     Spencer     Arnold          2292 Dyer Park Suite 698    HI       30374   \n",
      "40       David   Anderson  9299 Kimberly Mountains Apt. 160    GA       66995   \n",
      "52      Jerome     Adkins         5763 Ashley View Apt. 054    NJ       33403   \n",
      "130    Michael      Allen         8032 Yvonne Cove Apt. 472    MP       87536   \n",
      "233      Roger   Anderson     1900 Bradley Skyway Suite 346    WY       83697   \n",
      "311     Darren  Alexander      67790 Brandon Wells Apt. 209    FM       92577   \n",
      "\n",
      "             ssn         username sex                       mail   birthdate  \n",
      "94   618-23-7085    michaelmartin   F        kmiller@hotmail.com  1997-08-23  \n",
      "117  485-57-5914  robersonbeverly   F     brownjames@hotmail.com  1975-12-30  \n",
      "164  701-62-8909        michael06   F       hollyweber@yahoo.com  1949-02-24  \n",
      "172  082-24-7955      ecunningham   F  jennifersanchez@gmail.com  1912-02-22  \n",
      "221  475-87-5012  justinrodriguez   F        msnyder@hotmail.com  1938-02-06  \n",
      "230  579-46-9356        tanyakemp   F         ldoyle@hotmail.com  1916-08-11  \n",
      "236  392-79-6259        phyllis60   F      kelseydavis@gmail.com  1946-12-12  \n",
      "294  430-97-1375        fbartlett   F        natalie15@yahoo.com  1929-10-24  \n",
      "356  607-43-8328  destinygonzalez   F          bross@hotmail.com  1921-02-21  \n",
      "378  606-20-1906         afreeman   F    cherylbuckley@gmail.com  1958-04-02  \n",
      "15   839-68-0180      justingrant   M   millerjennifer@gmail.com  2002-06-11  \n",
      "40   863-94-6652           bsmith   M          cjensen@gmail.com  2007-05-06  \n",
      "52   891-40-6262        htrujillo   M         teresa97@gmail.com  1938-07-02  \n",
      "130  417-66-5820         vbaldwin   M        danderson@gmail.com  1960-05-24  \n",
      "233  557-08-4915        jeffrey73   M     mandystone@hotmail.com  2019-12-14  \n",
      "311  202-81-9617     lawsoneugene   M     sblankenship@gmail.com  1964-06-17  \n",
      "Sort by state:\n",
      "    first name  last name                    street address state postal code  \\\n",
      "356    Melinda      Allen                    736 Reese Loaf    FL       60678   \n",
      "311     Darren  Alexander      67790 Brandon Wells Apt. 209    FM       92577   \n",
      "40       David   Anderson  9299 Kimberly Mountains Apt. 160    GA       66995   \n",
      "164   Kathleen     Arroyo       7433 Joshua Light Suite 423    GU       35854   \n",
      "15     Spencer     Arnold          2292 Dyer Park Suite 698    HI       30374   \n",
      "172     Gloria    Aguilar         435 Escobar Wall Apt. 304    ME       71133   \n",
      "236    Chelsea      Adams       560 Cynthia Summit Apt. 271    MN       51695   \n",
      "130    Michael      Allen         8032 Yvonne Cove Apt. 472    MP       87536   \n",
      "221    Jessica   Anderson      323 Vasquez Village Apt. 866    ND       62196   \n",
      "52      Jerome     Adkins         5763 Ashley View Apt. 054    NJ       33403   \n",
      "230       Beth   Arellano     3585 Tanner Mission Suite 928    NM       91034   \n",
      "294     Andrea    Andrews      620 Sanders Summit Suite 382    NY       95796   \n",
      "378    Rebecca      Allen                  827 Jason Island    PA       29406   \n",
      "94      Alyssa   Anderson      12509 Jordan Rapid Suite 221    RI       67312   \n",
      "117   Patricia    Andrade                  037 Warner Place    VI       46571   \n",
      "233      Roger   Anderson     1900 Bradley Skyway Suite 346    WY       83697   \n",
      "\n",
      "             ssn         username sex                       mail   birthdate  \n",
      "356  607-43-8328  destinygonzalez   F          bross@hotmail.com  1921-02-21  \n",
      "311  202-81-9617     lawsoneugene   M     sblankenship@gmail.com  1964-06-17  \n",
      "40   863-94-6652           bsmith   M          cjensen@gmail.com  2007-05-06  \n",
      "164  701-62-8909        michael06   F       hollyweber@yahoo.com  1949-02-24  \n",
      "15   839-68-0180      justingrant   M   millerjennifer@gmail.com  2002-06-11  \n",
      "172  082-24-7955      ecunningham   F  jennifersanchez@gmail.com  1912-02-22  \n",
      "236  392-79-6259        phyllis60   F      kelseydavis@gmail.com  1946-12-12  \n",
      "130  417-66-5820         vbaldwin   M        danderson@gmail.com  1960-05-24  \n",
      "221  475-87-5012  justinrodriguez   F        msnyder@hotmail.com  1938-02-06  \n",
      "52   891-40-6262        htrujillo   M         teresa97@gmail.com  1938-07-02  \n",
      "230  579-46-9356        tanyakemp   F         ldoyle@hotmail.com  1916-08-11  \n",
      "294  430-97-1375        fbartlett   F        natalie15@yahoo.com  1929-10-24  \n",
      "378  606-20-1906         afreeman   F    cherylbuckley@gmail.com  1958-04-02  \n",
      "94   618-23-7085    michaelmartin   F        kmiller@hotmail.com  1997-08-23  \n",
      "117  485-57-5914  robersonbeverly   F     brownjames@hotmail.com  1975-12-30  \n",
      "233  557-08-4915        jeffrey73   M     mandystone@hotmail.com  2019-12-14  \n",
      "Sort by age( youngest first):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first name</th>\n",
       "      <th>last name</th>\n",
       "      <th>street address</th>\n",
       "      <th>state</th>\n",
       "      <th>postal code</th>\n",
       "      <th>ssn</th>\n",
       "      <th>username</th>\n",
       "      <th>sex</th>\n",
       "      <th>mail</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Roger</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>1900 Bradley Skyway Suite 346</td>\n",
       "      <td>WY</td>\n",
       "      <td>83697</td>\n",
       "      <td>557-08-4915</td>\n",
       "      <td>jeffrey73</td>\n",
       "      <td>M</td>\n",
       "      <td>mandystone@hotmail.com</td>\n",
       "      <td>2019-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>David</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>9299 Kimberly Mountains Apt. 160</td>\n",
       "      <td>GA</td>\n",
       "      <td>66995</td>\n",
       "      <td>863-94-6652</td>\n",
       "      <td>bsmith</td>\n",
       "      <td>M</td>\n",
       "      <td>cjensen@gmail.com</td>\n",
       "      <td>2007-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Spencer</td>\n",
       "      <td>Arnold</td>\n",
       "      <td>2292 Dyer Park Suite 698</td>\n",
       "      <td>HI</td>\n",
       "      <td>30374</td>\n",
       "      <td>839-68-0180</td>\n",
       "      <td>justingrant</td>\n",
       "      <td>M</td>\n",
       "      <td>millerjennifer@gmail.com</td>\n",
       "      <td>2002-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Alyssa</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>12509 Jordan Rapid Suite 221</td>\n",
       "      <td>RI</td>\n",
       "      <td>67312</td>\n",
       "      <td>618-23-7085</td>\n",
       "      <td>michaelmartin</td>\n",
       "      <td>F</td>\n",
       "      <td>kmiller@hotmail.com</td>\n",
       "      <td>1997-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Patricia</td>\n",
       "      <td>Andrade</td>\n",
       "      <td>037 Warner Place</td>\n",
       "      <td>VI</td>\n",
       "      <td>46571</td>\n",
       "      <td>485-57-5914</td>\n",
       "      <td>robersonbeverly</td>\n",
       "      <td>F</td>\n",
       "      <td>brownjames@hotmail.com</td>\n",
       "      <td>1975-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Darren</td>\n",
       "      <td>Alexander</td>\n",
       "      <td>67790 Brandon Wells Apt. 209</td>\n",
       "      <td>FM</td>\n",
       "      <td>92577</td>\n",
       "      <td>202-81-9617</td>\n",
       "      <td>lawsoneugene</td>\n",
       "      <td>M</td>\n",
       "      <td>sblankenship@gmail.com</td>\n",
       "      <td>1964-06-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Allen</td>\n",
       "      <td>8032 Yvonne Cove Apt. 472</td>\n",
       "      <td>MP</td>\n",
       "      <td>87536</td>\n",
       "      <td>417-66-5820</td>\n",
       "      <td>vbaldwin</td>\n",
       "      <td>M</td>\n",
       "      <td>danderson@gmail.com</td>\n",
       "      <td>1960-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Allen</td>\n",
       "      <td>827 Jason Island</td>\n",
       "      <td>PA</td>\n",
       "      <td>29406</td>\n",
       "      <td>606-20-1906</td>\n",
       "      <td>afreeman</td>\n",
       "      <td>F</td>\n",
       "      <td>cherylbuckley@gmail.com</td>\n",
       "      <td>1958-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Kathleen</td>\n",
       "      <td>Arroyo</td>\n",
       "      <td>7433 Joshua Light Suite 423</td>\n",
       "      <td>GU</td>\n",
       "      <td>35854</td>\n",
       "      <td>701-62-8909</td>\n",
       "      <td>michael06</td>\n",
       "      <td>F</td>\n",
       "      <td>hollyweber@yahoo.com</td>\n",
       "      <td>1949-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Adams</td>\n",
       "      <td>560 Cynthia Summit Apt. 271</td>\n",
       "      <td>MN</td>\n",
       "      <td>51695</td>\n",
       "      <td>392-79-6259</td>\n",
       "      <td>phyllis60</td>\n",
       "      <td>F</td>\n",
       "      <td>kelseydavis@gmail.com</td>\n",
       "      <td>1946-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Jerome</td>\n",
       "      <td>Adkins</td>\n",
       "      <td>5763 Ashley View Apt. 054</td>\n",
       "      <td>NJ</td>\n",
       "      <td>33403</td>\n",
       "      <td>891-40-6262</td>\n",
       "      <td>htrujillo</td>\n",
       "      <td>M</td>\n",
       "      <td>teresa97@gmail.com</td>\n",
       "      <td>1938-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Jessica</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>323 Vasquez Village Apt. 866</td>\n",
       "      <td>ND</td>\n",
       "      <td>62196</td>\n",
       "      <td>475-87-5012</td>\n",
       "      <td>justinrodriguez</td>\n",
       "      <td>F</td>\n",
       "      <td>msnyder@hotmail.com</td>\n",
       "      <td>1938-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Andrea</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>620 Sanders Summit Suite 382</td>\n",
       "      <td>NY</td>\n",
       "      <td>95796</td>\n",
       "      <td>430-97-1375</td>\n",
       "      <td>fbartlett</td>\n",
       "      <td>F</td>\n",
       "      <td>natalie15@yahoo.com</td>\n",
       "      <td>1929-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Melinda</td>\n",
       "      <td>Allen</td>\n",
       "      <td>736 Reese Loaf</td>\n",
       "      <td>FL</td>\n",
       "      <td>60678</td>\n",
       "      <td>607-43-8328</td>\n",
       "      <td>destinygonzalez</td>\n",
       "      <td>F</td>\n",
       "      <td>bross@hotmail.com</td>\n",
       "      <td>1921-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Beth</td>\n",
       "      <td>Arellano</td>\n",
       "      <td>3585 Tanner Mission Suite 928</td>\n",
       "      <td>NM</td>\n",
       "      <td>91034</td>\n",
       "      <td>579-46-9356</td>\n",
       "      <td>tanyakemp</td>\n",
       "      <td>F</td>\n",
       "      <td>ldoyle@hotmail.com</td>\n",
       "      <td>1916-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Gloria</td>\n",
       "      <td>Aguilar</td>\n",
       "      <td>435 Escobar Wall Apt. 304</td>\n",
       "      <td>ME</td>\n",
       "      <td>71133</td>\n",
       "      <td>082-24-7955</td>\n",
       "      <td>ecunningham</td>\n",
       "      <td>F</td>\n",
       "      <td>jennifersanchez@gmail.com</td>\n",
       "      <td>1912-02-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first name  last name                    street address state postal code  \\\n",
       "233      Roger   Anderson     1900 Bradley Skyway Suite 346    WY       83697   \n",
       "40       David   Anderson  9299 Kimberly Mountains Apt. 160    GA       66995   \n",
       "15     Spencer     Arnold          2292 Dyer Park Suite 698    HI       30374   \n",
       "94      Alyssa   Anderson      12509 Jordan Rapid Suite 221    RI       67312   \n",
       "117   Patricia    Andrade                  037 Warner Place    VI       46571   \n",
       "311     Darren  Alexander      67790 Brandon Wells Apt. 209    FM       92577   \n",
       "130    Michael      Allen         8032 Yvonne Cove Apt. 472    MP       87536   \n",
       "378    Rebecca      Allen                  827 Jason Island    PA       29406   \n",
       "164   Kathleen     Arroyo       7433 Joshua Light Suite 423    GU       35854   \n",
       "236    Chelsea      Adams       560 Cynthia Summit Apt. 271    MN       51695   \n",
       "52      Jerome     Adkins         5763 Ashley View Apt. 054    NJ       33403   \n",
       "221    Jessica   Anderson      323 Vasquez Village Apt. 866    ND       62196   \n",
       "294     Andrea    Andrews      620 Sanders Summit Suite 382    NY       95796   \n",
       "356    Melinda      Allen                    736 Reese Loaf    FL       60678   \n",
       "230       Beth   Arellano     3585 Tanner Mission Suite 928    NM       91034   \n",
       "172     Gloria    Aguilar         435 Escobar Wall Apt. 304    ME       71133   \n",
       "\n",
       "             ssn         username sex                       mail  birthdate  \n",
       "233  557-08-4915        jeffrey73   M     mandystone@hotmail.com 2019-12-14  \n",
       "40   863-94-6652           bsmith   M          cjensen@gmail.com 2007-05-06  \n",
       "15   839-68-0180      justingrant   M   millerjennifer@gmail.com 2002-06-11  \n",
       "94   618-23-7085    michaelmartin   F        kmiller@hotmail.com 1997-08-23  \n",
       "117  485-57-5914  robersonbeverly   F     brownjames@hotmail.com 1975-12-30  \n",
       "311  202-81-9617     lawsoneugene   M     sblankenship@gmail.com 1964-06-17  \n",
       "130  417-66-5820         vbaldwin   M        danderson@gmail.com 1960-05-24  \n",
       "378  606-20-1906         afreeman   F    cherylbuckley@gmail.com 1958-04-02  \n",
       "164  701-62-8909        michael06   F       hollyweber@yahoo.com 1949-02-24  \n",
       "236  392-79-6259        phyllis60   F      kelseydavis@gmail.com 1946-12-12  \n",
       "52   891-40-6262        htrujillo   M         teresa97@gmail.com 1938-07-02  \n",
       "221  475-87-5012  justinrodriguez   F        msnyder@hotmail.com 1938-02-06  \n",
       "294  430-97-1375        fbartlett   F        natalie15@yahoo.com 1929-10-24  \n",
       "356  607-43-8328  destinygonzalez   F          bross@hotmail.com 1921-02-21  \n",
       "230  579-46-9356        tanyakemp   F         ldoyle@hotmail.com 1916-08-11  \n",
       "172  082-24-7955      ecunningham   F  jennifersanchez@gmail.com 1912-02-22  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe where last name starts with A\n",
    "data = df[df[\"last name\"].str.startswith('A')].copy()\n",
    "#sort by sex and by default it is ascending and F is first\n",
    "ladies_first = data.sort_values(by = [\"sex\"])\n",
    "#The same as ladies_first, it starts with 'A' first\n",
    "state =  data.sort_values(by = [\"state\"])\n",
    "#Convert this birthdate to real datetime value\n",
    "data[\"birthdate\"] = pd.to_datetime(data[\"birthdate\"])\n",
    "#pass False to ascending, it means the youngest is sorted first\n",
    "age = data.sort_values(by = [\"birthdate\"], ascending = False)\n",
    "print(\"Sort by ladies first:\") \n",
    "print(ladies_first)\n",
    "print(\"Sort by state:\")\n",
    "print(state)\n",
    "print(\"Sort by age( youngest first):\")\n",
    "age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82629f-43fd-4272-a4a2-97addd6614b6",
   "metadata": {},
   "source": [
    "## Problem 2. Weather (part 1/2)\n",
    "\n",
    "The file `private/exrc_02/data/XXXXX_prob02_weather.csv` contains hourly weather observations from Helsinki during one month, downloaded from [fmi.fi](https://en.ilmatieteenlaitos.fi/open-data-manual-fmi-wfs-services) (not recommended).\n",
    "\n",
    "First, please do some data cleaning and reorganizing as you find suitable. Then, please answer the following questions:\n",
    "\n",
    "a) How many percentages of the `(tmax+tmin)/2` observations are at most one standard deviation away from the total average of `(tmax+tmin)/2`?\n",
    "\n",
    "b) Find the top-5 timestamps for the difference between `tmax` and `tmin`, i.e. for `tmax-tmin`. For the found rows, print out the following information: timestamp, max temperature, min temperature and temperature difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635f4c81-639f-4276-a1a6-ae0709a8f6a1",
   "metadata": {},
   "source": [
    "### Problem 2a \n",
    "Preference:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.Series.between.html#pandas.Series.between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a20b981b-fb10-4384-a276-8ec08f5a0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "user = getuser()\n",
    "csv_location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob02_weather.csv'\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "df.index = df.Time\n",
    "\n",
    "df = df.drop('Time', axis=1)\n",
    "\n",
    "df = df.pivot(columns='ParameterName', values='ParameterValue')\n",
    "\n",
    "df = df.drop(['TG_PT12H_min', 'rrday', 'tday', 'snow'], axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "avr = (df['tmin'] + df['tmax'])/2\n",
    "my_mean = ((df['tmin'] + df['tmax'])/2).mean()\n",
    "\n",
    "my_std = ((df['tmin'] + df['tmax'])/2).std()\n",
    "\n",
    "#Get value true if value from lower (my_mean-my_std) to upper (my_mean+my_std)\n",
    "#The purpose is to count all of average value of avr variable form range of  (my_mean-my_std) and (my_mean+my_std)\n",
    "most_deviation = avr.between(my_mean-my_std,my_mean+my_std)\n",
    "# Get average with mean() and get percent when mulptile with 100\n",
    "percent = most_deviation.mean() * 100\n",
    "print(percent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857cc8a-20b2-4c8c-82fe-59b6fc98bf3a",
   "metadata": {},
   "source": [
    "### Problem 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "051d5783-c7a5-485f-a3eb-0e58e236d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      max temperature  min temperature  temperature difference\n",
      "Time                                                                          \n",
      "2018-11-04T00:00:00Z              9.7              2.0                     7.7\n",
      "2018-11-15T00:00:00Z              9.0              3.0                     6.0\n",
      "2018-11-02T00:00:00Z             10.5              4.7                     5.8\n",
      "2018-11-28T00:00:00Z             -0.8             -6.1                     5.3\n",
      "2018-11-26T00:00:00Z             -0.2             -5.3                     5.1\n"
     ]
    }
   ],
   "source": [
    "#Create a new column with difference between max and min temperature\n",
    "df[\"temperature difference\"] = df['tmax'] - df['tmin']\n",
    "## sort out the difference from biggest to smallest\n",
    "sort = df.sort_values(\"temperature difference\",ascending = False)\n",
    "#Change the names of column titles\n",
    "sort.columns = [\"max temperature\",\"min temperature\",\"temperature difference\"]\n",
    "#only show with top 5\n",
    "print(sort.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc3925-ea46-4069-a059-1adc344dd929",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 3. Premier League Table\n",
    "The file `private/exrc_02/data/XXXXX_prob03_epl.csv` has some English Premier League results, downloaded using [this api](https://github.com/miquel-vv/football_data_api).\n",
    "\n",
    "Using the full data, generate a league table which has the team name as the index and columns as follows (a win gives 3 points, a draw gives 1 point, and a loss gives 0 points):\n",
    "* games played\n",
    "* wins\n",
    "* draws\n",
    "* defeats\n",
    "* goals for - goals against\n",
    "* points\n",
    "\n",
    "\n",
    "Sort it with points (most points win). If points are equal, then sorted by\n",
    "* goal difference (goals for - goals against)\n",
    "* goals for\n",
    "\n",
    "\n",
    "The expected result should look something like this (not the same data though):\n",
    "```\n",
    "                games  wins  draws  defeats   goals  points\n",
    "Man City           38    32      4        2  106-27     100\n",
    "Man United         38    25      6        7   68-28      81\n",
    "Tottenham          38    23      8        7   74-36      77\n",
    "Liverpool          38    21     12        5   84-38      75\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e51237-c567-456a-86ae-982bfb2207b0",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "- https://www.geeksforgeeks.org/pandas/python-pandas-dataframe-groupby/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.agg.html#pandas.core.groupby.DataFrameGroupBy.agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848aca0a-7f8a-4533-ab5e-553411c96f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>games</th>\n",
       "      <th>wins</th>\n",
       "      <th>draws</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Liverpool FC</th>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0-20.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nottingham Forest FC</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>36.0-15.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Ham United FC</th>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>24.0-18.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFC Bournemouth</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>41.0-20.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chelsea FC</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>27.0-16.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fulham FC</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>32.0-29.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aston Villa FC</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>31.0-19.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manchester City FC</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>43.0-27.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manchester United FC</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>34.0-18.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brentford FC</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0-22.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leeds United FC</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0-25.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tottenham Hotspur FC</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>37.0-33.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leicester City FC</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>34.0-29.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newcastle United FC</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0-20.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crystal Palace FC</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>22.0-23.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wolverhampton Wanderers FC</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>19.0-20.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southampton FC</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27.0-25.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Everton FC</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>23.0-20.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arsenal FC</th>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>28.0-28.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brighton &amp; Hove Albion FC</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>33.0-31.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            games  wins  draws  defeats      goals  points\n",
       "team                                                                      \n",
       "Liverpool FC                   21    11      5        3  39.0-20.0      38\n",
       "Nottingham Forest FC           21    10      6        4  36.0-15.0      36\n",
       "West Ham United FC             21    11      3        6  24.0-18.0      36\n",
       "AFC Bournemouth                21    10      5        5  41.0-20.0      35\n",
       "Chelsea FC                     21    10      5        5  27.0-16.0      35\n",
       "Fulham FC                      20    10      4        6  32.0-29.0      34\n",
       "Aston Villa FC                 21    10      4        6  31.0-19.0      34\n",
       "Manchester City FC             19    10      3        6  43.0-27.0      33\n",
       "Manchester United FC           19    10      3        6  34.0-18.0      33\n",
       "Brentford FC                   20     8      8        3  38.0-22.0      32\n",
       "Leeds United FC                19     9      5        4  34.0-25.0      32\n",
       "Tottenham Hotspur FC           20     9      3        8  37.0-33.0      30\n",
       "Leicester City FC              21     9      3        8  34.0-29.0      30\n",
       "Newcastle United FC            21     7      9        4  24.0-20.0      30\n",
       "Crystal Palace FC              21     8      6        6  22.0-23.0      30\n",
       "Wolverhampton Wanderers FC     20     8      5        6  19.0-20.0      29\n",
       "Southampton FC                 21     8      3        9  27.0-25.0      27\n",
       "Everton FC                     21     7      6        7  23.0-20.0      27\n",
       "Arsenal FC                     19     8      2        8  28.0-28.0      26\n",
       "Brighton & Hove Albion FC      21     7      4        8  33.0-31.0      25"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from getpass import getuser\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "user = getuser()\n",
    "csv_location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob03_epl.csv'\n",
    "csv_location = \"ah4323_prob03_epl.csv\"\n",
    "df = pd.read_csv(csv_location)\n",
    "\n",
    "\n",
    "df['fullTime']=df['fullTime'].apply(lambda x: literal_eval(x))\n",
    "##Parse the scores of home team and away team from fullTime to different columns\n",
    "df['homeScore'] = df['fullTime'].apply(lambda x: x['homeTeam'])\n",
    "df['awayScore'] = df['fullTime'].apply(lambda x: x['awayTeam'])\n",
    "#set value 1 for each game in order count the number of games\n",
    "df['games'] = 1\n",
    "\n",
    "##Set two different data frame for hometeam and awayteam\n",
    "## For hometeam, there are homescore(goals for) and awayscore(goal against) and number of games\n",
    "## For awayteam, homescore is set from awayscore of hometeam.\n",
    "##On the other hand, the \"goals for\"/\"homescore\" of awayteam is score from awayscore of hometeam.\n",
    "home = pd.DataFrame({\"team\": df[\"homeTeam\"], \"homeScore\": df[\"homeScore\"], \"awayScore\": df[\"awayScore\"], 'games': df['games']} )\n",
    "away = pd.DataFrame({\"team\": df[\"awayTeam\"], \"awayScore\": df[\"awayScore\"], \"homeScore\": df[\"homeScore\"] ,'games': df['games']})\n",
    "\n",
    "##two datafram is combined  in same coulum name such as team, homescore and away\n",
    "combine = pd.concat([home, away])\n",
    "## Create column wins, draws amd defeats\n",
    "## It simply set it true or false by set condition and convert it to type integer so \n",
    "## it is easier to calculate it later\n",
    "combine['wins'] =  (combine['homeScore'] > combine['awayScore']).astype(int)\n",
    "combine['draws'] = (combine['homeScore'] == combine['awayScore']).astype(int)\n",
    "combine['defeats'] = (combine['homeScore'] < combine['awayScore']).astype(int)\n",
    "\n",
    "## Function groupby will set any function based on team.\n",
    "## For example, team AFC Bournemoth will be filtered and calcuated the sum of game played, scores and so on.  \n",
    "combine = combine.groupby('team').agg(\n",
    "        {'games' : 'sum',\n",
    "        'homeScore' : 'sum',\n",
    "        'awayScore':'sum',\n",
    "        'wins': 'sum',\n",
    "        'draws': 'sum',\n",
    "        'defeats'  : 'sum',}\n",
    ")\n",
    "## set goal difference and points \n",
    "combine['goalDif'] = combine['homeScore'] - combine['awayScore']\n",
    "combine['goals'] = combine['homeScore'].astype(str) + '-'  + combine['awayScore'].astype(str) \n",
    "combine['points'] = combine['wins'] *3  + combine['draws'] \n",
    "##Set all of needed columns \n",
    "##Sort from largest with points first then goals for and then goal difference\n",
    "combine = combine.sort_values(by=[\"points\",\"homeScore\",\"goalDif\"] ,ascending = [False,False,False])\n",
    "df = combine[['games','wins','draws','defeats','goals','points']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670cdbf-167d-45b5-b2b3-24e1bc8ae4e6",
   "metadata": {},
   "source": [
    "## Problem 4. Weather (part 2/2)\n",
    "\n",
    "The file `private/exrc_02/data/XXXXX_prob04_weather.txt` \n",
    "has some (old) weather data from Jyväskylä 1959-2021, again downloaded from [fmi.fi](https://en.ilmatieteenlaitos.fi/open-data-manual-fmi-wfs-services) (not recommended).\n",
    "\n",
    "Calculate the \"snow sum\" (not an official meteorological term) for each winter by adding the snow depths for each day of that winter. Start from winter 1959-60 and end to 2019-20 since 1958-59 and 2020-21 are only partial.\n",
    "\n",
    "Notes:\n",
    "* You need to define \"winter\" by yourself.\n",
    "* FMI uses -1 as snow depth when \"there is absolutely no snow at all\". We don't want to reduce snow sum in that case, so replace -1 with 0.\n",
    "* For missing data, assume that the snow depth has been the same as during the previous day. (Fill any `NaN`s with the previous valid value.)\n",
    "\n",
    "Then produce a DataFrame that has the winter as the index (in form \"1959-1960\") and columns:\n",
    "* snow sum\n",
    "* snow sum rank among winters so that largest = 1\n",
    "* count of days where snow depth has been positive\n",
    "* max snow depth of the winter.\n",
    "\n",
    "\n",
    "The three first and the three last rows should look something like:\n",
    "```\n",
    "           Snow sum  rank  count  max\n",
    "Winter                               \n",
    "1959-1960      5593    18    169   65\n",
    "1960-1961      5082    28    162   60\n",
    "1961-1962      6644    12    156   78\n",
    "\n",
    "...\n",
    "\n",
    "2017-2018      6882     8    161   81\n",
    "2018-2019      4030    42    150   54\n",
    "2019-2020      1432    59    112   30\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0660f-b2c3-41ee-a8a9-a29add9adfb1",
   "metadata": {},
   "source": [
    "Reference:\n",
    "- https://www.geeksforgeeks.org/python/pandas-query-method/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html#pandas.core.groupby.DataFrameGroupBy.rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c4770b46-3ac5-457c-8bec-6c4805cdc54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Snow_sum</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-1960</th>\n",
       "      <td>4956.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>134</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-1961</th>\n",
       "      <td>4344.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>133</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961-1962</th>\n",
       "      <td>5546.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>126</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-1963</th>\n",
       "      <td>3594.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>137</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-1964</th>\n",
       "      <td>3762.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>142</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-2016</th>\n",
       "      <td>1958.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>104</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-2017</th>\n",
       "      <td>2378.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>141</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-2018</th>\n",
       "      <td>5765.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>134</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-2019</th>\n",
       "      <td>3640.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>111</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2020</th>\n",
       "      <td>1414.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>107</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Snow_sum  rank  count   max\n",
       "winter                                \n",
       "1959-1960    4956.0  17.0    134  65.0\n",
       "1960-1961    4344.0  28.0    133  60.0\n",
       "1961-1962    5546.0  12.0    126  78.0\n",
       "1962-1963    3594.0  42.0    137  50.0\n",
       "1963-1964    3762.0  40.0    142  49.0\n",
       "...             ...   ...    ...   ...\n",
       "2015-2016    1958.0  55.0    104  40.0\n",
       "2016-2017    2378.0  52.0    141  38.0\n",
       "2017-2018    5765.0  11.0    134  80.0\n",
       "2018-2019    3640.0  41.0    111  54.0\n",
       "2019-2020    1414.0  59.0    107  30.0\n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from getpass import getuser\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "user = getuser()\n",
    "location = f'/home/varpha/dan/private/{user}' + \\\n",
    "                f'/exrc_02/data/{user}_prob04_weather.csv'\n",
    "df = pd.read_csv(location)\n",
    "## Winter in Finland could happend from December to March. It's still very cold in November and April.\n",
    "##But let's set winter from December to March\n",
    "df = df.query('Month >=11 or Month <=3')\n",
    "#replace -1 wiht 0 and fill Na with previous value with ffill() function\n",
    "df[\"Snow depth (cm)\"]= df[\"Snow depth (cm)\"].replace(-1,0)\n",
    "df[\"Snow depth (cm)\"]= df[\"Snow depth (cm)\"].ffill()\n",
    "##set winter based on month 11-3\n",
    "## The period is set like this\n",
    "##For example, 11-12/1959 and 1,2,3/1960 => winter is set as period 1959-1960 and 11-12/1960 and 1-3/1961 => 1960-1961 and so on\n",
    "df['winter']= df.apply(lambda x: \n",
    "             f'{x.Year}-{x.Year +1}' if\n",
    "             x.Month == 11 or  x.Month == 12 else\n",
    "             f'{x.Year -1}-{x.Year}' if\n",
    "             x.Month in [1,2,3] else None,\n",
    "             axis=1\n",
    "            ) \n",
    "\n",
    "## set index of datafram is based on winter period \n",
    "df.index = df['winter']\n",
    "df = df.drop('winter',axis=1)\n",
    "##Only set winter period from \"1959-1960\" to\"2019-2020\n",
    "df = df[\"1959-1960\":\"2019-2020\"]\n",
    "##Caculation based on winter period\n",
    "df = df.groupby(\"winter\").agg(\n",
    "    Snow_sum = (\"Snow depth (cm)\",\"sum\"),\n",
    "    count = (\"Snow depth (cm)\", lambda x : (x > 0).sum() ),\n",
    "    max = (\"Snow depth (cm)\",\"max\")\n",
    ")\n",
    "#rank from biggest with number 1 \n",
    "df['rank'] = df['Snow_sum'].rank(ascending= False,method='min')\n",
    "df = df[[\"Snow_sum\",\"rank\",\"count\",\"max\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf511d-2bff-4d3b-8cd3-2231732df527",
   "metadata": {},
   "source": [
    "## Problem 5. Statfi data wrangle.\n",
    "- Here we're trying to make some sense out of the data that we downloaded from the statfi service in problem 5 of the first exercises. If you did it successfully, please use your own data. Otherwise you may use the data found in `public/exrc_02/data`.\n",
    "- That data used the keyword `kihi` and the final table `statfin_kihi_pxt_13zt.px`. You may want to replace them in the front end url below.\n",
    "- First use [this front end](https://pxdata.stat.fi/PxWeb/pxweb/en/StatFin/StatFin__kihi/statfin_kihi_pxt_13zt.px/) to produce a meaningful table, and then try to produce a similar table with pandas and your data.\n",
    "- The most elegant solution wins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "205e6306-d55b-4bd3-b7cd-11f387bf47af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               key                               values\n",
      "0  [0, 2012, 0, 0]  [9980, .., 53390, .., 5.3, 3.0, 22]\n",
      "1  [0, 2012, 0, 1]  [7670, .., 51330, .., 6.7, 4.0, 29]\n",
      "2  [0, 2012, 0, 2]    [1380, .., 2060, .., 1.5, 1.0, .]\n",
      "3  [0, 2012, 0, 3]        [920, .., 0, .., 0.0, 0.0, .]\n",
      "4  [0, 2012, 1, 0]  [3140, .., 17510, .., 5.6, 3.0, 21]\n",
      "5  [0, 2012, 1, 1]    [2370, ., 16710, ., 7.1, 4.0, 28]\n",
      "6  [0, 2012, 1, 2]        [500, ., 800, ., 1.6, 2.0, .]\n",
      "7  [0, 2012, 1, 3]        [270, .., 0, .., 0.0, 0.0, .]\n",
      "8  [0, 2012, 2, 0]  [3670, .., 20290, .., 5.5, 3.0, 24]\n",
      "9  [0, 2012, 2, 1]  [2930, .., 19680, .., 6.7, 4.0, 30]\n",
      "['Trip purpose', 'Year', 'Season', 'Type of trip abroad']\n",
      "['Trips, thousand trips', 'Change of trips, %', 'Overnight stays, thousand overnight stays', 'Change of nights, %', 'Average length of trip, nights', 'Median length of trip, nights', 'Share of package trips, %']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Trips, thousand trips</th>\n",
       "      <th>Average length of trip, nights</th>\n",
       "      <th>Average length of trip, nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>9980</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>7670</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>3140</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>2370</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>500</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012</td>\n",
       "      <td>270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012</td>\n",
       "      <td>3670</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>2930</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>430</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012</td>\n",
       "      <td>320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012</td>\n",
       "      <td>3170</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012</td>\n",
       "      <td>2370</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012</td>\n",
       "      <td>460</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012</td>\n",
       "      <td>340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013</td>\n",
       "      <td>9530</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013</td>\n",
       "      <td>7200</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013</td>\n",
       "      <td>1360</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013</td>\n",
       "      <td>960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year Trips, thousand trips Average length of trip, nights  \\\n",
       "0   2012                  9980                            5.3   \n",
       "1   2012                  7670                            6.7   \n",
       "2   2012                  1380                            1.5   \n",
       "3   2012                   920                            0.0   \n",
       "4   2012                  3140                            5.6   \n",
       "5   2012                  2370                            7.1   \n",
       "6   2012                   500                            1.6   \n",
       "7   2012                   270                            0.0   \n",
       "8   2012                  3670                            5.5   \n",
       "9   2012                  2930                            6.7   \n",
       "10  2012                   430                            1.4   \n",
       "11  2012                   320                            0.0   \n",
       "12  2012                  3170                            4.9   \n",
       "13  2012                  2370                            6.3   \n",
       "14  2012                   460                            1.4   \n",
       "15  2012                   340                            0.0   \n",
       "16  2013                  9530                            5.1   \n",
       "17  2013                  7200                            6.5   \n",
       "18  2013                  1360                            1.4   \n",
       "19  2013                   960                            0.0   \n",
       "\n",
       "   Average length of trip, nights  \n",
       "0                             5.3  \n",
       "1                             6.7  \n",
       "2                             1.5  \n",
       "3                             0.0  \n",
       "4                             5.6  \n",
       "5                             7.1  \n",
       "6                             1.6  \n",
       "7                             0.0  \n",
       "8                             5.5  \n",
       "9                             6.7  \n",
       "10                            1.4  \n",
       "11                            0.0  \n",
       "12                            4.9  \n",
       "13                            6.3  \n",
       "14                            1.4  \n",
       "15                            0.0  \n",
       "16                            5.1  \n",
       "17                            6.5  \n",
       "18                            1.4  \n",
       "19                            0.0  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from getpass import getuser\n",
    "\n",
    "user = getuser()\n",
    "# let's read the data into a plain python dict first\n",
    "with open(\"test.json\",\"r\") as handle:\n",
    "    statfi_data = json.load(handle)\n",
    "\n",
    "df = pd.json_normalize(statfi_data, record_path = 'data')\n",
    "print(df.head(10))\n",
    "\n",
    "key_exploded = df['key'].apply(pd.Series)\n",
    "\n",
    "values_exploded = df['values'].apply(pd.Series)\n",
    "\n",
    "df = pd.concat([key_exploded, values_exploded], axis=1)\n",
    "##In test file, there are total 11 items in columns but there are only 4 items in key of data\n",
    "#That's why it needs to be get data in two parts below\n",
    "##Get key name based on the length of key_exploded.columns\n",
    "key_names = [c[\"text\"] for c in statfi_data[\"columns\"][:len(key_exploded.columns)]]\n",
    "print(key_names)\n",
    "##Get value name from the rest of data of statfi_data[\"columns\"]\n",
    "value_names = [c[\"text\"] for c in statfi_data[\"columns\"][len(key_exploded.columns):]]\n",
    "print(value_names)\n",
    "df.columns = key_names + value_names\n",
    "## For some fields about trips\n",
    "\n",
    "df = df[[\"Year\",\"Trips, thousand trips\",\"Average length of trip, nights\",\"Average length of trip, nights\"]]\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0e70b-1a6e-40f7-aba7-d12ae5968d8a",
   "metadata": {},
   "source": [
    "## How to submit my solutions?\n",
    "\n",
    "Open a Terminal tab (e.g. <tt>File $\\rightarrow$ New $\\rightarrow$ Terminal</tt>, copy-paste the following into the Terminal command prompt, and press enter:\n",
    "<pre>\n",
    "  /home/varpha/dan/menu.py\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
